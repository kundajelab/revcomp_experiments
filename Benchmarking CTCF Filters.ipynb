{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import keras_genomics\n",
    "import numpy as np\n",
    "import keras.layers as k1\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.utils import conv_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Initializer\n",
    "def _compute_fans(shape, data_format='channels_last'):\n",
    "    \"\"\"Computes the number of input and output units for a weight shape.\n",
    "    # Arguments\n",
    "        shape: Integer shape tuple.\n",
    "        data_format: Image data format to use for convolution kernels.\n",
    "            Note that all kernels in Keras are standardized on the\n",
    "            `channels_last` ordering (even when inputs are set\n",
    "            to `channels_first`).\n",
    "    # Returns\n",
    "        A tuple of scalars, `(fan_in, fan_out)`.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid `data_format` argument.\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "        fan_out = shape[1]\n",
    "    elif len(shape) in {3, 4, 5}:\n",
    "        # Assuming convolution kernels (1D, 2D or 3D).\n",
    "        # TH kernel shape: (depth, input_depth, ...)\n",
    "        # TF kernel shape: (..., input_depth, depth)\n",
    "        if data_format == 'channels_first':\n",
    "            receptive_field_size = np.prod(shape[2:])\n",
    "            fan_in = shape[1] * receptive_field_size\n",
    "            fan_out = shape[0] * receptive_field_size\n",
    "        elif data_format == 'channels_last':\n",
    "            receptive_field_size = np.prod(shape[:-2])\n",
    "            fan_in = shape[-2] * receptive_field_size\n",
    "            fan_out = shape[-1] * receptive_field_size\n",
    "        else:\n",
    "            raise ValueError('Invalid data_format: ' + data_format)\n",
    "    else:\n",
    "        # No specific assumptions.\n",
    "        fan_in = np.sqrt(np.prod(shape))\n",
    "        fan_out = np.sqrt(np.prod(shape))\n",
    "    return fan_in, fan_out\n",
    "\n",
    "class RevcompVarianceScaling(Initializer):\n",
    "    def __init__(self, scale=1.0,\n",
    "                 mode='fan_in',\n",
    "                 distribution='normal',\n",
    "                 seed=None):\n",
    "        if scale <= 0.:\n",
    "            raise ValueError('`scale` must be a positive float. Got:', scale)\n",
    "        mode = mode.lower()\n",
    "        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n",
    "            raise ValueError('Invalid `mode` argument: '\n",
    "                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n",
    "                             'but got', mode)\n",
    "        distribution = distribution.lower()\n",
    "        if distribution not in {'normal', 'uniform'}:\n",
    "            raise ValueError('Invalid `distribution` argument: '\n",
    "                             'expected one of {\"normal\", \"uniform\"} '\n",
    "                             'but got', distribution)\n",
    "        self.scale = scale\n",
    "        self.mode = mode\n",
    "        self.distribution = distribution\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        fan_in, fan_out = _compute_fans(shape)\n",
    "        fan_out = fan_out*2 #revcomp kernel underestimates fan_out\n",
    "        print(\"fanin:\",fan_in, \"fanout:\",fan_out, self.scale, self.mode)\n",
    "        scale = self.scale\n",
    "        if self.mode == 'fan_in':\n",
    "            scale /= max(1., fan_in)\n",
    "        elif self.mode == 'fan_out':\n",
    "            scale /= max(1., fan_out)\n",
    "        else:\n",
    "            scale /= max(1., float(fan_in + fan_out) / 2)\n",
    "        if self.distribution == 'normal':\n",
    "            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n",
    "            stddev = np.sqrt(scale) / .87962566103423978\n",
    "            return K.truncated_normal(shape, 0., stddev,\n",
    "                                      dtype=dtype, seed=self.seed)\n",
    "        else:\n",
    "            limit = np.sqrt(3. * scale)\n",
    "            return K.random_uniform(shape, -limit, limit,\n",
    "                                    dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'scale': self.scale,\n",
    "            'mode': self.mode,\n",
    "            'distribution': self.distribution,\n",
    "            'seed': self.seed\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "class ColsInBedFile(\n",
    "    coordbased.coordstovals.core.AbstractSingleNdarrayCoordsToVals):\n",
    "    def __init__(self, gzipped_bed_file, **kwargs):\n",
    "        super(ColsInBedFile, self).__init__(**kwargs)\n",
    "        self.gzipped_bed_file = gzipped_bed_file\n",
    "        coords_to_vals = {}\n",
    "        for row in gzip.open(gzipped_bed_file, 'rb'):\n",
    "            row = row.decode(\"utf-8\").rstrip()\n",
    "            split_row = row.split(\"\\t\")\n",
    "            chrom_start_end = split_row[0]+\":\"+split_row[1]+\"-\"+split_row[2]\n",
    "            vals = np.array([float(x) for x in split_row[4:]])\n",
    "            coords_to_vals[chrom_start_end] = vals\n",
    "        self.coords_to_vals = coords_to_vals\n",
    "        \n",
    "    def _get_ndarray(self, coors):\n",
    "        to_return = []\n",
    "        for coor in coors:\n",
    "            chrom_start_end = (coor.chrom+\":\"\n",
    "                               +str(coor.start)+\"-\"+str(coor.end))\n",
    "            to_return.append(self.coords_to_vals[chrom_start_end])\n",
    "        return np.array(to_return)\n",
    "    \n",
    "    \n",
    "inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "  genome_fasta_path= '/mnt/data/annotations/by_release/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta',\n",
    "  center_size_to_use=1000)\n",
    "\n",
    "targets_coordstovals = ColsInBedFile(\n",
    "       gzipped_bed_file=\"summits_with_signal.bed.gz\")\n",
    "            \n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      #coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\", \n",
    "        batch_size=64, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\", \n",
    "        batch_size = 64, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_train_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=128,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size=128, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size = 128, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_coordstovals.ltrdict = {\n",
    "           'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1],\n",
    "           'n':[0,0,0,0],'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],\n",
    "           'T':[0,0,0,1],'N':[0,0,0,0],'R': [0.5,0,0.5,0],'Y':[0,0.5,0,0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([val for batch in keras_train_batch_generator for val in batch[1]], dtype = 'float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36436"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSpatialDropout1D(Dropout): \n",
    "    def __init__(self, rate,**kwargs): \n",
    "        super(RevCompSpatialDropout1D, self).__init__(rate, **kwargs)\n",
    "        self.seed = 3\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "\n",
    "    def _get_noise_shape(self, inputs): \n",
    "        input_shape = K.shape(inputs)\n",
    "        noise_shape = (input_shape[0], 1, 1, int(self.num_input_chan/2)) \n",
    "        return noise_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        self.input_len = input_shape[1]\n",
    "        super(RevCompSpatialDropout1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None): \n",
    "        inputs_fwdandrevconcat = K.concatenate(\n",
    "                tensors = [\n",
    "                    inputs[:,:,None,:int(self.num_input_chan/2)],\n",
    "                    inputs[:,:,None,int(self.num_input_chan/2):][:,:,:,::-1]],\n",
    "                axis=2)\n",
    "\n",
    "        if 0. < self.rate < 1.: \n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            def dropped_inputs(): \n",
    "                dropped = K.dropout(inputs_fwdandrevconcat,\n",
    "                                    self.rate, noise_shape, seed = self.seed)\n",
    "                dropped = K.reshape(dropped, (-1, int(self.input_len), int(self.num_input_chan)))\n",
    "                return K.concatenate(\n",
    "                    tensors = [\n",
    "                        dropped[:,:,:int(self.num_input_chan/2)],\n",
    "                        dropped[:,:,int(self.num_input_chan/2):][:,:,::-1]],\n",
    "                    axis=-1)\n",
    "\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training = training)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import numbers\n",
    "from tensorflow.python.framework import tensor_util\n",
    "def _get_noise_shape(x, noise_shape):\n",
    "  # If noise_shape is none return immediately.\n",
    "  if noise_shape is None:\n",
    "    return array_ops.shape(x)\n",
    "\n",
    "  try:\n",
    "    # Best effort to figure out the intended shape.\n",
    "    # If not possible, let the op to handle it.\n",
    "    # In eager mode exception will show up.\n",
    "    noise_shape_ = tensor_shape.as_shape(noise_shape)\n",
    "  except (TypeError, ValueError):\n",
    "    return noise_shape\n",
    "\n",
    "  if x.shape.dims is not None and len(x.shape.dims) == len(noise_shape_.dims):\n",
    "    new_dims = []\n",
    "    for i, dim in enumerate(x.shape.dims):\n",
    "      if noise_shape_.dims[i].value is None and dim.value is not None:\n",
    "        new_dims.append(dim.value)\n",
    "      else:\n",
    "        new_dims.append(noise_shape_.dims[i].value)\n",
    "    return tensor_shape.TensorShape(new_dims)\n",
    "\n",
    "  return noise_shape\n",
    "\n",
    "class MCRCDropout(Layer):\n",
    "    \"\"\"Applies MC Dropout to the input.\n",
    "       The applied noise vector is symmetric to reverse complement symmetry\n",
    "       Class structure only slightly adapted \n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    Remains active ative at test time so sampling is required\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(MCRCDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(MCRCDropout, self).build(input_shape)\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                       for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            import numpy as np\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            x = inputs\n",
    "            seed = self.seed\n",
    "            keep_prob = 1. - self.rate\n",
    "            if seed is None:\n",
    "                seed = np.random.randint(10e6)\n",
    "            # the dummy 1. works around a TF bug\n",
    "            # (float32_ref vs. float32 incompatibility)\n",
    "            x= x*1\n",
    "            name = None\n",
    "            with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "                x = ops.convert_to_tensor(x, name=\"x\")\n",
    "                if not x.dtype.is_floating:\n",
    "                    raise ValueError(\"x has to be a floating point tensor since it's going to\"\n",
    "                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n",
    "                if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "                    raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                       \"range (0, 1], got %g\" % keep_prob)\n",
    "                keep_prob = ops.convert_to_tensor(\n",
    "                             keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "                keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "                # Do nothing if we know keep_prob == 1\n",
    "                if tensor_util.constant_value(keep_prob) == 1:\n",
    "                    return x\n",
    "\n",
    "                noise_shape = _get_noise_shape(x, noise_shape)\n",
    "                # uniform [keep_prob, 1.0 + keep_prob)\n",
    "                random_tensor = keep_prob\n",
    "                random_tensor += random_ops.random_uniform(\n",
    "                noise_shape, seed=seed, dtype=x.dtype)\n",
    "               \n",
    "                # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "                binary_tensor = math_ops.floor(random_tensor)\n",
    "                dim = binary_tensor.shape[2]//2\n",
    "\n",
    "                symmetric_binary = K.concatenate(\n",
    "                    tensors = [\n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):], \n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):][::,::-1,::-1]], \n",
    "                  axis=2)\n",
    "                ret = math_ops.div(x, keep_prob) * symmetric_binary\n",
    "                \n",
    "                return ret\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate,\n",
    "                  'noise_shape': self.noise_shape,\n",
    "                  'seed': self.seed}\n",
    "        base_config = super(MCRCDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevComp(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "      super(RevComp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "      super(RevComp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "      return inputs[:,::-1,::-1]\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "      return input_shape\n",
    "\n",
    "# custom_objects = {'RevComp':RevComp}\n",
    "# siamese_model_final = load_model('siamese_1000.h5', custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool(Initializer): \n",
    "    def __call__(self, shape, dtype = None): \n",
    "        return K.constant(1/(shape[0]), shape=shape, dtype=dtype)\n",
    "\n",
    "class WeightDistConv(Conv1D): \n",
    "    def __init__(self, filters, \n",
    "                kernel_size, \n",
    "                strides =1, \n",
    "                padding = 'valid', \n",
    "                data_format = 'channels_last',\n",
    "                dilation_rate = 1, \n",
    "                activation = None, \n",
    "                use_bias = False, \n",
    "                kernel_initializer = AveragePool(), \n",
    "                bias_initializer = 'zeros', \n",
    "                kernel_regularizer = None, \n",
    "                bias_regularizer = None, \n",
    "                activity_regularizer = None, \n",
    "                kernel_constraint = None,\n",
    "                bias_constraint = None, \n",
    "                **kwargs): \n",
    "        super(WeightDistConv, self).__init__(\n",
    "            filters=filters, \n",
    "            kernel_size=kernel_size, \n",
    "            strides = strides, \n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs) \n",
    "\n",
    "\n",
    "    def build(self, input_shape): \n",
    "        self.bias = None\n",
    "        self.filters = input_shape[-1]\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (self.filters,)\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                        initializer = self.kernel_initializer, \n",
    "                                        name ='kernel',\n",
    "                                        regularizer = self.kernel_regularizer, \n",
    "                                        constraint = self.kernel_constraint)\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=3,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.num_input_channels = input_shape[1]\n",
    "        self.built = True\n",
    "       \n",
    "      \n",
    "    #Layer's logic\n",
    "    def call(self, inputs):\n",
    "        result = []\n",
    "        for x in range(self.kernel_size[0]): \n",
    "            result.append((self.kernel[x][:,None]*K.eye(self.filters))[None,:,:])\n",
    "\n",
    "        curr_kernel = K.concatenate(result, axis = 0)\n",
    "#         print(\"curr kernel: \", curr_kernel)\n",
    "        outputs = K.conv1d(inputs, curr_kernel,\n",
    "                         strides=self.strides[0],\n",
    "                         padding=self.padding,\n",
    "                         data_format=self.data_format,\n",
    "                         dilation_rate=self.dilation_rate[0])\n",
    "\n",
    "        if (self.activation is not None):\n",
    "            outputs = self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "  \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = conv_utils.conv_output_length(input_length = self.num_input_channels, \n",
    "                                               filter_size = self.filters,\n",
    "                                               padding=self.padding,\n",
    "                                               stride=self.strides[0])\n",
    "        return (input_shape[0],length, self.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'RevCompConv1D':keras_genomics.layers.RevCompConv1D,\n",
    "                  'RevCompSumPool':RevCompSumPool,\n",
    "                  'RevcompVarianceScaling':RevcompVarianceScaling, \n",
    "                  'MCRCDropout':MCRCDropout,\n",
    "                  'RevCompSpatialDropout1D': RevCompSpatialDropout1D,\n",
    "                  'RevComp':RevComp,\n",
    "                  'AveragePool': AveragePool,\n",
    "                  'WeightDistConv': WeightDistConv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_spearmanr(y_test, name, test_batch_generator): \n",
    "    model = load_model(name, custom_objects)\n",
    "    y_pred = model.predict_generator(test_batch_generator)\n",
    "    plt.scatter(y_test, y_pred, alpha = 0.1)\n",
    "    plt.xlabel(\"True Labels: %s\" % name)\n",
    "    plt.ylabel(\"Predicted Labels\")\n",
    "    plt.show()\n",
    "    print(spearmanr(y_test, y_pred))\n",
    "\n",
    "# Runs dropout during testing time and takes the average\n",
    "def predict_with_uncertainty(f, x, no_classes, n_iter=100):\n",
    "    result = np.zeros((n_iter,) + (x.shape[0], no_classes) )\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result[i,:, :] = f((x, 1))[0]\n",
    "\n",
    "    prediction = result.mean(axis=0)\n",
    "    uncertainty = result.std(axis=0)\n",
    "    return prediction\n",
    "\n",
    "def spearmanr_all(y_test, name, test_batch_generator): \n",
    "    model = load_model(name, custom_objects)\n",
    "    f2 = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                    [model.layers[-1].output])\n",
    "    \n",
    "    y_pred = np.concatenate(np.array([predict_with_uncertainty(f2, test_batch_generator[i][0], 1) for i in range(len(test_batch_generator))]), axis = 0)\n",
    "    rho, pval = spearmanr(y_test, y_pred)\n",
    "    return rho\n",
    "\n",
    "def get_results(filename, y_test, test_batch_generator): \n",
    "    result_arr = []\n",
    "    for i in range(10): \n",
    "        seed_num = seed_nums[i]\n",
    "        result_arr.append([spearmanr_all(y_test, ('/users/hannahgz/revcomp_experiments/SPI1_Results/%s_' % filename + str(seed_num) + '.h5'),\n",
    "                                      test_batch_generator), rates[i]])\n",
    "        print(str(result_arr[i][0]) + \" \" + str(result_arr[i][1]))\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([val for batch in keras_test_batch_generator for val in batch[1]], dtype = 'float32') \n",
    "y_test_augment = np.array([val for batch in keras_test_batch_generator_augment for val in batch[1]], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from abstention.figure_making_utils import wilcox_srs\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment_dropout\n",
      "Correlation:  0.579961855577644\n",
      "augment_spatial_dropout\n",
      "Correlation:  0.6082566515197448\n",
      "rc_dropout\n",
      "Correlation:  0.629177295527509\n",
      "rc_mc_dropout\n",
      "Correlation:  0.6104919234604967\n",
      "rc_orig_spatial_dropout\n",
      "Correlation:  0.6504447102627249\n",
      "rc_rc_spatial_dropout\n",
      "Correlation:  0.6231500735506831\n",
      "reg_dropout\n",
      "Correlation:  0.5678962597791517\n",
      "reg_spatial_dropout\n",
      "Correlation:  0.5610326067089133\n",
      "siamese_dropout\n",
      "Correlation:  0.6218975446824649\n",
      "siamese_spatial_dropout\n",
      "Correlation:  0.6098560370986797\n"
     ]
    }
   ],
   "source": [
    "rc_dropout = []\n",
    "rc_mc_dropout = []\n",
    "rc_orig_spatial_dropout = []\n",
    "rc_rc_spatial_dropout = []\n",
    "siamese_dropout = []\n",
    "siamese_spatial_dropout = []\n",
    "def get_results_from_config(name, seed_num): \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters_2/config_%s_5_filters_%s.json\" % (name, str(seed_num))) as json_file: \n",
    "        data = json.load(json_file)\n",
    "        print(name)\n",
    "        print(\"Correlation: \", data[\"correlation\"])\n",
    "    return data[\"correlation\"]\n",
    "        \n",
    "def get_results_model(name, seed_num):\n",
    "    rho = spearmanr_all(y_test, (\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters/%s_5_filters_%s.h5\" % (name, str(seed_num))), keras_test_batch_generator)\n",
    "    print(name)\n",
    "    print(\"Correlation: \", rho)\n",
    "\n",
    "get_results_from_config(\"augment_dropout\", 5068)\n",
    "get_results_from_config(\"augment_spatial_dropout\", 9337)\n",
    "rc_dropout.append(get_results_from_config(\"rc_dropout\", 8157))\n",
    "rc_mc_dropout.append(get_results_from_config(\"rc_mc_dropout\", 1976))\n",
    "rc_orig_spatial_dropout.append(get_results_model(\"rc_orig_spatial_dropout\", 7975))\n",
    "rc_rc_spatial_dropout.append(get_results_from_config(\"rc_rc_spatial_dropout\", 8011))\n",
    "get_results_from_config(\"reg_dropout\", 6011)\n",
    "get_results_from_config(\"reg_spatial_dropout\", 2079)\n",
    "siamese_dropout.append(get_results_from_config(\"siamese_dropout\", 4563))\n",
    "siamese_spatial_dropout.append(get_results_from_config(\"siamese_spatial_dropout\", 8844))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_dropout\n",
      "Correlation:  0.6258305461356328\n",
      "rc_mc_dropout\n",
      "Correlation:  0.6141984098836304\n",
      "rc_orig_spatial_dropout\n",
      "Correlation:  0.6480089182456751\n",
      "rc_rc_spatial_dropout\n",
      "Correlation:  0.6341481393791699\n",
      "siamese_dropout\n",
      "Correlation:  0.5947071600795995\n",
      "siamese_spatial_dropout\n",
      "Correlation:  0.6280957386437396\n"
     ]
    }
   ],
   "source": [
    "def get_results_from_config(name, seed_num): \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters_2/config_%s_5_filters_%s.json\" % (name, str(seed_num))) as json_file: \n",
    "        data = json.load(json_file)\n",
    "        print(name)\n",
    "        print(\"Correlation: \", data[\"correlation\"])\n",
    "    return data[\"correlation\"]\n",
    "rc_dropout.append(get_results_from_config(\"rc_dropout\", 5524))\n",
    "rc_mc_dropout.append(get_results_from_config(\"rc_mc_dropout\", 2958))\n",
    "rc_orig_spatial_dropout.append(get_results_from_config(\"rc_orig_spatial_dropout\", 5546))\n",
    "rc_rc_spatial_dropout.append(get_results_from_config(\"rc_rc_spatial_dropout\", 3730))\n",
    "siamese_dropout.append(get_results_from_config(\"siamese_dropout\", 7197))\n",
    "siamese_spatial_dropout.append(get_results_from_config(\"siamese_spatial_dropout\", 8944))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_dropout\n",
      "Correlation:  0.5971730699330292\n",
      "rc_mc_dropout\n",
      "Correlation:  0.6254929606793849\n",
      "rc_orig_spatial_dropout\n",
      "Correlation:  0.6040033839985453\n",
      "rc_rc_spatial_dropout\n",
      "Correlation:  0.6452457711437067\n",
      "siamese_dropout\n",
      "Correlation:  0.619605657740282\n",
      "siamese_spatial_dropout\n",
      "Correlation:  0.6461858878005585\n"
     ]
    }
   ],
   "source": [
    "def get_results_from_config(name, seed_num): \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters_3/config_%s_5_filters_%s.json\" % (name, str(seed_num))) as json_file: \n",
    "        data = json.load(json_file)\n",
    "        print(name)\n",
    "        print(\"Correlation: \", data[\"correlation\"])\n",
    "    return data[\"correlation\"]\n",
    "rc_dropout.append(get_results_from_config(\"rc_dropout\", 4675))\n",
    "rc_mc_dropout.append(get_results_from_config(\"rc_mc_dropout\", 5887))\n",
    "rc_orig_spatial_dropout.append(get_results_from_config(\"rc_orig_spatial_dropout\", 2451))\n",
    "rc_rc_spatial_dropout.append(get_results_from_config(\"rc_rc_spatial_dropout\", 9243))\n",
    "siamese_dropout.append(get_results_from_config(\"siamese_dropout\", 1365))\n",
    "siamese_spatial_dropout.append(get_results_from_config(\"siamese_spatial_dropout\", 4979))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_dropout\n",
      "Correlation:  0.6133529275435395\n",
      "rc_mc_dropout\n",
      "Correlation:  0.6376209246386088\n",
      "rc_orig_spatial_dropout\n",
      "Correlation:  0.5928856304570961\n",
      "rc_rc_spatial_dropout\n",
      "Correlation:  0.6424079840878698\n",
      "siamese_dropout\n",
      "Correlation:  0.6188316253446644\n",
      "siamese_spatial_dropout\n",
      "Correlation:  0.6398062393482135\n"
     ]
    }
   ],
   "source": [
    "def get_results_from_config(name, seed_num): \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters_4/config_%s_5_filters_%s.json\" % (name, str(seed_num))) as json_file: \n",
    "        data = json.load(json_file)\n",
    "        print(name)\n",
    "        print(\"Correlation: \", data[\"correlation\"])\n",
    "    return data[\"correlation\"]\n",
    "rc_dropout.append(get_results_from_config(\"rc_dropout\", 2646))\n",
    "rc_mc_dropout.append(get_results_from_config(\"rc_mc_dropout\", 1438))\n",
    "rc_orig_spatial_dropout.append(get_results_from_config(\"rc_orig_spatial_dropout\", 1652))\n",
    "rc_rc_spatial_dropout.append(get_results_from_config(\"rc_rc_spatial_dropout\", 8558))\n",
    "siamese_dropout.append(get_results_from_config(\"siamese_dropout\", 4677))\n",
    "siamese_spatial_dropout.append(get_results_from_config(\"siamese_spatial_dropout\", 7438))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_dropout\n",
      "Correlation:  0.6305932362750384\n",
      "rc_mc_dropout\n",
      "Correlation:  0.6451284228949195\n",
      "rc_orig_spatial_dropout\n",
      "Correlation:  0.647927720166936\n",
      "rc_rc_spatial_dropout\n",
      "Correlation:  0.6388134758891323\n"
     ]
    }
   ],
   "source": [
    "rc_dropout = []\n",
    "rc_mc_dropout = []\n",
    "rc_orig_spatial_dropout = []\n",
    "rc_rc_spatial_dropout = []\n",
    "import json\n",
    "def get_results_from_config(name, seed_num): \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/CTCF_Architecture_Results/CTCF_5_Filters_5/config_%s_5_filters_%s.json\" % (name, str(seed_num))) as json_file: \n",
    "        data = json.load(json_file)\n",
    "        print(name)\n",
    "        print(\"Correlation: \", data[\"correlation\"])\n",
    "    return data[\"correlation\"]\n",
    "rc_dropout.append(get_results_from_config(\"rc_dropout\", 4330))\n",
    "rc_mc_dropout.append(get_results_from_config(\"rc_mc_dropout\", 6721))\n",
    "rc_orig_spatial_dropout.append(get_results_from_config(\"rc_orig_spatial_dropout\", 6235))\n",
    "rc_rc_spatial_dropout.append(get_results_from_config(\"rc_rc_spatial_dropout\", 4305))\n",
    "# siamese_dropout.append(get_results_from_config(\"siamese_dropout\", 4677))\n",
    "# siamese_spatial_dropout.append(get_results_from_config(\"siamese_spatial_dropout\", 7438))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.629177295527509, 0.6258305461356328, 0.5971730699330292, 0.6133529275435395]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6104919234604967,\n",
       " 0.6141984098836304,\n",
       " 0.6254929606793849,\n",
       " 0.6376209246386088]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_mc_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0.6480089182456751, 0.6040033839985453, 0.5928856304570961]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_orig_spatial_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6231500735506831,\n",
       " 0.6341481393791699,\n",
       " 0.6452457711437067,\n",
       " 0.6424079840878698]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_rc_spatial_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6218975446824649, 0.5947071600795995, 0.619605657740282, 0.6188316253446644]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6098560370986797,\n",
       " 0.6280957386437396,\n",
       " 0.6461858878005585,\n",
       " 0.6398062393482135]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_spatial_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_dropout_SPI1 = get_results('augment_dropout/augment_dropout', y_test_augment, keras_test_batch_generator_augment)\n",
    "augment_spatial_dropout_SPI1 = get_results('augment_spatial_dropout/augment_spatial_dropout', y_test_augment, keras_test_batch_generator_augment)\n",
    "rc_dropout_SPI1 = get_results('rc_dropout/rc_dropout', y_test, keras_test_batch_generator)\n",
    "rc_mc_dropout_SPI1 = get_results('rc_mc_dropout/rc_mc_dropout', y_test, keras_test_batch_generator)\n",
    "rc_orig_spatial_dropout_SPI1 = get_results('rc_orig_spatial_dropout/rc_orig_spatial_dropout', y_test, keras_test_batch_generator)\n",
    "rc_rc_spatial_droput_SPI1 = get_results('rc_rc_spatial_dropout/rc_rc_spatial_dropout', y_test, keras_test_batch_generator)\n",
    "reg_dropout_SPI1 = get_results('reg_dropout/reg_dropout', y_test, keras_test_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
