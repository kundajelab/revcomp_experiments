{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import sacred\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "from sacred import Ingredient\n",
    "\n",
    "import keras \n",
    "import keras_genomics\n",
    "import keras.layers as k1\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import Input\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.initializers import Initializer\n",
    "from keras.utils import conv_utils\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "class ColsInBedFile(\n",
    "    coordbased.coordstovals.core.AbstractSingleNdarrayCoordsToVals):\n",
    "    def __init__(self, gzipped_bed_file, **kwargs):\n",
    "        super(ColsInBedFile, self).__init__(**kwargs)\n",
    "        self.gzipped_bed_file = gzipped_bed_file\n",
    "        coords_to_vals = {}\n",
    "        for row in gzip.open(gzipped_bed_file, 'rb'):\n",
    "            row = row.decode(\"utf-8\").rstrip()\n",
    "            split_row = row.split(\"\\t\")\n",
    "            chrom_start_end = split_row[0]+\":\"+split_row[1]+\"-\"+split_row[2]\n",
    "            vals = np.array([float(x) for x in split_row[4:]])\n",
    "            coords_to_vals[chrom_start_end] = vals\n",
    "        self.coords_to_vals = coords_to_vals\n",
    "        \n",
    "    def _get_ndarray(self, coors):\n",
    "        to_return = []\n",
    "        for coor in coors:\n",
    "            chrom_start_end = (coor.chrom+\":\"\n",
    "                               +str(coor.start)+\"-\"+str(coor.end))\n",
    "            to_return.append(self.coords_to_vals[chrom_start_end])\n",
    "        return np.array(to_return)\n",
    "    \n",
    "    \n",
    "inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "  genome_fasta_path= '/mnt/data/annotations/by_release/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta',\n",
    "  center_size_to_use=1000)\n",
    "\n",
    "targets_coordstovals = ColsInBedFile(\n",
    "       gzipped_bed_file=\"summits_with_signal.bed.gz\")\n",
    "            \n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      #coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\", \n",
    "        batch_size=64, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\", \n",
    "        batch_size = 64, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_train_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=128,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size=128, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size = 128, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([val for batch in keras_test_batch_generator for val in batch[1]], dtype = 'float32') \n",
    "y_test_augment = np.array([val for batch in keras_test_batch_generator_augment for val in batch[1]], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool(Initializer): \n",
    "    def __call__(self, shape, dtype = None): \n",
    "        return K.constant(1/(shape[0]), shape=shape, dtype=dtype)\n",
    "\n",
    "class WeightDistConv(Conv1D): \n",
    "    def __init__(self, filters, \n",
    "                kernel_size, \n",
    "                strides =1, \n",
    "                padding = 'valid', \n",
    "                data_format = 'channels_last',\n",
    "                dilation_rate = 1, \n",
    "                activation = None, \n",
    "                use_bias = False, \n",
    "                kernel_initializer = AveragePool(), \n",
    "                bias_initializer = 'zeros', \n",
    "                kernel_regularizer = None, \n",
    "                bias_regularizer = None, \n",
    "                activity_regularizer = None, \n",
    "                kernel_constraint = None,\n",
    "                bias_constraint = None, \n",
    "                **kwargs): \n",
    "        super(WeightDistConv, self).__init__(\n",
    "            filters=filters, \n",
    "            kernel_size=kernel_size, \n",
    "            strides = strides, \n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs) \n",
    "\n",
    "\n",
    "    def build(self, input_shape): \n",
    "        self.bias = None\n",
    "        self.filters = input_shape[-1]\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (self.filters,)\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                        initializer = self.kernel_initializer, \n",
    "                                        name ='kernel',\n",
    "                                        regularizer = self.kernel_regularizer, \n",
    "                                        constraint = self.kernel_constraint)\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=3,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.num_input_channels = input_shape[1]\n",
    "        self.built = True\n",
    "       \n",
    "      \n",
    "    #Layer's logic\n",
    "    def call(self, inputs):\n",
    "        result = []\n",
    "        for x in range(self.kernel_size[0]): \n",
    "            result.append((self.kernel[x][:,None]*K.eye(self.filters))[None,:,:])\n",
    "\n",
    "        curr_kernel = K.concatenate(result, axis = 0)\n",
    "        print(\"curr kernel: \", curr_kernel)\n",
    "        outputs = K.conv1d(inputs, curr_kernel,\n",
    "                         strides=self.strides[0],\n",
    "                         padding=self.padding,\n",
    "                         data_format=self.data_format,\n",
    "                         dilation_rate=self.dilation_rate[0])\n",
    "\n",
    "        if (self.activation is not None):\n",
    "            outputs = self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "  \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = conv_utils.conv_output_length(input_length = self.num_input_channels, \n",
    "                                               filter_size = self.filters,\n",
    "                                               padding=self.padding,\n",
    "                                               stride=self.strides[0])\n",
    "        return (input_shape[0],length, self.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import numbers\n",
    "from tensorflow.python.framework import tensor_util\n",
    "def _get_noise_shape(x, noise_shape):\n",
    "  # If noise_shape is none return immediately.\n",
    "  if noise_shape is None:\n",
    "    return array_ops.shape(x)\n",
    "\n",
    "  try:\n",
    "    # Best effort to figure out the intended shape.\n",
    "    # If not possible, let the op to handle it.\n",
    "    # In eager mode exception will show up.\n",
    "    noise_shape_ = tensor_shape.as_shape(noise_shape)\n",
    "  except (TypeError, ValueError):\n",
    "    return noise_shape\n",
    "\n",
    "  if x.shape.dims is not None and len(x.shape.dims) == len(noise_shape_.dims):\n",
    "    new_dims = []\n",
    "    for i, dim in enumerate(x.shape.dims):\n",
    "      if noise_shape_.dims[i].value is None and dim.value is not None:\n",
    "        new_dims.append(dim.value)\n",
    "      else:\n",
    "        new_dims.append(noise_shape_.dims[i].value)\n",
    "    return tensor_shape.TensorShape(new_dims)\n",
    "\n",
    "  return noise_shape\n",
    "\n",
    "class MCRCDropout(Layer):\n",
    "    \"\"\"Applies MC Dropout to the input.\n",
    "       The applied noise vector is symmetric to reverse complement symmetry\n",
    "       Class structure only slightly adapted \n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    Remains active ative at test time so sampling is required\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(MCRCDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(MCRCDropout, self).build(input_shape)\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                       for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            import numpy as np\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            x = inputs\n",
    "            seed = self.seed\n",
    "            keep_prob = 1. - self.rate\n",
    "            if seed is None:\n",
    "                seed = np.random.randint(10e6)\n",
    "            # the dummy 1. works around a TF bug\n",
    "            # (float32_ref vs. float32 incompatibility)\n",
    "            x= x*1\n",
    "            name = None\n",
    "            with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "                x = ops.convert_to_tensor(x, name=\"x\")\n",
    "                if not x.dtype.is_floating:\n",
    "                    raise ValueError(\"x has to be a floating point tensor since it's going to\"\n",
    "                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n",
    "                if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "                    raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                       \"range (0, 1], got %g\" % keep_prob)\n",
    "                keep_prob = ops.convert_to_tensor(\n",
    "                             keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "                keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "                # Do nothing if we know keep_prob == 1\n",
    "                if tensor_util.constant_value(keep_prob) == 1:\n",
    "                    return x\n",
    "\n",
    "                noise_shape = _get_noise_shape(x, noise_shape)\n",
    "                # uniform [keep_prob, 1.0 + keep_prob)\n",
    "                random_tensor = keep_prob\n",
    "                random_tensor += random_ops.random_uniform(\n",
    "                noise_shape, seed=seed, dtype=x.dtype)\n",
    "               \n",
    "                # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "                binary_tensor = math_ops.floor(random_tensor)\n",
    "                dim = binary_tensor.shape[2]//2\n",
    "\n",
    "                symmetric_binary = K.concatenate(\n",
    "                    tensors = [\n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):], \n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):][::,::-1,::-1]], \n",
    "                  axis=2)\n",
    "                ret = math_ops.div(x, keep_prob) * symmetric_binary\n",
    "                \n",
    "                return ret\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate,\n",
    "                  'noise_shape': self.noise_shape,\n",
    "                  'seed': self.seed}\n",
    "        base_config = super(MCRCDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSpatialDropout1D(Dropout): \n",
    "    def __init__(self, rate,**kwargs): \n",
    "        super(RevCompSpatialDropout1D, self).__init__(rate, **kwargs)\n",
    "        self.seed = 3\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "\n",
    "    def _get_noise_shape(self, inputs): \n",
    "        input_shape = K.shape(inputs)\n",
    "        noise_shape = (input_shape[0], 1, 1, int(self.num_input_chan/2)) \n",
    "        return noise_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        self.input_len = input_shape[1]\n",
    "        super(RevCompSpatialDropout1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None): \n",
    "        inputs_fwdandrevconcat = K.concatenate(\n",
    "                tensors = [\n",
    "                    inputs[:,:,None,:int(self.num_input_chan/2)],\n",
    "                    inputs[:,:,None,int(self.num_input_chan/2):][:,:,:,::-1]],\n",
    "                axis=2)\n",
    "\n",
    "        if 0. < self.rate < 1.: \n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            def dropped_inputs(): \n",
    "                dropped = K.dropout(inputs_fwdandrevconcat,\n",
    "                                    self.rate, noise_shape, seed = self.seed)\n",
    "                dropped = K.reshape(dropped, (-1, int(self.input_len), int(self.num_input_chan)))\n",
    "                return K.concatenate(\n",
    "                    tensors = [\n",
    "                        dropped[:,:,:int(self.num_input_chan/2)],\n",
    "                        dropped[:,:,int(self.num_input_chan/2):][:,:,::-1]],\n",
    "                    axis=-1)\n",
    "\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training = training)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from sacred import Experiment, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment(\"Augment Models\", interactive = True)\n",
    "\n",
    "MODEL_DIR = \"/users/hannahgz/revcomp_experiments/sacred_runs/augment_spatial_dropout/\"\n",
    "ex.observers.append(\n",
    "    sacred.observers.FileStorageObserver.create(MODEL_DIR)\n",
    ")\n",
    "ex.captured_out_filter = utils.apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config \n",
    "def config(): \n",
    "    # Number of convolutional layers to apply\n",
    "    num_conv = 3\n",
    "    \n",
    "    # Filters \n",
    "    filters = 15\n",
    "    \n",
    "    # Kernel Size \n",
    "    kernel_size = 15 \n",
    "    \n",
    "    # Whether to add weight dist layer before conv layers \n",
    "    weight_dist = False \n",
    "    \n",
    "    # Pool Size for Max Pooling \n",
    "    pool_size = 40 \n",
    "    \n",
    "    # Strides for Max Pooling \n",
    "    strides = 40 \n",
    "    \n",
    "    # Whether to use rc layers or normal layers \n",
    "    rev_comp = False \n",
    "    \n",
    "    # Whether the model is siamese or not \n",
    "    siamese = False\n",
    "    \n",
    "    # Whether to use regular dropout \n",
    "    dropout = False \n",
    "    \n",
    "    # Whether to use RevCompSpatialDropout1D \n",
    "    spatial_dropout = False \n",
    "    \n",
    "    # Whether to use MCRCDropout \n",
    "    mc_dropout = False\n",
    "    \n",
    "    # Dropout Rate: used for all types of dropout\n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    # Type of Pooling, options are: 'max', 'avg', 'weight_dist' \n",
    "    pooling = 'max'\n",
    "    \n",
    "    # Units in dense layer \n",
    "    units = 100\n",
    "    \n",
    "    # Whether or not to use a siamese model\n",
    "    siamese = False\n",
    "    \n",
    "    #Number of epochs to train\n",
    "    num_epochs = 300\n",
    "    \n",
    "    #Patience for early stopping \n",
    "    patience = 60 \n",
    "    \n",
    "    #Training seed \n",
    "    seed_num = 1000\n",
    "    \n",
    "    #Filename for saving the model\n",
    "    filename = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def main(\n",
    "    _run, _log, num_conv, filters, kernel_size, weight_dist, pool_size, \n",
    "    strides, rev_comp, dropout, dropout_rate, spatial_dropout, \n",
    "    mc_dropout, pooling, units, augment, siamese, num_epochs, patience, \n",
    "    seed_num, filename\n",
    "):\n",
    "    seed(seed_num)\n",
    "    set_random_seed(seed_num)\n",
    "    print(keras_train_batch_generator_augment)\n",
    "#     train_batch_generator = keras_train_batch_generator\n",
    "#     test_batch_generaotr = keras_test_batch_generator\n",
    "#     print(test_batch_generator)\n",
    "#     valid_batch_generator = keras_valid_batch_generator\n",
    "\n",
    "#     if augment: \n",
    "#         train_batch_generator = keras_train_batch_generator_augment \n",
    "#         test_batch_generaotr = keras_test_batch_generator_augment\n",
    "#         valid_batch_generator = keras_valid_batch_generator_augment\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    #Convolutional layers and dropout\n",
    "    for i in range(num_conv): \n",
    "        if i > 0 and i < num_conv - 1 and weight_dist: \n",
    "            model.add(WeightDistConv(filters = filters, kernel_size = kernel_size, \n",
    "                                input_shape = keras_train_batch_generator_augment[0][0].shape[1:], padding = \"same\"))\n",
    "        if not rev_comp: \n",
    "            model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                          input_shape=keras_train_batch_generator_augment[0][0].shape[1:],\n",
    "                          padding=\"same\")) \n",
    "        else: \n",
    "            model.add(keras_genomics.layers.RevCompConv1D(filters=filters, \n",
    "                                                          kernel_size=kernel_size, \n",
    "                                                          input_shape=keras_train_batch_generator_augment[0][0].shape[1:], \n",
    "                                                          padding=\"same\"))\n",
    "        model.add(k1.core.Activation(\"relu\"))\n",
    "        \n",
    "        #Don't apply dropout before the pooling layer\n",
    "        if i != num_conv - 1: \n",
    "            if dropout: \n",
    "                model.add(k1.Dropout(dropout_rate))\n",
    "            elif spatial_dropout:\n",
    "                if rev_comp: \n",
    "                    model.add(RevCompSpatialDropout1D(dropout_rate)) \n",
    "                else: \n",
    "                    model.add(k1.SpatialDropout1D(dropout_rate))\n",
    "            elif mc_dropout: \n",
    "                model.add(MCRCDropout(dropout_rate))\n",
    "\n",
    "    #Only needed with rc model\n",
    "    if rev_comp: \n",
    "        model.add(RevCompSumPool())\n",
    "    \n",
    "    #Pooling layers\n",
    "    if pooling == 'max': \n",
    "        model.add(k1.pooling.MaxPooling1D(pool_size = pool_size,padding = \"same\", strides = strides))\n",
    "    elif pooling == 'avg':\n",
    "        model.add(k1.pooling.AveragePooling1D(pool_size = pool_size, padding = \"same\", strides = strides))\n",
    "    elif pooling == 'weight_dist':\n",
    "        model.add(WeightDistConv(filters = filters, kernel_size = kernel_size, \n",
    "                                input_shape = keras_train_batch_generator_augment[0][0].shape[1:], padding = \"same\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Fully-connected layers \n",
    "    model.add(keras_genomics.layers.core.Dense(units = units, activation = \"relu\"))\n",
    "    model.add(keras_genomics.layers.core.Dense(units = 1))  \n",
    "    \n",
    "    if siamese: \n",
    "        main_input = Input(shape=keras_train_batch_generator_augment[0][0].shape[1:])\n",
    "        rev_input = Input(shape=keras_train_batch_generator_augment[0][0].shape[1:])\n",
    "        rev_input = RevComp()(main_input)\n",
    "        main_output = model(main_input)\n",
    "        rev_output = model(rev_input)\n",
    "        avg = k1.Average()([main_output, rev_output])\n",
    "        model = Model(inputs = main_input, outputs = avg)\n",
    "\n",
    "    output_dir = os.path.join(MODEL_DIR, str(_run._id))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor = 'val_loss',\n",
    "                              patience = patience,\n",
    "                              restore_best_weights=True)\n",
    "    model.fit_generator(generator = keras_train_batch_generator_augment, \n",
    "                           epochs = num_epochs, callbacks = [early_stopping_callback],\n",
    "                           validation_data = keras_valid_batch_generator_augment)\n",
    "    model.set_weights(early_stopping_callback.best_weights)\n",
    "    \n",
    "    filename = (filename + '_%s.h5' % seed_num, str(seed_num))[0]\n",
    "    model.save(filename)\n",
    "    \n",
    "    y_pred = model.predict_generator(keras_test_batch_generator_augment)\n",
    "\n",
    "    \n",
    "    rho, pval = spearmanr(y_test_augment, y_pred)\n",
    "    print('correlation ', rho)\n",
    "    print('p-value', pval)\n",
    "    _run.log_scalar('correlation', rho)\n",
    "    _run.log_scalar('p-value', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 12:09:58.066308 140166411724544 initialize.py:192] Added new config entry: \"augment\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<seqdataloader.batchproducers.coordbased.core.KerasBatchGenerator object at 0x7f7a9385c128>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 1000, 15)          915       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1000, 15)          3390      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1000, 15)          3390      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 15)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               37600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 45,396\n",
      "Trainable params: 45,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "285/285 [==============================] - 117s 410ms/step - loss: 10058.3925 - val_loss: 10871.9746\n",
      "Epoch 2/300\n",
      "285/285 [==============================] - 114s 399ms/step - loss: 8850.4627 - val_loss: 11341.0826\n",
      "Epoch 3/300\n",
      "285/285 [==============================] - 110s 387ms/step - loss: 8737.4675 - val_loss: 11605.2702\n",
      "Epoch 4/300\n",
      "285/285 [==============================] - 112s 394ms/step - loss: 8655.3786 - val_loss: 11709.8427\n",
      "Epoch 5/300\n",
      "285/285 [==============================] - 111s 389ms/step - loss: 8627.6484 - val_loss: 10891.6618\n",
      "Epoch 6/300\n",
      "285/285 [==============================] - 109s 383ms/step - loss: 8577.3027 - val_loss: 10634.4343\n",
      "Epoch 7/300\n",
      "285/285 [==============================] - 113s 396ms/step - loss: 8536.5331 - val_loss: 10301.8067\n",
      "Epoch 8/300\n",
      "  4/285 [..............................] - ETA: 3:42 - loss: 8320.8635"
     ]
    }
   ],
   "source": [
    "ex.run(config_updates = {'augment': True, 'spatial_dropout': True, 'filename': 'augment_spatial_dropout'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.run(config_updates = {'augment': True, 'spatial_dropout': True, 'weight_dist': True, 'filename': 'augment_spatial_dropout_weight_dist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.run(config_updates = {'augment': True, 'dropout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
