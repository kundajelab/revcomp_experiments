{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kundajelab/revcomp_experiments/blob/master/CTCG_RegressionExample_Standard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyeOFCfq24Cb"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHHAxdHG3MmH"
   },
   "source": [
    "Run some stuff to set up the colab environment (won't need to do this on the cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPUF-_5X5d88"
   },
   "outputs": [],
   "source": [
    "#We want to prepare a bed file that has +/- 1kb around the summit, followed by\n",
    "# the signal strength\n",
    "! zcat peaks_with_signal.bed.gz | perl -lane 'print $F[0].\"\\t\".($F[1]+$F[9]).\"\\t\".($F[1]+$F[9]).\"\\t+\\t\".($F[6])' | egrep -w 'chr1|chr2|chr3|chr4|chr5|chr6|chr7|chr8|chr9|chr10|chr11|chr12|chr13|chr14|chr15|chr16|chr17|chr18|chr19|chr20|chr21|chr22|chrX|chrY' | gzip -c > summits_with_signal.bed.gz\n",
    "\n",
    "#We split into training/test/validation set by chromosome\n",
    "!zcat summits_with_signal.bed.gz | egrep -w 'chr1|chr8|chr21' | gzip -c > test_summits_with_signal.bed.gz\n",
    "!zcat summits_with_signal.bed.gz | egrep -w 'chr22' | gzip -c > valid_summits_with_signal.bed.gz\n",
    "!zcat summits_with_signal.bed.gz | egrep -w -v 'chr1|chr8|chr21|chr22' | gzip -c > train_summits_with_signal.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FbHhcBySQ4ZF",
    "outputId": "b8f7eb49-952c-47ed-bf44-532fc395e4aa"
   },
   "outputs": [],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "class ColsInBedFile(\n",
    "    coordbased.coordstovals.core.AbstractSingleNdarrayCoordsToVals):\n",
    "    def __init__(self, gzipped_bed_file, **kwargs):\n",
    "        super(ColsInBedFile, self).__init__(**kwargs)\n",
    "        self.gzipped_bed_file = gzipped_bed_file\n",
    "        coords_to_vals = {}\n",
    "        for row in gzip.open(gzipped_bed_file, 'rb'):\n",
    "            row = row.decode(\"utf-8\").rstrip()\n",
    "            split_row = row.split(\"\\t\")\n",
    "            chrom_start_end = split_row[0]+\":\"+split_row[1]+\"-\"+split_row[2]\n",
    "            vals = np.array([float(x) for x in split_row[4:]])\n",
    "            coords_to_vals[chrom_start_end] = vals\n",
    "        self.coords_to_vals = coords_to_vals\n",
    "        \n",
    "    def _get_ndarray(self, coors):\n",
    "        to_return = []\n",
    "        for coor in coors:\n",
    "            chrom_start_end = (coor.chrom+\":\"\n",
    "                               +str(coor.start)+\"-\"+str(coor.end))\n",
    "            to_return.append(self.coords_to_vals[chrom_start_end])\n",
    "        return np.array(to_return)\n",
    "    \n",
    "    \n",
    "inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "  genome_fasta_path= '/mnt/data/annotations/by_release/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta',\n",
    "  center_size_to_use=1000)\n",
    "\n",
    "targets_coordstovals = ColsInBedFile(\n",
    "       gzipped_bed_file=\"summits_with_signal.bed.gz\")\n",
    "            \n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      #coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\", \n",
    "        batch_size=64, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\", \n",
    "        batch_size = 64, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_train_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=128,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size=128, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size = 128, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLg6RrQU5Cs5"
   },
   "outputs": [],
   "source": [
    "y_test = np.array([val for batch in keras_test_batch_generator for val in batch[1]], dtype = 'float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PfxbH31FCTad",
    "outputId": "0ddc683f-56ed-43ef-efb7-638e33c6bcab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simdna from git+https://github.com/kundajelab/simdna.git@v0.4.3.1#egg=simdna\n",
      "  Cloning https://github.com/kundajelab/simdna.git (to revision v0.4.3.1) to /tmp/pip-install-e0uvt34p/simdna\n",
      "  Running command git clone -q https://github.com/kundajelab/simdna.git /tmp/pip-install-e0uvt34p/simdna\n",
      "  Running command git checkout -q ab8ff979761fa4bd307e2d75a87c1da258a9f743\n",
      "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from simdna) (1.16.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from simdna) (3.0.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simdna) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->simdna) (41.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->simdna) (1.12.0)\n",
      "Building wheels for collected packages: simdna\n",
      "  Building wheel for simdna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5pg_b1k9/wheels/d7/dd/b9/c0544822379aa265750e5c8e5e164435e70f9346cdac4516b4\n",
      "Successfully built simdna\n",
      "Installing collected packages: simdna\n",
      "Successfully installed simdna-0.4.3.1\n",
      "Cloning into 'revcomp_experiments'...\n",
      "remote: Enumerating objects: 1378, done.\u001b[K\n",
      "remote: Total 1378 (delta 0), reused 0 (delta 0), pack-reused 1378\u001b[K\n",
      "Receiving objects: 100% (1378/1378), 521.43 MiB | 27.72 MiB/s, done.\n",
      "Resolving deltas: 100% (308/308), done.\n",
      "Checking out files: 100% (1201/1201), done.\n",
      "/content/revcomp_experiments\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating revcompexp.egg-info\n",
      "writing revcompexp.egg-info/PKG-INFO\n",
      "writing dependency_links to revcompexp.egg-info/dependency_links.txt\n",
      "writing requirements to revcompexp.egg-info/requires.txt\n",
      "writing top-level names to revcompexp.egg-info/top_level.txt\n",
      "writing manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "writing manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "running install_scripts\n",
      "running build_scripts\n",
      "creating build/scripts-3.6\n",
      "copying and adjusting scripts/motif_density_and_position_sim.py -> build/scripts-3.6\n",
      "changing mode of build/scripts-3.6/motif_density_and_position_sim.py from 644 to 755\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "copying build/scripts-3.6/motif_density_and_position_sim.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/motif_density_and_position_sim.py to 755\n",
      "copying revcompexp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/revcompexp-0.1.0.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing revcompexp-0.1.0.0-py3.6.egg\n",
      "Copying revcompexp-0.1.0.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding revcompexp 0.1.0.0 to easy-install.pth file\n",
      "Installing motif_density_and_position_sim.py script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/revcompexp-0.1.0.0-py3.6.egg\n",
      "Processing dependencies for revcompexp==0.1.0.0\n",
      "Searching for scipy==1.3.0\n",
      "Best match: scipy 1.3.0\n",
      "Adding scipy 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for matplotlib==3.0.3\n",
      "Best match: matplotlib 3.0.3\n",
      "Adding matplotlib 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for numpy==1.16.4\n",
      "Best match: numpy 1.16.4\n",
      "Adding numpy 1.16.4 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for simdna==0.4.3.1\n",
      "Best match: simdna 0.4.3.1\n",
      "Adding simdna 0.4.3.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for python-dateutil==2.5.3\n",
      "Best match: python-dateutil 2.5.3\n",
      "Adding python-dateutil 2.5.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for pyparsing==2.4.0\n",
      "Best match: pyparsing 2.4.0\n",
      "Adding pyparsing 2.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for kiwisolver==1.1.0\n",
      "Best match: kiwisolver 1.1.0\n",
      "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for setuptools==41.0.1\n",
      "Best match: setuptools 41.0.1\n",
      "Adding setuptools 41.0.1 to easy-install.pth file\n",
      "Installing easy_install script to /usr/local/bin\n",
      "Installing easy_install-3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Finished processing dependencies for revcompexp==0.1.0.0\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kundajelab/simdna.git@v0.4.3.1#egg=simdna\n",
    "!git clone https://github.com/kundajelab/revcomp_experiments.git\n",
    "%cd revcomp_experiments/\n",
    "!python setup.py install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import numbers\n",
    "from tensorflow.python.framework import tensor_util\n",
    "def _get_noise_shape(x, noise_shape):\n",
    "  # If noise_shape is none return immediately.\n",
    "  if noise_shape is None:\n",
    "    return array_ops.shape(x)\n",
    "\n",
    "  try:\n",
    "    # Best effort to figure out the intended shape.\n",
    "    # If not possible, let the op to handle it.\n",
    "    # In eager mode exception will show up.\n",
    "    noise_shape_ = tensor_shape.as_shape(noise_shape)\n",
    "  except (TypeError, ValueError):\n",
    "    return noise_shape\n",
    "\n",
    "  if x.shape.dims is not None and len(x.shape.dims) == len(noise_shape_.dims):\n",
    "    new_dims = []\n",
    "    for i, dim in enumerate(x.shape.dims):\n",
    "      if noise_shape_.dims[i].value is None and dim.value is not None:\n",
    "        new_dims.append(dim.value)\n",
    "      else:\n",
    "        new_dims.append(noise_shape_.dims[i].value)\n",
    "    return tensor_shape.TensorShape(new_dims)\n",
    "\n",
    "  return noise_shape\n",
    "\n",
    "class MCRCDropout(Layer):\n",
    "    \"\"\"Applies MC Dropout to the input.\n",
    "       The applied noise vector is symmetric to reverse complement symmetry\n",
    "       Class structure only slightly adapted \n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    Remains active ative at test time so sampling is required\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(MCRCDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(MCRCDropout, self).build(input_shape)\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                       for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            import numpy as np\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            x = inputs\n",
    "            seed = self.seed\n",
    "            keep_prob = 1. - self.rate\n",
    "            if seed is None:\n",
    "                seed = np.random.randint(10e6)\n",
    "            # the dummy 1. works around a TF bug\n",
    "            # (float32_ref vs. float32 incompatibility)\n",
    "            x= x*1\n",
    "            name = None\n",
    "            with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "                x = ops.convert_to_tensor(x, name=\"x\")\n",
    "                if not x.dtype.is_floating:\n",
    "                    raise ValueError(\"x has to be a floating point tensor since it's going to\"\n",
    "                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n",
    "                if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "                    raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                       \"range (0, 1], got %g\" % keep_prob)\n",
    "                keep_prob = ops.convert_to_tensor(\n",
    "                             keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "                keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "                # Do nothing if we know keep_prob == 1\n",
    "                if tensor_util.constant_value(keep_prob) == 1:\n",
    "                    return x\n",
    "\n",
    "                noise_shape = _get_noise_shape(x, noise_shape)\n",
    "                # uniform [keep_prob, 1.0 + keep_prob)\n",
    "                random_tensor = keep_prob\n",
    "                random_tensor += random_ops.random_uniform(\n",
    "                noise_shape, seed=seed, dtype=x.dtype)\n",
    "               \n",
    "                # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "                binary_tensor = math_ops.floor(random_tensor)\n",
    "                dim = binary_tensor.shape[2]//2\n",
    "\n",
    "                symmetric_binary = K.concatenate(\n",
    "                    tensors = [\n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):], \n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):][::,::-1,::-1]], \n",
    "                  axis=2)\n",
    "                ret = math_ops.div(x, keep_prob) * symmetric_binary\n",
    "                \n",
    "                return ret\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate,\n",
    "                  'noise_shape': self.noise_shape,\n",
    "                  'seed': self.seed}\n",
    "        base_config = super(MCRCDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSpatialDropout1D(Dropout): \n",
    "    def __init__(self, rate,**kwargs): \n",
    "        super(RevCompSpatialDropout1D, self).__init__(rate, **kwargs)\n",
    "        self.seed = 3\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "\n",
    "    def _get_noise_shape(self, inputs): \n",
    "        input_shape = K.shape(inputs)\n",
    "        noise_shape = (input_shape[0], 1, 1, int(self.num_input_chan/2)) \n",
    "        return noise_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        self.input_len = input_shape[1]\n",
    "        super(RevCompSpatialDropout1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None): \n",
    "        inputs_fwdandrevconcat = K.concatenate(\n",
    "                tensors = [\n",
    "                    inputs[:,:,None,:int(self.num_input_chan/2)],\n",
    "                    inputs[:,:,None,int(self.num_input_chan/2):][:,:,:,::-1]],\n",
    "                axis=2)\n",
    "\n",
    "        if 0. < self.rate < 1.: \n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            def dropped_inputs(): \n",
    "                dropped = K.dropout(inputs_fwdandrevconcat,\n",
    "                                    self.rate, noise_shape, seed = self.seed)\n",
    "                dropped = K.reshape(dropped, (-1, int(self.input_len), int(self.num_input_chan)))\n",
    "                return K.concatenate(\n",
    "                    tensors = [\n",
    "                        dropped[:,:,:int(self.num_input_chan/2)],\n",
    "                        dropped[:,:,int(self.num_input_chan/2):][:,:,::-1]],\n",
    "                    axis=-1)\n",
    "\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training = training)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4nWT9znDNFg"
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "import keras_genomics\n",
    "import numpy as np\n",
    "import keras.layers as k1\n",
    "import simdna\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrcj_JuUEBqa"
   },
   "outputs": [],
   "source": [
    "kernel_size = 15\n",
    "filters= 15\n",
    "input_length = 1000\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "\n",
    "seed_num = 1000\n",
    "seed(seed_num)\n",
    "set_random_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "DRZ4kapcAdTn",
    "outputId": "c6cbb268-4268-43c4-fda4-d9091cb6ed73"
   },
   "outputs": [],
   "source": [
    "scale = 1.0\n",
    "\n",
    "reg_model = keras.models.Sequential()\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        input_shape=keras_train_batch_generator[0][0].shape[1:],\n",
    "                        padding=\"same\"))\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "# reg_model.add(k1.Dropout(0.2))\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "# reg_model.add(k1.Dropout(0.2))\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "reg_model.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\",\n",
    "                                               strides=40))\n",
    "reg_model.add(Flatten())\n",
    "reg_model.add(k1.Dense(units = 100, activation = \"relu\"))\n",
    "reg_model.add(k1.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 9142.7943 - val_loss: 10202.9160\n",
      "Epoch 2/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 8629.8014 - val_loss: 10131.3871\n",
      "Epoch 3/300\n",
      "570/570 [==============================] - 28s 50ms/step - loss: 8620.2255 - val_loss: 10077.9938\n",
      "Epoch 4/300\n",
      "570/570 [==============================] - 29s 51ms/step - loss: 8541.9243 - val_loss: 9905.9050\n",
      "Epoch 5/300\n",
      "570/570 [==============================] - 35s 62ms/step - loss: 7620.2680 - val_loss: 7625.9957\n",
      "Epoch 6/300\n",
      "570/570 [==============================] - 32s 57ms/step - loss: 6461.0789 - val_loss: 7045.0124\n",
      "Epoch 7/300\n",
      "570/570 [==============================] - 31s 54ms/step - loss: 6012.0077 - val_loss: 6577.6624\n",
      "Epoch 8/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 5746.5841 - val_loss: 6448.6490\n",
      "Epoch 9/300\n",
      "570/570 [==============================] - 35s 61ms/step - loss: 5499.3372 - val_loss: 6795.1595\n",
      "Epoch 10/300\n",
      "570/570 [==============================] - 29s 51ms/step - loss: 5345.6607 - val_loss: 6129.9684\n",
      "Epoch 11/300\n",
      "570/570 [==============================] - 33s 59ms/step - loss: 5215.1268 - val_loss: 5983.5345\n",
      "Epoch 12/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 5074.4213 - val_loss: 5858.0310\n",
      "Epoch 13/300\n",
      "570/570 [==============================] - 30s 53ms/step - loss: 4992.4384 - val_loss: 5785.9168\n",
      "Epoch 14/300\n",
      "570/570 [==============================] - 28s 50ms/step - loss: 4866.2688 - val_loss: 5820.9246\n",
      "Epoch 15/300\n",
      "570/570 [==============================] - 29s 50ms/step - loss: 4796.9926 - val_loss: 5646.2950\n",
      "Epoch 16/300\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 4715.3897 - val_loss: 5787.9709\n",
      "Epoch 17/300\n",
      "570/570 [==============================] - 30s 53ms/step - loss: 4638.9354 - val_loss: 5986.8779\n",
      "Epoch 18/300\n",
      "570/570 [==============================] - 29s 51ms/step - loss: 4559.4616 - val_loss: 5722.3986\n",
      "Epoch 19/300\n",
      "570/570 [==============================] - 31s 54ms/step - loss: 4488.0260 - val_loss: 5847.0915\n",
      "Epoch 20/300\n",
      "570/570 [==============================] - 28s 50ms/step - loss: 4401.6565 - val_loss: 5735.2333\n",
      "Epoch 21/300\n",
      "570/570 [==============================] - 30s 53ms/step - loss: 4367.5602 - val_loss: 5784.2001\n",
      "Epoch 22/300\n",
      "570/570 [==============================] - 30s 53ms/step - loss: 4263.6695 - val_loss: 5864.6019\n",
      "Epoch 23/300\n",
      "570/570 [==============================] - 29s 50ms/step - loss: 4237.6523 - val_loss: 5807.6409\n",
      "Epoch 24/300\n",
      "570/570 [==============================] - 30s 52ms/step - loss: 4148.9790 - val_loss: 5885.5666\n",
      "Epoch 25/300\n",
      "570/570 [==============================] - 36s 63ms/step - loss: 4117.5155 - val_loss: 5898.8871\n",
      "Epoch 26/300\n",
      "570/570 [==============================] - 35s 61ms/step - loss: 4044.0474 - val_loss: 5912.1738\n",
      "Epoch 27/300\n",
      "570/570 [==============================] - 33s 58ms/step - loss: 3995.9430 - val_loss: 5980.6518\n",
      "Epoch 28/300\n",
      "570/570 [==============================] - 36s 63ms/step - loss: 3921.8276 - val_loss: 5826.8620\n",
      "Epoch 29/300\n",
      "570/570 [==============================] - 31s 54ms/step - loss: 3881.3745 - val_loss: 5867.8274\n",
      "Epoch 30/300\n",
      "570/570 [==============================] - 28s 50ms/step - loss: 3852.0942 - val_loss: 5884.1166\n",
      "Epoch 31/300\n",
      "570/570 [==============================] - 30s 53ms/step - loss: 3765.1169 - val_loss: 5958.8076\n",
      "Epoch 32/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 3720.5185 - val_loss: 5925.3922\n",
      "Epoch 33/300\n",
      "570/570 [==============================] - 34s 60ms/step - loss: 3662.9929 - val_loss: 6099.9799\n",
      "Epoch 34/300\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 3611.8069 - val_loss: 5913.7450\n",
      "Epoch 35/300\n",
      "570/570 [==============================] - 32s 57ms/step - loss: 3565.2837 - val_loss: 6092.1061\n",
      "Epoch 36/300\n",
      "570/570 [==============================] - 35s 62ms/step - loss: 3524.4174 - val_loss: 6089.4277\n",
      "Epoch 37/300\n",
      "570/570 [==============================] - 29s 51ms/step - loss: 3487.1452 - val_loss: 6079.0780\n",
      "Epoch 38/300\n",
      "570/570 [==============================] - 29s 51ms/step - loss: 3442.4036 - val_loss: 6582.3529\n",
      "Epoch 39/300\n",
      "570/570 [==============================] - 38s 67ms/step - loss: 3407.7257 - val_loss: 6200.0400\n",
      "Epoch 40/300\n",
      "570/570 [==============================] - 32s 56ms/step - loss: 3353.6705 - val_loss: 6288.5768\n",
      "Epoch 41/300\n",
      "570/570 [==============================] - 31s 54ms/step - loss: 3307.4313 - val_loss: 6251.4081\n",
      "Epoch 42/300\n",
      "570/570 [==============================] - 33s 58ms/step - loss: 3257.1306 - val_loss: 6227.9047\n",
      "Epoch 43/300\n",
      "173/570 [========>.....................] - ETA: 24s - loss: 3200.4606"
     ]
    }
   ],
   "source": [
    "reg_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 60,\n",
    "                              restore_best_weights=True)\n",
    "history_reg = reg_model.fit_generator(generator=keras_train_batch_generator, \n",
    "                                      epochs=300, callbacks =[early_stopping_callback], \n",
    "                                      validation_data=keras_valid_batch_generator)\n",
    "reg_model.set_weights(early_stopping_callback.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_filename = ('reg_no_dropout_%s.h5' % seed_num, str(seed_num))[0]\n",
    "reg_model.save(reg_filename)\n",
    "reg_model_final = load_model(reg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_model = keras.models.Sequential()\n",
    "augment_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        input_shape=keras_train_batch_generator_augment[0][0].shape[1:], padding=\"same\"))\n",
    "augment_model.add(k1.core.Activation(\"relu\"))\n",
    "# augment_model.add(k1.Dropout(0.2))\n",
    "augment_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "augment_model.add(k1.core.Activation(\"relu\"))\n",
    "# augment_model.add(k1.Dropout(0.2))\n",
    "augment_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "augment_model.add(k1.core.Activation(\"relu\"))\n",
    "augment_model.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\",\n",
    "                                               strides=40))\n",
    "augment_model.add(Flatten())\n",
    "augment_model.add(k1.Dense(units = 100, activation = \"relu\"))\n",
    "augment_model.add(k1.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 60,\n",
    "                              restore_best_weights=True)\n",
    "history_aug = augment_model.fit_generator(generator=keras_train_batch_generator_augment, \n",
    "                                      epochs=300, callbacks =[early_stopping_callback], \n",
    "                                      validation_data=keras_valid_batch_generator_augment)\n",
    "augment_model.set_weights(early_stopping_callback.best_weights)\n",
    "augment_filename = ('augment_no_dropout_%s.h5' % seed_num, str(seed_num))[0]\n",
    "augment_model.save(augment_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0YzKxPmkKk_"
   },
   "outputs": [],
   "source": [
    "rc_model_standard_mcdropout = keras.models.Sequential()\n",
    "rc_model_standard_mcdropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, \n",
    "            input_shape=keras_train_batch_generator[0][0].shape[1:], padding=\"same\"))\n",
    "rc_model_standard_mcdropout.add(k1.core.Activation(\"relu\"))\n",
    "# rc_model_standard_mcdropout.add(MCRCDropout(0.2))\n",
    "rc_model_standard_mcdropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, padding=\"same\"))\n",
    "rc_model_standard_mcdropout.add(k1.core.Activation(\"relu\"))\n",
    "# rc_model_standard_mcdropout.add(MCRCDropout(0.2))\n",
    "rc_model_standard_mcdropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size,padding=\"same\"))\n",
    "rc_model_standard_mcdropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_mcdropout.add(RevCompSumPool())\n",
    "rc_model_standard_mcdropout.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\", strides=40))\n",
    "rc_model_standard_mcdropout.add(Flatten())\n",
    "rc_model_standard_mcdropout.add(keras_genomics.layers.core.Dense(units = 100, activation = \"relu\"))\n",
    "rc_model_standard_mcdropout.add(keras_genomics.layers.core.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_model_standard_mcdropout.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 60,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "history_rc_standard_mcdropout = rc_model_standard_mcdropout.fit_generator(generator=keras_train_batch_generator, \n",
    "                                                      epochs=300, callbacks = [early_stopping_callback],\n",
    "                                                     validation_data=keras_valid_batch_generator)\n",
    "    \n",
    "rc_model_standard_mcdropout.set_weights(early_stopping_callback.best_weights)\n",
    "rc_standard_filename_mcdropout = ('rc_standard_no_dropout_%s.h5' % seed_num, str(seed_num))[0]\n",
    "rc_model_standard_mcdropout.save(rc_standard_filename_mcdropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_model_standard_spatial_dropout = keras.models.Sequential()\n",
    "rc_model_standard_spatial_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, \n",
    "            input_shape=keras_train_batch_generator[0][0].shape[1:], padding=\"same\"))\n",
    "rc_model_standard_spatial_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_spatial_dropout.add(RevCompSpatialDropout1D(0.2))\n",
    "rc_model_standard_spatial_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, padding=\"same\"))\n",
    "rc_model_standard_spatial_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_spatial_dropout.add(RevCompSpatialDropout1D(0.2))\n",
    "rc_model_standard_spatial_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size,padding=\"same\"))\n",
    "rc_model_standard_spatial_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_spatial_dropout.add(RevCompSumPool())\n",
    "rc_model_standard_spatial_dropout.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\", strides=40))\n",
    "rc_model_standard_spatial_dropout.add(Flatten())\n",
    "rc_model_standard_spatial_dropout.add(keras_genomics.layers.core.Dense(units = 100, activation = \"relu\"))\n",
    "rc_model_standard_spatial_dropout.add(keras_genomics.layers.core.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_model_standard_spatial_dropout.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 60,\n",
    "                              restore_best_weights=True)\n",
    "history_rc_spatial_dropout = rc_model_standard_spatial_dropout.fit_generator(generator=keras_train_batch_generator, \n",
    "                                                      epochs=300, callbacks = [early_stopping_callback],\n",
    "                                                     validation_data=keras_valid_batch_generator)\n",
    "    \n",
    "rc_model_standard_spatial_dropout.set_weights(early_stopping_callback.best_weights)\n",
    "rc_standard_filename_spatial_dropout = ('rc_standard_spatial_dropout_%s.h5' % seed_num, str(seed_num))[0]\n",
    "rc_model_standard_spatial_dropout.save(rc_standard_filename_spatial_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_model_standard_dropout = keras.models.Sequential()\n",
    "rc_model_standard_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, \n",
    "            input_shape=keras_train_batch_generator[0][0].shape[1:], padding=\"same\"))\n",
    "rc_model_standard_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_dropout.add(k1.Dropout(0.2))\n",
    "rc_model_standard_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, padding=\"same\"))\n",
    "rc_model_standard_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_dropout.add(k1.Dropout(0.2))\n",
    "rc_model_standard_dropout.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size,padding=\"same\"))\n",
    "rc_model_standard_dropout.add(k1.core.Activation(\"relu\"))\n",
    "rc_model_standard_dropout.add(RevCompSumPool())\n",
    "rc_model_standard_dropout.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\", strides=40))\n",
    "rc_model_standard_dropout.add(Flatten())\n",
    "rc_model_standard_dropout.add(keras_genomics.layers.core.Dense(units = 100, activation = \"relu\"))\n",
    "rc_model_standard_dropout.add(keras_genomics.layers.core.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_model_standard_dropout.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 60,\n",
    "                              restore_best_weights=True)\n",
    "history_rc_dropout = rc_model_standard_dropout.fit_generator(generator=keras_train_batch_generator, \n",
    "                                                      epochs=300, callbacks = [early_stopping_callback],\n",
    "                                                     validation_data=keras_valid_batch_generator)\n",
    "    \n",
    "rc_model_standard_dropout.set_weights(early_stopping_callback.best_weights)\n",
    "rc_standard_filename_dropout = ('rc_standard_dropout_%s.h5' % seed_num, str(seed_num))[0]\n",
    "rc_model_standard_dropout.save(rc_standard_filename_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CTCG_RegressionExample_Standard.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
