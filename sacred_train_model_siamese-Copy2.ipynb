{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import sacred\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "from sacred import Ingredient\n",
    "\n",
    "import keras \n",
    "import keras_genomics\n",
    "import keras.layers as k1\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import Input\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.initializers import Initializer\n",
    "from keras.utils import conv_utils\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "class ColsInBedFile(\n",
    "    coordbased.coordstovals.core.AbstractSingleNdarrayCoordsToVals):\n",
    "    def __init__(self, gzipped_bed_file, **kwargs):\n",
    "        super(ColsInBedFile, self).__init__(**kwargs)\n",
    "        self.gzipped_bed_file = gzipped_bed_file\n",
    "        coords_to_vals = {}\n",
    "        for row in gzip.open(gzipped_bed_file, 'rb'):\n",
    "            row = row.decode(\"utf-8\").rstrip()\n",
    "            split_row = row.split(\"\\t\")\n",
    "            chrom_start_end = split_row[0]+\":\"+split_row[1]+\"-\"+split_row[2]\n",
    "            vals = np.array([float(x) for x in split_row[4:]])\n",
    "            coords_to_vals[chrom_start_end] = vals\n",
    "        self.coords_to_vals = coords_to_vals\n",
    "        \n",
    "    def _get_ndarray(self, coors):\n",
    "        to_return = []\n",
    "        for coor in coors:\n",
    "            chrom_start_end = (coor.chrom+\":\"\n",
    "                               +str(coor.start)+\"-\"+str(coor.end))\n",
    "            to_return.append(self.coords_to_vals[chrom_start_end])\n",
    "        return np.array(to_return)\n",
    "    \n",
    "    \n",
    "inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "  genome_fasta_path= '/mnt/data/annotations/by_release/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta',\n",
    "  center_size_to_use=1000)\n",
    "\n",
    "targets_coordstovals = ColsInBedFile(\n",
    "       gzipped_bed_file=\"summits_with_signal.bed.gz\")\n",
    "            \n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      #coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\", \n",
    "        batch_size=64, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\", \n",
    "        batch_size = 64, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_train_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal.bed.gz\",\n",
    "      coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=128,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size=128, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size = 128, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([val for batch in keras_test_batch_generator for val in batch[1]], dtype = 'float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool(Initializer): \n",
    "    def __call__(self, shape, dtype = None): \n",
    "        print(shape[0])\n",
    "        return K.constant(1/(shape[0]), shape=shape, dtype=dtype)\n",
    "\n",
    "class WeightDistConv(Conv1D): \n",
    "    def __init__(self, filters, \n",
    "                kernel_size, \n",
    "                strides =1, \n",
    "                padding = 'valid', \n",
    "                data_format = 'channels_last',\n",
    "                dilation_rate = 1, \n",
    "                activation = None, \n",
    "                use_bias = False, \n",
    "                kernel_initializer = AveragePool(), \n",
    "                bias_initializer = 'zeros', \n",
    "                kernel_regularizer = None, \n",
    "                bias_regularizer = None, \n",
    "                activity_regularizer = None, \n",
    "                kernel_constraint = None,\n",
    "                bias_constraint = None, \n",
    "                **kwargs): \n",
    "        super(WeightDistConv, self).__init__(\n",
    "            filters=filters, \n",
    "            kernel_size=kernel_size, \n",
    "            strides = strides, \n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs) \n",
    "\n",
    "\n",
    "    def build(self, input_shape): \n",
    "        self.bias = None\n",
    "        self.filters = input_shape[-1]\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (self.filters,)\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                        initializer = self.kernel_initializer, \n",
    "                                        name ='kernel',\n",
    "                                        regularizer = self.kernel_regularizer, \n",
    "                                        constraint = self.kernel_constraint)\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=3,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.num_input_channels = input_shape[1]\n",
    "        self.built = True\n",
    "       \n",
    "      \n",
    "    #Layer's logic\n",
    "    def call(self, inputs):\n",
    "        result = []\n",
    "        for x in range(self.kernel_size[0]): \n",
    "            result.append((self.kernel[x][:,None]*K.eye(self.filters))[None,:,:])\n",
    "\n",
    "        curr_kernel = K.concatenate(result, axis = 0)\n",
    "        print(\"curr kernel: \", curr_kernel)\n",
    "        outputs = K.conv1d(inputs, curr_kernel,\n",
    "                         strides=self.strides[0],\n",
    "                         padding=self.padding,\n",
    "                         data_format=self.data_format,\n",
    "                         dilation_rate=self.dilation_rate[0])\n",
    "\n",
    "        if (self.activation is not None):\n",
    "            outputs = self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "  \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = conv_utils.conv_output_length(input_length = self.num_input_channels, \n",
    "                                               filter_size = self.filters,\n",
    "                                               padding=self.padding,\n",
    "                                               stride=self.strides[0])\n",
    "        return (input_shape[0],length, self.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import numbers\n",
    "from tensorflow.python.framework import tensor_util\n",
    "def _get_noise_shape(x, noise_shape):\n",
    "  # If noise_shape is none return immediately.\n",
    "  if noise_shape is None:\n",
    "    return array_ops.shape(x)\n",
    "\n",
    "  try:\n",
    "    # Best effort to figure out the intended shape.\n",
    "    # If not possible, let the op to handle it.\n",
    "    # In eager mode exception will show up.\n",
    "    noise_shape_ = tensor_shape.as_shape(noise_shape)\n",
    "  except (TypeError, ValueError):\n",
    "    return noise_shape\n",
    "\n",
    "  if x.shape.dims is not None and len(x.shape.dims) == len(noise_shape_.dims):\n",
    "    new_dims = []\n",
    "    for i, dim in enumerate(x.shape.dims):\n",
    "      if noise_shape_.dims[i].value is None and dim.value is not None:\n",
    "        new_dims.append(dim.value)\n",
    "      else:\n",
    "        new_dims.append(noise_shape_.dims[i].value)\n",
    "    return tensor_shape.TensorShape(new_dims)\n",
    "\n",
    "  return noise_shape\n",
    "\n",
    "class MCRCDropout(Layer):\n",
    "    \"\"\"Applies MC Dropout to the input.\n",
    "       The applied noise vector is symmetric to reverse complement symmetry\n",
    "       Class structure only slightly adapted \n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    Remains active ative at test time so sampling is required\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(MCRCDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(MCRCDropout, self).build(input_shape)\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                       for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            import numpy as np\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            x = inputs\n",
    "            seed = self.seed\n",
    "            keep_prob = 1. - self.rate\n",
    "            if seed is None:\n",
    "                seed = np.random.randint(10e6)\n",
    "            # the dummy 1. works around a TF bug\n",
    "            # (float32_ref vs. float32 incompatibility)\n",
    "            x= x*1\n",
    "            name = None\n",
    "            with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "                x = ops.convert_to_tensor(x, name=\"x\")\n",
    "                if not x.dtype.is_floating:\n",
    "                    raise ValueError(\"x has to be a floating point tensor since it's going to\"\n",
    "                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n",
    "                if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "                    raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                       \"range (0, 1], got %g\" % keep_prob)\n",
    "                keep_prob = ops.convert_to_tensor(\n",
    "                             keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "                keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "                # Do nothing if we know keep_prob == 1\n",
    "                if tensor_util.constant_value(keep_prob) == 1:\n",
    "                    return x\n",
    "\n",
    "                noise_shape = _get_noise_shape(x, noise_shape)\n",
    "                # uniform [keep_prob, 1.0 + keep_prob)\n",
    "                random_tensor = keep_prob\n",
    "                random_tensor += random_ops.random_uniform(\n",
    "                noise_shape, seed=seed, dtype=x.dtype)\n",
    "               \n",
    "                # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "                binary_tensor = math_ops.floor(random_tensor)\n",
    "                dim = binary_tensor.shape[2]//2\n",
    "\n",
    "                symmetric_binary = K.concatenate(\n",
    "                    tensors = [\n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):], \n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):][::,::-1,::-1]], \n",
    "                  axis=2)\n",
    "                ret = math_ops.div(x, keep_prob) * symmetric_binary\n",
    "                \n",
    "                return ret\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate,\n",
    "                  'noise_shape': self.noise_shape,\n",
    "                  'seed': self.seed}\n",
    "        base_config = super(MCRCDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSpatialDropout1D(Dropout): \n",
    "    def __init__(self, rate,**kwargs): \n",
    "        super(RevCompSpatialDropout1D, self).__init__(rate, **kwargs)\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "\n",
    "    def _get_noise_shape(self, inputs): \n",
    "        input_shape = K.shape(inputs)\n",
    "        noise_shape = (input_shape[0], 1, 1, int(self.num_input_chan/2)) \n",
    "        return noise_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        self.input_len = input_shape[1]\n",
    "        super(RevCompSpatialDropout1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None): \n",
    "        inputs_fwdandrevconcat = K.concatenate(\n",
    "                tensors = [\n",
    "                    inputs[:,:,None,:int(self.num_input_chan/2)],\n",
    "                    inputs[:,:,None,int(self.num_input_chan/2):][:,:,:,::-1]],\n",
    "                axis=2)\n",
    "\n",
    "        if 0. < self.rate < 1.: \n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            def dropped_inputs(): \n",
    "                dropped = K.dropout(inputs_fwdandrevconcat,\n",
    "                                    self.rate, noise_shape, seed = self.seed)\n",
    "                dropped = K.reshape(dropped, (-1, int(self.input_len), int(self.num_input_chan)))\n",
    "                return K.concatenate(\n",
    "                    tensors = [\n",
    "                        dropped[:,:,:int(self.num_input_chan/2)],\n",
    "                        dropped[:,:,int(self.num_input_chan/2):][:,:,::-1]],\n",
    "                    axis=-1)\n",
    "\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training = training)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevComp(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevComp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(RevComp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        return inputs[:,::-1,::-1]\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from sacred import Experiment, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment(\"New Weight Dist Model\", interactive = True)\n",
    "\n",
    "# MODEL_DIR = \"/users/hannahgz/revcomp_experiments/sacred_runs/siamese_models/Seed_3000/\"\n",
    "# ex.observers.append(\n",
    "#     sacred.observers.FileStorageObserver.create(MODEL_DIR)\n",
    "# )\n",
    "# ex.captured_out_filter = utils.apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config \n",
    "def config(): \n",
    "    # Number of convolutional layers to apply\n",
    "    num_conv = 3\n",
    "    \n",
    "    # Filters \n",
    "    filters = 15\n",
    "    \n",
    "    # Kernel Size \n",
    "    kernel_size = 15 \n",
    "    \n",
    "    # Whether to add weight dist layer before conv layers \n",
    "    weight_dist = False \n",
    "    \n",
    "    #Weight dist filters \n",
    "    weight_dist_filters = 15\n",
    "    \n",
    "    #Weight dist kernel_size \n",
    "    weight_dist_kernel_size = 40\n",
    "    \n",
    "    # Pool Size for Pooling \n",
    "    pool_size = 40 \n",
    "    \n",
    "    # Strides for Max Pooling \n",
    "    strides = 40 \n",
    "    \n",
    "    # Whether to use rc layers or normal layers \n",
    "    rev_comp = False \n",
    "    \n",
    "    # Whether the model uses augmented data \n",
    "    augment = False\n",
    "    \n",
    "    # Whether the model is siamese or not \n",
    "    siamese = False\n",
    "    \n",
    "    # Whether to use regular dropout \n",
    "    dropout = False \n",
    "    \n",
    "    # Whether to use RevCompSpatialDropout1D \n",
    "    spatial_dropout = False \n",
    "    \n",
    "    # Whether to use MCRCDropout \n",
    "    mc_dropout = False\n",
    "    \n",
    "    # Dropout Rate: used for all types of dropout\n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    # Type of Pooling, options are: 'max', 'avg', 'weight_dist' \n",
    "    pooling = 'max'\n",
    "    \n",
    "    # Units in dense layer \n",
    "    units = 100\n",
    "    \n",
    "    # Whether or not to use a siamese model\n",
    "    siamese = False\n",
    "    \n",
    "    #Number of epochs to train\n",
    "    num_epochs = 300\n",
    "    \n",
    "    #Patience for early stopping \n",
    "    patience = 60 \n",
    "    \n",
    "    #Training seed \n",
    "    seed_num = 3000\n",
    "    \n",
    "    #Filename for saving the model\n",
    "    filename = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def main(\n",
    "    _run, _log, num_conv, filters, kernel_size, weight_dist_filters,\n",
    "    weight_dist_kernel_size, weight_dist, pool_size, strides, rev_comp, \n",
    "    dropout, dropout_rate, spatial_dropout, mc_dropout, pooling, \n",
    "    units, augment, siamese, num_epochs, patience, seed_num, filename\n",
    "):\n",
    "    seed(seed_num)\n",
    "    set_random_seed(seed_num)\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    #Convolutional layers and dropout\n",
    "    for i in range(num_conv): \n",
    "        if i == (num_conv - 1) and weight_dist: \n",
    "            model.add(WeightDistConv(filters = weight_dist_filters, kernel_size = weight_dist_kernel_size, \n",
    "                                input_shape = keras_train_batch_generator[0][0].shape[1:], padding = \"same\"))\n",
    "        if not rev_comp: \n",
    "            model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                          input_shape=keras_train_batch_generator[0][0].shape[1:],\n",
    "                          padding=\"same\")) \n",
    "        else: \n",
    "            model.add(keras_genomics.layers.RevCompConv1D(filters=filters, \n",
    "                                                          kernel_size=kernel_size, \n",
    "                                                          input_shape=keras_train_batch_generator[0][0].shape[1:], \n",
    "                                                          padding=\"same\"))\n",
    "        model.add(k1.core.Activation(\"relu\"))\n",
    "        \n",
    "        #Don't apply dropout before the pooling layer\n",
    "        if i != num_conv - 1: \n",
    "            if dropout: \n",
    "                model.add(k1.Dropout(dropout_rate))\n",
    "            elif spatial_dropout:\n",
    "                if rev_comp: \n",
    "                    model.add(RevCompSpatialDropout1D(dropout_rate)) \n",
    "                else: \n",
    "                    model.add(k1.core.SpatialDropout1D(dropout_rate))\n",
    "            elif mc_dropout: \n",
    "                model.add(MCRCDropout(dropout_rate))\n",
    "\n",
    "    #Only needed with rc model\n",
    "    if rev_comp: \n",
    "        model.add(RevCompSumPool())\n",
    "    \n",
    "    #Pooling layers\n",
    "    if pooling == 'max': \n",
    "        model.add(k1.pooling.MaxPooling1D(pool_size = pool_size,padding = \"same\", strides = strides))\n",
    "    elif pooling == 'avg':\n",
    "        model.add(k1.pooling.AveragePooling1D(pool_size = pool_size, padding = \"same\", strides = strides))\n",
    "    elif pooling == 'weight_dist':\n",
    "        model.add(WeightDistConv(filters = weight_dist_filters, kernel_size = weight_dist_kernel_size, strides = strides,\n",
    "                                input_shape = keras_train_batch_generator[0][0].shape[1:], padding = \"same\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Fully-connected layers \n",
    "    model.add(keras_genomics.layers.core.Dense(units = units, activation = \"relu\"))\n",
    "    model.add(keras_genomics.layers.core.Dense(units = 1))  \n",
    "    \n",
    "    if siamese: \n",
    "        main_input = Input(shape=keras_train_batch_generator[0][0].shape[1:])\n",
    "        rev_input = Input(shape=keras_train_batch_generator[0][0].shape[1:])\n",
    "        rev_input = RevComp()(main_input)\n",
    "        main_output = model(main_input)\n",
    "        rev_output = model(rev_input)\n",
    "        avg = k1.Average()([main_output, rev_output])\n",
    "        model = Model(inputs = main_input, outputs = avg)\n",
    "\n",
    "    output_dir = os.path.join(MODEL_DIR, str(_run._id))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor = 'val_loss',\n",
    "                              patience = patience,\n",
    "                              restore_best_weights=True)\n",
    "    model.fit_generator(generator = keras_train_batch_generator, \n",
    "                           epochs = num_epochs, callbacks = [early_stopping_callback],\n",
    "                           validation_data = keras_valid_batch_generator)\n",
    "    model.set_weights(early_stopping_callback.best_weights)\n",
    "    \n",
    "    y_pred = model.predict_generator(keras_test_batch_generator)\n",
    "    \n",
    "    filename = (filename + '_%s.h5' % seed_num, str(seed_num))[0]\n",
    "    model.save(filename)\n",
    "    \n",
    "    rho, pval = spearmanr(y_test, y_pred)\n",
    "    print('correlation ', rho)\n",
    "    print('p-value', pval)\n",
    "    _run.log_scalar('correlation', rho)\n",
    "    _run.log_scalar('p-value', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.run(config_updates = {'siamese': True, 'spatial_dropout': True, 'filename': 'siamese_spatial_dropout'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.run(config_updates = {'siamese': True, 'spatial_dropout': True, 'weight_dist': True, 'filename': 'siamese_spatial_dropout_weight_dist'})\n",
    "# ex.run(config_updates = {'siamese': True, 'dropout': True, 'filename': 'dropout'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese w/ dropout \n",
    "#siamese w/ dropout and weight dist \n",
    "#siamese w/ nothing\n",
    "# ex = Experiment(\"Siamese Model\", interactive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 12:56:47.872084 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0730 12:56:48.625100 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 12:56:48.655480 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "curr kernel:  Tensor(\"weight_dist_conv_1/concat:0\", shape=(40, 15, 15), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 12:56:59.343607 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 15)          915       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1000, 15)          3390      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1000, 15)          3390      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1000, 15)          0         \n",
      "_________________________________________________________________\n",
      "weight_dist_conv_1 (WeightDi (None, 25, 15)            600       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               37600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 45,996\n",
      "Trainable params: 45,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 12:57:14.595007 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0730 12:57:16.819869 140319294207744 deprecation_wrapper.py:119] From /users/hannahgz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "570/570 [==============================] - 436s 765ms/step - loss: 9247.6540 - val_loss: 10404.3928\n",
      "Epoch 2/300\n",
      "570/570 [==============================] - 368s 645ms/step - loss: 8656.6690 - val_loss: 10255.7840\n",
      "Epoch 3/300\n",
      "570/570 [==============================] - 300s 527ms/step - loss: 8660.2903 - val_loss: 10069.8382\n",
      "Epoch 4/300\n",
      "570/570 [==============================] - 232s 408ms/step - loss: 8641.8927 - val_loss: 10012.4233\n",
      "Epoch 5/300\n",
      "570/570 [==============================] - 103s 180ms/step - loss: 8406.2497 - val_loss: 9010.6109\n",
      "Epoch 6/300\n",
      "570/570 [==============================] - 84s 147ms/step - loss: 7117.7145 - val_loss: 7738.2007\n",
      "Epoch 7/300\n",
      "570/570 [==============================] - 79s 138ms/step - loss: 6659.4347 - val_loss: 7144.6917\n",
      "Epoch 8/300\n",
      "570/570 [==============================] - 68s 120ms/step - loss: 6428.0396 - val_loss: 7049.2994\n",
      "Epoch 9/300\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 6161.8182 - val_loss: 6739.6687\n",
      "Epoch 10/300\n",
      "570/570 [==============================] - 68s 120ms/step - loss: 5973.1256 - val_loss: 6701.5637\n",
      "Epoch 11/300\n",
      "570/570 [==============================] - 41s 72ms/step - loss: 5823.0986 - val_loss: 6379.4415\n",
      "Epoch 12/300\n",
      "570/570 [==============================] - 42s 74ms/step - loss: 5668.2042 - val_loss: 6212.3501\n",
      "Epoch 13/300\n",
      "570/570 [==============================] - 44s 78ms/step - loss: 5547.5666 - val_loss: 6037.0941\n",
      "Epoch 14/300\n",
      "570/570 [==============================] - 46s 80ms/step - loss: 5463.3234 - val_loss: 6067.6463\n",
      "Epoch 15/300\n",
      "570/570 [==============================] - 39s 68ms/step - loss: 5352.7581 - val_loss: 6079.2194\n",
      "Epoch 16/300\n",
      "570/570 [==============================] - 38s 66ms/step - loss: 5261.5100 - val_loss: 5923.3876\n",
      "Epoch 17/300\n",
      "570/570 [==============================] - 38s 67ms/step - loss: 5196.8559 - val_loss: 5866.9803\n",
      "Epoch 18/300\n",
      "570/570 [==============================] - 40s 70ms/step - loss: 5105.9629 - val_loss: 5891.8359\n",
      "Epoch 19/300\n",
      "570/570 [==============================] - 39s 69ms/step - loss: 5038.9104 - val_loss: 6023.8261\n",
      "Epoch 20/300\n",
      "570/570 [==============================] - 38s 67ms/step - loss: 4956.3672 - val_loss: 5794.8583\n",
      "Epoch 21/300\n",
      "570/570 [==============================] - 41s 73ms/step - loss: 4855.6064 - val_loss: 6074.0609\n",
      "Epoch 22/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4775.5257 - val_loss: 5822.3079\n",
      "Epoch 23/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4681.7705 - val_loss: 5909.2937\n",
      "Epoch 24/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4616.6376 - val_loss: 5794.6420\n",
      "Epoch 25/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4525.7780 - val_loss: 5706.6678\n",
      "Epoch 26/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4442.9498 - val_loss: 5736.0709\n",
      "Epoch 27/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4389.6028 - val_loss: 6020.8554\n",
      "Epoch 28/300\n",
      "570/570 [==============================] - 37s 64ms/step - loss: 4317.6954 - val_loss: 5705.3437\n",
      "Epoch 29/300\n",
      "570/570 [==============================] - 37s 64ms/step - loss: 4230.7370 - val_loss: 5869.6238\n",
      "Epoch 30/300\n",
      "570/570 [==============================] - 36s 64ms/step - loss: 4145.4087 - val_loss: 6460.4863\n",
      "Epoch 31/300\n",
      "570/570 [==============================] - 36s 64ms/step - loss: 4108.8265 - val_loss: 6180.1896\n",
      "Epoch 32/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 4055.9539 - val_loss: 6077.7569\n",
      "Epoch 33/300\n",
      "570/570 [==============================] - 36s 64ms/step - loss: 3982.7463 - val_loss: 5930.8091\n",
      "Epoch 34/300\n",
      "570/570 [==============================] - 37s 64ms/step - loss: 3929.5582 - val_loss: 6388.6689\n",
      "Epoch 35/300\n",
      "570/570 [==============================] - 37s 64ms/step - loss: 3868.0000 - val_loss: 6245.7130\n",
      "Epoch 36/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 3809.4377 - val_loss: 6262.4846\n",
      "Epoch 37/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 3760.4525 - val_loss: 6293.4726\n",
      "Epoch 38/300\n",
      "570/570 [==============================] - 37s 65ms/step - loss: 3688.3181 - val_loss: 6151.7790\n",
      "Epoch 39/300\n",
      "570/570 [==============================] - 37s 66ms/step - loss: 3636.7983 - val_loss: 6400.9664\n",
      "Epoch 40/300\n",
      "570/570 [==============================] - 36s 63ms/step - loss: 3565.7713 - val_loss: 6318.5089\n",
      "Epoch 41/300\n",
      "570/570 [==============================] - 37s 64ms/step - loss: 3526.2431 - val_loss: 6669.5837\n",
      "Epoch 42/300\n",
      "570/570 [==============================] - 38s 66ms/step - loss: 3491.2885 - val_loss: 6699.3049\n",
      "Epoch 43/300\n",
      "570/570 [==============================] - 38s 66ms/step - loss: 3433.4472 - val_loss: 6646.5836\n",
      "Epoch 44/300\n",
      "570/570 [==============================] - 38s 66ms/step - loss: 3383.7566 - val_loss: 6682.5042\n",
      "Epoch 45/300\n",
      "314/570 [===============>..............] - ETA: 16s - loss: 3257.0650"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = (\"/users/hannahgz/revcomp_experiments/sacred_runs/new_weight_dist\")\n",
    "ex.observers.append(\n",
    "    sacred.observers.FileStorageObserver.create(MODEL_DIR)\n",
    ")\n",
    "\n",
    "ex.captured_out_filter = utils.apply_backspaces_and_linefeeds\n",
    "for curr_seed in range(1000, 11000, 1000): \n",
    "    ex.run(config_updates = {'pooling': 'weight_dist', 'filename': 'weight_dist_pooling', 'seed_num': curr_seed})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.run(config_updates = {'siamese': True, 'dropout': True, 'spatial_dropout': True, 'filename': 'siamese_spatial_dropout'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.run(config_updates = {'siamese': True, 'filename': 'siamese'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
