{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdataloader.seqdataloader.labelgen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: [[: not found\n",
      "--2019-08-25 02:02:02--  https://www.encodeproject.org/files/ENCFF289XSX/@@download/ENCFF289XSX.bigWig\n",
      "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
      "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://download.encodeproject.org/https://encode-public.s3.amazonaws.com/2019/02/13/9a778a35-5a1a-4b1d-9207-bd2f09af2d07/ENCFF289XSX.bigWig?response-content-disposition=attachment%3B%20filename%3DENCFF289XSX.bigWig&x-amz-security-token=AgoJb3JpZ2luX2VjEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHCKEh%2FJRbBQ0MaEMnH9%2BJS7STRqu2w%2BJHa7UfLynCzaAiEA8t%2FAq%2BiKitvohB3g2uLz%2B9C8%2FF1MPd%2F30EQHLOttqasq2gMIKRAAGgwyMjA3NDg3MTQ4NjMiDN3S8DqM%2FOL82yZQjSq3A38F%2B2ZdModYXtXFeZSoGYugZmFvKbJ%2BUtlTdviTdBLrUBT3TLGH1LvqIDIzzk8hvq5CwOIyV2r65nXsOlnWJf6bIruu9pv%2BozbDWDb9uBLMmbsbLq8%2BUIc20Qz6AKjRP7xV%2BH%2Bnyc4oGWlqcXWgAhNpEgs621H3BtYuCGC8MFCNf874YribBdjbCABRHDO3l3%2By%2FJTn0NJgPlyK888F624xbA3nSHwdFkvTJ%2B2FRgkqmM2v4Ra5QPF2FC3S8kkkvmMhR73b1gobHLA1B40UHzqCwMeQFCj79Spd95y0gPHTAKOIeVMA1cNawgWAuRkumwC6E3qiQdycCSlwdKJUV2gLzgG2lYcl%2F8JtU%2FMzNVuuROzEEAIo3E96pWFForf5xqDkRtPf2D%2BYl7dYMX6GkYKoohOlmhVtRPqrjmjGJSCm3f4hRU0wfBQ3C7%2Bi2nS2IXNhs1oElWJEqoL7g%2F%2BDJqh3K3sCOZHrD7kRbNDpOzhw6kZK1ZR22MNLTOX1nIHIGlLSlXIVgbj8hAbPJKB%2FxpGPdGGYU%2Bt8pmkkk2dxjYSBZM%2Fwc7qBcnKWLHNjldcwZ1BEIQh%2FNF0w7P2I6wU6tAEEEvZGb2NXHRsnr7%2FtcU28ITmWGYg%2BEbwWRO0h72QNiDY3ARrQ4KA7ooUN5ifC32xl8Un8bVxmu3GniwPDm9dIXASVbnoYGaYuY1lt8HCh7%2BDAB86DG1FYDyJj2pBelZUvWp30EtckyXyigaDASrY7QBgb%2BAaEQ5DBExVd4ojgFG9en7RXLelE27pvmDw7bH2MRBYVKx7zBaKzhiXwZmZJWYxomMm7yRU2w6ejzTI4fFFmsiQ%3D&Expires=1566853322&Signature=ZGP%2F1CO8qDM89pAw0Va1OqHN9IA%3D&AWSAccessKeyId=ASIATGZNGCNXQS3DDT4H [following]\n",
      "--2019-08-25 02:02:02--  https://download.encodeproject.org/https://encode-public.s3.amazonaws.com/2019/02/13/9a778a35-5a1a-4b1d-9207-bd2f09af2d07/ENCFF289XSX.bigWig?response-content-disposition=attachment%3B%20filename%3DENCFF289XSX.bigWig&x-amz-security-token=AgoJb3JpZ2luX2VjEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHCKEh%2FJRbBQ0MaEMnH9%2BJS7STRqu2w%2BJHa7UfLynCzaAiEA8t%2FAq%2BiKitvohB3g2uLz%2B9C8%2FF1MPd%2F30EQHLOttqasq2gMIKRAAGgwyMjA3NDg3MTQ4NjMiDN3S8DqM%2FOL82yZQjSq3A38F%2B2ZdModYXtXFeZSoGYugZmFvKbJ%2BUtlTdviTdBLrUBT3TLGH1LvqIDIzzk8hvq5CwOIyV2r65nXsOlnWJf6bIruu9pv%2BozbDWDb9uBLMmbsbLq8%2BUIc20Qz6AKjRP7xV%2BH%2Bnyc4oGWlqcXWgAhNpEgs621H3BtYuCGC8MFCNf874YribBdjbCABRHDO3l3%2By%2FJTn0NJgPlyK888F624xbA3nSHwdFkvTJ%2B2FRgkqmM2v4Ra5QPF2FC3S8kkkvmMhR73b1gobHLA1B40UHzqCwMeQFCj79Spd95y0gPHTAKOIeVMA1cNawgWAuRkumwC6E3qiQdycCSlwdKJUV2gLzgG2lYcl%2F8JtU%2FMzNVuuROzEEAIo3E96pWFForf5xqDkRtPf2D%2BYl7dYMX6GkYKoohOlmhVtRPqrjmjGJSCm3f4hRU0wfBQ3C7%2Bi2nS2IXNhs1oElWJEqoL7g%2F%2BDJqh3K3sCOZHrD7kRbNDpOzhw6kZK1ZR22MNLTOX1nIHIGlLSlXIVgbj8hAbPJKB%2FxpGPdGGYU%2Bt8pmkkk2dxjYSBZM%2Fwc7qBcnKWLHNjldcwZ1BEIQh%2FNF0w7P2I6wU6tAEEEvZGb2NXHRsnr7%2FtcU28ITmWGYg%2BEbwWRO0h72QNiDY3ARrQ4KA7ooUN5ifC32xl8Un8bVxmu3GniwPDm9dIXASVbnoYGaYuY1lt8HCh7%2BDAB86DG1FYDyJj2pBelZUvWp30EtckyXyigaDASrY7QBgb%2BAaEQ5DBExVd4ojgFG9en7RXLelE27pvmDw7bH2MRBYVKx7zBaKzhiXwZmZJWYxomMm7yRU2w6ejzTI4fFFmsiQ%3D&Expires=1566853322&Signature=ZGP%2F1CO8qDM89pAw0Va1OqHN9IA%3D&AWSAccessKeyId=ASIATGZNGCNXQS3DDT4H\n",
      "Resolving download.encodeproject.org (download.encodeproject.org)... 34.211.244.144\n",
      "Connecting to download.encodeproject.org (download.encodeproject.org)|34.211.244.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://encode-public.s3.amazonaws.com/2019/02/13/9a778a35-5a1a-4b1d-9207-bd2f09af2d07/ENCFF289XSX.bigWig?response-content-disposition=attachment%3B%20filename%3DENCFF289XSX.bigWig&x-amz-security-token=AgoJb3JpZ2luX2VjEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHCKEh%2FJRbBQ0MaEMnH9%2BJS7STRqu2w%2BJHa7UfLynCzaAiEA8t%2FAq%2BiKitvohB3g2uLz%2B9C8%2FF1MPd%2F30EQHLOttqasq2gMIKRAAGgwyMjA3NDg3MTQ4NjMiDN3S8DqM%2FOL82yZQjSq3A38F%2B2ZdModYXtXFeZSoGYugZmFvKbJ%2BUtlTdviTdBLrUBT3TLGH1LvqIDIzzk8hvq5CwOIyV2r65nXsOlnWJf6bIruu9pv%2BozbDWDb9uBLMmbsbLq8%2BUIc20Qz6AKjRP7xV%2BH%2Bnyc4oGWlqcXWgAhNpEgs621H3BtYuCGC8MFCNf874YribBdjbCABRHDO3l3%2By%2FJTn0NJgPlyK888F624xbA3nSHwdFkvTJ%2B2FRgkqmM2v4Ra5QPF2FC3S8kkkvmMhR73b1gobHLA1B40UHzqCwMeQFCj79Spd95y0gPHTAKOIeVMA1cNawgWAuRkumwC6E3qiQdycCSlwdKJUV2gLzgG2lYcl%2F8JtU%2FMzNVuuROzEEAIo3E96pWFForf5xqDkRtPf2D%2BYl7dYMX6GkYKoohOlmhVtRPqrjmjGJSCm3f4hRU0wfBQ3C7%2Bi2nS2IXNhs1oElWJEqoL7g%2F%2BDJqh3K3sCOZHrD7kRbNDpOzhw6kZK1ZR22MNLTOX1nIHIGlLSlXIVgbj8hAbPJKB%2FxpGPdGGYU%2Bt8pmkkk2dxjYSBZM%2Fwc7qBcnKWLHNjldcwZ1BEIQh%2FNF0w7P2I6wU6tAEEEvZGb2NXHRsnr7%2FtcU28ITmWGYg%2BEbwWRO0h72QNiDY3ARrQ4KA7ooUN5ifC32xl8Un8bVxmu3GniwPDm9dIXASVbnoYGaYuY1lt8HCh7%2BDAB86DG1FYDyJj2pBelZUvWp30EtckyXyigaDASrY7QBgb%2BAaEQ5DBExVd4ojgFG9en7RXLelE27pvmDw7bH2MRBYVKx7zBaKzhiXwZmZJWYxomMm7yRU2w6ejzTI4fFFmsiQ%3D&Expires=1566853322&Signature=ZGP%2F1CO8qDM89pAw0Va1OqHN9IA%3D&AWSAccessKeyId=ASIATGZNGCNXQS3DDT4H [following]\n",
      "--2019-08-25 02:02:02--  https://encode-public.s3.amazonaws.com/2019/02/13/9a778a35-5a1a-4b1d-9207-bd2f09af2d07/ENCFF289XSX.bigWig?response-content-disposition=attachment%3B%20filename%3DENCFF289XSX.bigWig&x-amz-security-token=AgoJb3JpZ2luX2VjEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHCKEh%2FJRbBQ0MaEMnH9%2BJS7STRqu2w%2BJHa7UfLynCzaAiEA8t%2FAq%2BiKitvohB3g2uLz%2B9C8%2FF1MPd%2F30EQHLOttqasq2gMIKRAAGgwyMjA3NDg3MTQ4NjMiDN3S8DqM%2FOL82yZQjSq3A38F%2B2ZdModYXtXFeZSoGYugZmFvKbJ%2BUtlTdviTdBLrUBT3TLGH1LvqIDIzzk8hvq5CwOIyV2r65nXsOlnWJf6bIruu9pv%2BozbDWDb9uBLMmbsbLq8%2BUIc20Qz6AKjRP7xV%2BH%2Bnyc4oGWlqcXWgAhNpEgs621H3BtYuCGC8MFCNf874YribBdjbCABRHDO3l3%2By%2FJTn0NJgPlyK888F624xbA3nSHwdFkvTJ%2B2FRgkqmM2v4Ra5QPF2FC3S8kkkvmMhR73b1gobHLA1B40UHzqCwMeQFCj79Spd95y0gPHTAKOIeVMA1cNawgWAuRkumwC6E3qiQdycCSlwdKJUV2gLzgG2lYcl%2F8JtU%2FMzNVuuROzEEAIo3E96pWFForf5xqDkRtPf2D%2BYl7dYMX6GkYKoohOlmhVtRPqrjmjGJSCm3f4hRU0wfBQ3C7%2Bi2nS2IXNhs1oElWJEqoL7g%2F%2BDJqh3K3sCOZHrD7kRbNDpOzhw6kZK1ZR22MNLTOX1nIHIGlLSlXIVgbj8hAbPJKB%2FxpGPdGGYU%2Bt8pmkkk2dxjYSBZM%2Fwc7qBcnKWLHNjldcwZ1BEIQh%2FNF0w7P2I6wU6tAEEEvZGb2NXHRsnr7%2FtcU28ITmWGYg%2BEbwWRO0h72QNiDY3ARrQ4KA7ooUN5ifC32xl8Un8bVxmu3GniwPDm9dIXASVbnoYGaYuY1lt8HCh7%2BDAB86DG1FYDyJj2pBelZUvWp30EtckyXyigaDASrY7QBgb%2BAaEQ5DBExVd4ojgFG9en7RXLelE27pvmDw7bH2MRBYVKx7zBaKzhiXwZmZJWYxomMm7yRU2w6ejzTI4fFFmsiQ%3D&Expires=1566853322&Signature=ZGP%2F1CO8qDM89pAw0Va1OqHN9IA%3D&AWSAccessKeyId=ASIATGZNGCNXQS3DDT4H\n",
      "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.218.235\n",
      "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.218.235|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 577542827 (551M) [binary/octet-stream]\n",
      "Saving to: ‘ENCFF289XSX.bigWig’\n",
      "\n",
      "ENCFF289XSX.bigWig  100%[===================>] 550.79M  20.3MB/s    in 42s     \n",
      "\n",
      "2019-08-25 02:02:45 (13.0 MB/s) - ‘ENCFF289XSX.bigWig’ saved [577542827/577542827]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "![[ -f ENCFF289XSX.bigWig ]] || wget https://www.encodeproject.org/files/ENCFF289XSX/@@download/ENCFF289XSX.bigWig\n",
    "# !ln -s ENCFF071ZMW.bed.gz peaks_with_signal_SPI1_new.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zcat peaks_with_signal.bed.gz | perl -lane 'print $F[0].\"\\t\".($F[1]+$F[9]).\"\\t\".($F[1]+$F[9]).\"\\t+\\t\".($F[6])' | egrep -w 'chr1|chr2|chr3|chr4|chr5|chr6|chr7|chr8|chr9|chr10|chr11|chr12|chr13|chr14|chr15|chr16|chr17|chr18|chr19|chr20|chr21|chr22|chrX|chrY' | gzip -c > summits_with_signal.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zcat regressionlabels.tsv.gz | perl -lane 'print $F[0].\"\\t\".($F[1]+$F[9]).\"\\t\".($F[1]+$F[9]).\"\\t+\\t\".($F[6])' | egrep -w 'chr1|chr2|chr3|chr4|chr5|chr6|chr7|chr8|chr9|chr10|chr11|chr12|chr13|chr14|chr15|chr16|chr17|chr18|chr19|chr20|chr21|chr22|chrX|chrY' | gzip -c > summits_with_signal_SPI1_new.bed.gz\n",
    "\n",
    "#We split into training/test/validation set by chromosome\n",
    "!zcat summits_with_signal_SPI1_new.bed.gz | egrep -w 'chr1|chr8|chr21' | gzip -c > test_summits_with_signal_SPI1_new.bed.gz\n",
    "!zcat summits_with_signal_SPI1_new.bed.gz | egrep -w 'chr22' | gzip -c > valid_summits_with_signal_SPI1_new.bed.gz\n",
    "!zcat summits_with_signal_SPI1_new.bed.gz | egrep -w -v 'chr1|chr8|chr21|chr22' | gzip -c > train_summits_with_signal_SPI1_new.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n"
     ]
    }
   ],
   "source": [
    "from seqdataloader.seqdataloader.batchproducers import coordbased\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "class ColsInBedFile(\n",
    "    coordbased.coordstovals.core.AbstractSingleNdarrayCoordsToVals):\n",
    "    def __init__(self, gzipped_bed_file, **kwargs):\n",
    "        super(ColsInBedFile, self).__init__(**kwargs)\n",
    "        self.gzipped_bed_file = gzipped_bed_file\n",
    "        coords_to_vals = {}\n",
    "        for row in gzip.open(gzipped_bed_file, 'rb'):\n",
    "            row = row.decode(\"utf-8\").rstrip()\n",
    "            split_row = row.split(\"\\t\")\n",
    "            chrom_start_end = split_row[0]+\":\"+split_row[1]+\"-\"+split_row[2]\n",
    "            vals = np.array([float(x) for x in split_row[4:]])\n",
    "            coords_to_vals[chrom_start_end] = vals\n",
    "        self.coords_to_vals = coords_to_vals\n",
    "        \n",
    "    def _get_ndarray(self, coors):\n",
    "        to_return = []\n",
    "        for coor in coors:\n",
    "            chrom_start_end = (coor.chrom+\":\"\n",
    "                               +str(coor.start)+\"-\"+str(coor.end))\n",
    "            to_return.append(self.coords_to_vals[chrom_start_end])\n",
    "        return np.array(to_return)\n",
    "    \n",
    "    \n",
    "inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "  genome_fasta_path= '/mnt/data/annotations/by_release/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta',\n",
    "  center_size_to_use=1000)\n",
    "\n",
    "targets_coordstovals = ColsInBedFile(\n",
    "       gzipped_bed_file=\"summits_with_signal_SPI1_new.bed.gz\")\n",
    "            \n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal_SPI1_new.bed.gz\",\n",
    "      #coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal_SPI1_new.bed.gz\", \n",
    "        batch_size=64, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal_SPI1_new.bed.gz\", \n",
    "        batch_size = 64, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_train_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer=coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"train_summits_with_signal_SPI1_new.bed.gz\",\n",
    "      coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "      batch_size=128,\n",
    "      shuffle_before_epoch=True,\n",
    "      seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "\n",
    "keras_valid_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"valid_summits_with_signal_SPI1_new.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size=128, \n",
    "        shuffle_before_epoch=True, \n",
    "        seed=1234\n",
    "    ),\n",
    "    inputs_coordstovals=inputs_coordstovals, \n",
    "    targets_coordstovals=targets_coordstovals\n",
    ")\n",
    "\n",
    "keras_test_batch_generator_augment = coordbased.core.KerasBatchGenerator(\n",
    "    coordsbatch_producer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "        bed_file=\"test_summits_with_signal_SPI1_new.bed.gz\",\n",
    "        coord_batch_transformer=coordbased.coordbatchtransformers.ReverseComplementAugmenter(),\n",
    "        batch_size = 128, \n",
    "        shuffle_before_epoch = True, \n",
    "        seed = 1234\n",
    "    ), \n",
    "    inputs_coordstovals = inputs_coordstovals, \n",
    "    targets_coordstovals = targets_coordstovals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_coordstovals.ltrdict = {\n",
    "           'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1],\n",
    "           'n':[0,0,0,0],'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],\n",
    "           'T':[0,0,0,1],'N':[0,0,0,0],'R': [0.5,0,0.5,0],'Y':[0,0.5,0,0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([val for batch in keras_test_batch_generator for val in batch[1]], dtype = 'float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_augment = np.array([val for batch in keras_test_batch_generator_augment for val in batch[1]], dtype = 'float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import keras_genomics\n",
    "import numpy as np\n",
    "import keras.layers as k1\n",
    "import simdna\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import numbers\n",
    "from tensorflow.python.framework import tensor_util\n",
    "def _get_noise_shape(x, noise_shape):\n",
    "  # If noise_shape is none return immediately.\n",
    "  if noise_shape is None:\n",
    "    return array_ops.shape(x)\n",
    "\n",
    "  try:\n",
    "    # Best effort to figure out the intended shape.\n",
    "    # If not possible, let the op to handle it.\n",
    "    # In eager mode exception will show up.\n",
    "    noise_shape_ = tensor_shape.as_shape(noise_shape)\n",
    "  except (TypeError, ValueError):\n",
    "    return noise_shape\n",
    "\n",
    "  if x.shape.dims is not None and len(x.shape.dims) == len(noise_shape_.dims):\n",
    "    new_dims = []\n",
    "    for i, dim in enumerate(x.shape.dims):\n",
    "      if noise_shape_.dims[i].value is None and dim.value is not None:\n",
    "        new_dims.append(dim.value)\n",
    "      else:\n",
    "        new_dims.append(noise_shape_.dims[i].value)\n",
    "    return tensor_shape.TensorShape(new_dims)\n",
    "\n",
    "  return noise_shape\n",
    "\n",
    "class MCRCDropout(Layer):\n",
    "    \"\"\"Applies MC Dropout to the input.\n",
    "       The applied noise vector is symmetric to reverse complement symmetry\n",
    "       Class structure only slightly adapted \n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    Remains active ative at test time so sampling is required\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(MCRCDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(MCRCDropout, self).build(input_shape)\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        if self.noise_shape is None:\n",
    "            return self.noise_shape\n",
    "\n",
    "        symbolic_shape = K.shape(inputs)\n",
    "        noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                       for axis, shape in enumerate(self.noise_shape)]\n",
    "        return tuple(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            import numpy as np\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            x = inputs\n",
    "            seed = self.seed\n",
    "            keep_prob = 1. - self.rate\n",
    "            if seed is None:\n",
    "                seed = np.random.randint(10e6)\n",
    "            # the dummy 1. works around a TF bug\n",
    "            # (float32_ref vs. float32 incompatibility)\n",
    "            x= x*1\n",
    "            name = None\n",
    "            with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "                x = ops.convert_to_tensor(x, name=\"x\")\n",
    "                if not x.dtype.is_floating:\n",
    "                    raise ValueError(\"x has to be a floating point tensor since it's going to\"\n",
    "                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n",
    "                if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "                    raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                       \"range (0, 1], got %g\" % keep_prob)\n",
    "                keep_prob = ops.convert_to_tensor(\n",
    "                             keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "                keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "                # Do nothing if we know keep_prob == 1\n",
    "                if tensor_util.constant_value(keep_prob) == 1:\n",
    "                    return x\n",
    "\n",
    "                noise_shape = _get_noise_shape(x, noise_shape)\n",
    "                # uniform [keep_prob, 1.0 + keep_prob)\n",
    "                random_tensor = keep_prob\n",
    "                random_tensor += random_ops.random_uniform(\n",
    "                noise_shape, seed=seed, dtype=x.dtype)\n",
    "               \n",
    "                # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "                binary_tensor = math_ops.floor(random_tensor)\n",
    "                dim = binary_tensor.shape[2]//2\n",
    "\n",
    "                symmetric_binary = K.concatenate(\n",
    "                    tensors = [\n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):], \n",
    "                      binary_tensor[:,:,int(self.num_input_chan/2):][::,::-1,::-1]], \n",
    "                  axis=2)\n",
    "                ret = math_ops.div(x, keep_prob) * symmetric_binary\n",
    "                \n",
    "                return ret\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate,\n",
    "                  'noise_shape': self.noise_shape,\n",
    "                  'seed': self.seed}\n",
    "        base_config = super(MCRCDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSpatialDropout1D(Dropout): \n",
    "    def __init__(self, rate,**kwargs): \n",
    "        super(RevCompSpatialDropout1D, self).__init__(rate, **kwargs)\n",
    "        self.seed = 3\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "\n",
    "    def _get_noise_shape(self, inputs): \n",
    "        input_shape = K.shape(inputs)\n",
    "        noise_shape = (input_shape[0], 1, 1, int(self.num_input_chan/2)) \n",
    "        return noise_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        self.input_len = input_shape[1]\n",
    "        super(RevCompSpatialDropout1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None): \n",
    "        inputs_fwdandrevconcat = K.concatenate(\n",
    "                tensors = [\n",
    "                    inputs[:,:,None,:int(self.num_input_chan/2)],\n",
    "                    inputs[:,:,None,int(self.num_input_chan/2):][:,:,:,::-1]],\n",
    "                axis=2)\n",
    "\n",
    "        if 0. < self.rate < 1.: \n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "            def dropped_inputs(): \n",
    "                dropped = K.dropout(inputs_fwdandrevconcat,\n",
    "                                    self.rate, noise_shape, seed = self.seed)\n",
    "                dropped = K.reshape(dropped, (-1, int(self.input_len), int(self.num_input_chan)))\n",
    "                return K.concatenate(\n",
    "                    tensors = [\n",
    "                        dropped[:,:,:int(self.num_input_chan/2)],\n",
    "                        dropped[:,:,int(self.num_input_chan/2):][:,:,::-1]],\n",
    "                    axis=-1)\n",
    "\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training = training)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevComp(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "      super(RevComp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "      super(RevComp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "      return inputs[:,::-1,::-1]\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "      return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 15\n",
    "filters= 15\n",
    "input_length = 1000\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "\n",
    "seed_num = 10000\n",
    "seed(seed_num)\n",
    "set_random_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def test(data):\n",
    "    num_conv = data[\"num_conv\"]\n",
    "    dataset = \"SPI1\"\n",
    "    augment =  data[\"augment\"]\n",
    "    dropout = data[\"dropout\"]\n",
    "    dropout_rate = data[\"dropout_rate\"]\n",
    "    filename = data[\"filename\"]\n",
    "    filters = data[\"filters\"]\n",
    "    kernel_size = data[\"kernel_size\"]\n",
    "    mc_dropout = data[\"mc_dropout\"]\n",
    "    num_epochs = data[\"num_epochs\"]\n",
    "    patience = data[\"patience\"]\n",
    "    pool_size = data[\"pool_size\"]\n",
    "    pooling = data[\"pooling\"]\n",
    "    rev_comp = data[\"rev_comp\"]\n",
    "#     seed_num = (int)(np.random.uniform(1000, 10000))\n",
    "    data[\"seed_num\"] = seed_num\n",
    "    siamese = data[\"siamese\"]\n",
    "    spatial_dropout = data[\"spatial_dropout\"]\n",
    "    rc_spatial_dropout = data[\"rc_spatial_dropout\"]\n",
    "    strides = data[\"strides\"]\n",
    "    units = data[\"units\"]\n",
    "    \n",
    "    train_batch_generator = keras_train_batch_generator\n",
    "    valid_batch_generator = keras_valid_batch_generator\n",
    "    test_batch_generator = keras_test_batch_generator\n",
    "    y_test_model = y_test\n",
    "    \n",
    "\n",
    "    if augment: \n",
    "        train_batch_generator = keras_train_batch_generator_augment\n",
    "        valid_batch_generator = keras_valid_batch_generator_augment\n",
    "        test_batch_generator = keras_test_batch_generator_augment\n",
    "        y_test_model = y_test_augment\n",
    "        \n",
    "    seed(seed_num)\n",
    "    set_random_seed(seed_num)\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    for i in range(num_conv): \n",
    "        if rev_comp: \n",
    "            model.add(keras_genomics.layers.RevCompConv1D(filters=filters, \n",
    "                                                          kernel_size=kernel_size, \n",
    "                                                          input_shape=train_batch_generator[0][0].shape[1:], \n",
    "                                                          padding=\"same\"))\n",
    "        else: \n",
    "            model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                          input_shape=train_batch_generator[0][0].shape[1:],\n",
    "                          padding=\"same\")) \n",
    "            \n",
    "        model.add(k1.core.Activation(\"relu\"))\n",
    "        \n",
    "        #No dropout before the pooling layer\n",
    "        if i != num_conv - 1: \n",
    "            if dropout: \n",
    "                model.add(k1.Dropout(dropout_rate))\n",
    "            elif spatial_dropout: \n",
    "                model.add(k1.SpatialDropout1D(dropout_rate))\n",
    "            elif rc_spatial_dropout:\n",
    "                model.add(RevCompSpatialDropout1D(dropout_rate)) \n",
    "            elif mc_dropout: \n",
    "                model.add(MCRCDropout(dropout_rate))\n",
    "\n",
    "    #Only needed with rc model\n",
    "    if rev_comp: \n",
    "        model.add(RevCompSumPool())\n",
    "    \n",
    "    #Pooling layers\n",
    "    if pooling == 'max': \n",
    "        model.add(k1.pooling.MaxPooling1D(pool_size = pool_size,padding = \"same\", strides = strides))\n",
    "    elif pooling == 'avg':\n",
    "        model.add(k1.pooling.AveragePooling1D(pool_size = pool_size, padding = \"same\", strides = strides))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Fully-connected layers \n",
    "    model.add(keras_genomics.layers.core.Dense(units = units, activation = \"relu\"))\n",
    "    model.add(keras_genomics.layers.core.Dense(units = 1))  \n",
    "    \n",
    "    if siamese: \n",
    "        main_input = Input(shape=train_batch_generator[0][0].shape[1:])\n",
    "        rev_input = Input(shape=train_batch_generator[0][0].shape[1:])\n",
    "        rev_input = RevComp()(main_input)\n",
    "        main_output = model(main_input)\n",
    "        rev_output = model(rev_input)\n",
    "        avg = k1.Average()([main_output, rev_output])\n",
    "        model = Model(inputs = main_input, outputs = avg)\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor = 'val_loss',\n",
    "                              patience = patience,\n",
    "                              restore_best_weights=True)\n",
    "    y_pred = []\n",
    "    \n",
    "    model.fit_generator(generator = train_batch_generator, \n",
    "                           epochs = num_epochs, callbacks = [early_stopping_callback],\n",
    "                           validation_data = valid_batch_generator)\n",
    "    model.set_weights(early_stopping_callback.best_weights)\n",
    "\n",
    "        \n",
    "    model.save(\"/users/hannahgz/revcomp_experiments/SPI1_New_Results/%s_%s.h5\" % (filename,str(seed_num)))\n",
    "\n",
    "    rho = 0\n",
    "    if dropout or mc_dropout or spatial_dropout or rc_spatial_dropout: \n",
    "        rho = spearmanr_all(y_test_model, model, test_batch_generator)\n",
    "    else: \n",
    "        y_pred = model.predict_generator(test_batch_generator)\n",
    "        rho, pval = spearmanr(y_test_model, y_pred)\n",
    "    \n",
    "    data[\"correlation\"] = rho\n",
    "    \n",
    "    with open(\"/users/hannahgz/revcomp_experiments/SPI1_New_Results/config_%s_%s.json\" % (filename,str(seed_num)), \"w\") as data_file: \n",
    "        json.dump(data, data_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_num in range(1000, 11000, 1000): \n",
    "    data = {\n",
    "            \"filename\": \"rc_15_filters\",\n",
    "            \"dataset\": \"SPI1\",\n",
    "            \"augment\": False,\n",
    "            \"siamese\": False,\n",
    "            \"rev_comp\": True,\n",
    "            \"dropout\": False,\n",
    "            \"mc_dropout\": False,\n",
    "            \"spatial_dropout\": False,\n",
    "            \"rc_spatial_dropout\": False,\n",
    "            \"dropout_rate\": 0.2,\n",
    "            \"num_conv\": 3,\n",
    "            \"filters\": 15,\n",
    "            \"kernel_size\": 15,\n",
    "            \"pool_size\": 40,\n",
    "            \"pooling\": \"max\",\n",
    "            \"num_epochs\": 1,\n",
    "            \"patience\": 60,\n",
    "            \"seed_num\": seed_num,\n",
    "            \"strides\": 40,\n",
    "            \"units\": 100,\n",
    "            \"correlation\": 0 \n",
    "            }\n",
    "    test(data)\n",
    "\n",
    "\n",
    "    data[\"filename\"] = \"reg_15_filters\"\n",
    "    data[\"rev_comp\"] = False\n",
    "    test(data)\n",
    "\n",
    "    data[\"filename\"] = \"augment_15_filters\"\n",
    "    data[\"augment\"] = True\n",
    "    test(data)\n",
    "\n",
    "    data[\"filename\"] = \"siamese_15_filters\"\n",
    "    data[\"siamese\"] = True\n",
    "    data[\"augment\"] = False\n",
    "    test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
