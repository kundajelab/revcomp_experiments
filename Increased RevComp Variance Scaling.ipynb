{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'revcomp_experiments' already exists and is not an empty directory.\n",
      "/users/hannahgz/revcomp_experiments/revcomp_experiments\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing revcompexp.egg-info/PKG-INFO\n",
      "writing dependency_links to revcompexp.egg-info/dependency_links.txt\n",
      "writing requirements to revcompexp.egg-info/requires.txt\n",
      "writing top-level names to revcompexp.egg-info/top_level.txt\n",
      "reading manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "writing manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "running install_scripts\n",
      "running build_scripts\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "copying build/scripts-3.7/motif_density_and_position_sim.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/motif_density_and_position_sim.py to 755\n",
      "copying revcompexp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/revcompexp-0.1.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing revcompexp-0.1.0.0-py3.7.egg\n",
      "Removing /users/hannahgz/anaconda3/lib/python3.7/site-packages/revcompexp-0.1.0.0-py3.7.egg\n",
      "Copying revcompexp-0.1.0.0-py3.7.egg to /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "revcompexp 0.1.0.0 is already the active version in easy-install.pth\n",
      "Installing motif_density_and_position_sim.py script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Installed /users/hannahgz/anaconda3/lib/python3.7/site-packages/revcompexp-0.1.0.0-py3.7.egg\n",
      "Processing dependencies for revcompexp==0.1.0.0\n",
      "Searching for scipy==1.2.1\n",
      "Best match: scipy 1.2.1\n",
      "Adding scipy 1.2.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for matplotlib==3.0.3\n",
      "Best match: matplotlib 3.0.3\n",
      "Adding matplotlib 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for numpy==1.16.2\n",
      "Best match: numpy 1.16.2\n",
      "Adding numpy 1.16.2 to easy-install.pth file\n",
      "Installing f2py script to /users/hannahgz/anaconda3/bin\n",
      "Installing f2py3 script to /users/hannahgz/anaconda3/bin\n",
      "Installing f2py3.7 script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for simdna==0.4.3.1\n",
      "Best match: simdna 0.4.3.1\n",
      "Processing simdna-0.4.3.1-py3.7.egg\n",
      "simdna 0.4.3.1 is already the active version in easy-install.pth\n",
      "Installing densityMotifSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing emptyBackground.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing motifGrammarSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing variableSpacingGrammarSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages/simdna-0.4.3.1-py3.7.egg\n",
      "Searching for python-dateutil==2.8.0\n",
      "Best match: python-dateutil 2.8.0\n",
      "Adding python-dateutil 2.8.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pyparsing==2.3.1\n",
      "Best match: pyparsing 2.3.1\n",
      "Adding pyparsing 2.3.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for kiwisolver==1.0.1\n",
      "Best match: kiwisolver 1.0.1\n",
      "Adding kiwisolver 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for setuptools==41.0.1\n",
      "Best match: setuptools 41.0.1\n",
      "Adding setuptools 41.0.1 to easy-install.pth file\n",
      "Installing easy_install script to /users/hannahgz/anaconda3/bin\n",
      "Installing easy_install-3.6 script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Finished processing dependencies for revcompexp==0.1.0.0\n",
      "/users/hannahgz/revcomp_experiments\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "!git clone https://github.com/kundajelab/revcomp_experiments.git\n",
    "%cd revcomp_experiments/\n",
    "!python setup.py install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: concise in /users/hannahgz/anaconda3/lib/python3.7/site-packages (0.6.6)\n",
      "Requirement already satisfied: descartes in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (0.20.3)\n",
      "Requirement already satisfied: keras>=2.0.4 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (2.2.4)\n",
      "Requirement already satisfied: scipy in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (1.2.1)\n",
      "Requirement already satisfied: gtfparse>=1.0.7 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (1.2.0)\n",
      "Requirement already satisfied: numpy in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (1.16.2)\n",
      "Requirement already satisfied: shapely in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (1.6.4.post2)\n",
      "Requirement already satisfied: pandas in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (3.0.3)\n",
      "Requirement already satisfied: hyperopt in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from concise) (0.1.2)\n",
      "Requirement already satisfied: pyyaml in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras>=2.0.4->concise) (5.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras>=2.0.4->concise) (1.0.8)\n",
      "Requirement already satisfied: h5py in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras>=2.0.4->concise) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras>=2.0.4->concise) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras>=2.0.4->concise) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from pandas->concise) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from pandas->concise) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->concise) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->concise) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->concise) (2.3.1)\n",
      "Requirement already satisfied: pymongo in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from hyperopt->concise) (3.8.0)\n",
      "Requirement already satisfied: networkx in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from hyperopt->concise) (2.2)\n",
      "Requirement already satisfied: tqdm in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from hyperopt->concise) (4.31.1)\n",
      "Requirement already satisfied: future in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from hyperopt->concise) (0.17.1)\n",
      "Requirement already satisfied: setuptools in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->concise) (41.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from networkx->hyperopt->concise) (4.4.0)\n",
      "Requirement already satisfied: keras-genomics in /users/hannahgz/anaconda3/lib/python3.7/site-packages (0.1.0.0)\n",
      "Requirement already satisfied: keras in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras-genomics) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (1.16.2)\n",
      "Requirement already satisfied: h5py in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (1.2.1)\n",
      "Requirement already satisfied: pyyaml in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from keras->keras-genomics) (5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install concise\n",
    "!pip install keras-genomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simdna from git+https://github.com/kundajelab/simdna.git@v0.4.3.1#egg=simdna in /users/hannahgz/anaconda3/lib/python3.7/site-packages/simdna-0.4.3.1-py3.7.egg (0.4.3.1)\n",
      "Requirement already satisfied: numpy>=1.9 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from simdna) (1.16.2)\n",
      "Requirement already satisfied: matplotlib in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from simdna) (3.0.3)\n",
      "Requirement already satisfied: scipy in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from simdna) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->simdna) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->simdna) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->simdna) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from matplotlib->simdna) (2.8.0)\n",
      "Requirement already satisfied: six in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->simdna) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /users/hannahgz/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->simdna) (41.0.1)\n",
      "fatal: destination path 'revcomp_experiments' already exists and is not an empty directory.\n",
      "/users/hannahgz/revcomp_experiments/revcomp_experiments\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing revcompexp.egg-info/PKG-INFO\n",
      "writing dependency_links to revcompexp.egg-info/dependency_links.txt\n",
      "writing requirements to revcompexp.egg-info/requires.txt\n",
      "writing top-level names to revcompexp.egg-info/top_level.txt\n",
      "reading manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "writing manifest file 'revcompexp.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "running install_scripts\n",
      "running build_scripts\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "copying build/scripts-3.7/motif_density_and_position_sim.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n",
      "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/motif_density_and_position_sim.py to 755\n",
      "copying revcompexp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying revcompexp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/revcompexp-0.1.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing revcompexp-0.1.0.0-py3.7.egg\n",
      "Removing /users/hannahgz/anaconda3/lib/python3.7/site-packages/revcompexp-0.1.0.0-py3.7.egg\n",
      "Copying revcompexp-0.1.0.0-py3.7.egg to /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "revcompexp 0.1.0.0 is already the active version in easy-install.pth\n",
      "Installing motif_density_and_position_sim.py script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Installed /users/hannahgz/anaconda3/lib/python3.7/site-packages/revcompexp-0.1.0.0-py3.7.egg\n",
      "Processing dependencies for revcompexp==0.1.0.0\n",
      "Searching for scipy==1.2.1\n",
      "Best match: scipy 1.2.1\n",
      "Adding scipy 1.2.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for matplotlib==3.0.3\n",
      "Best match: matplotlib 3.0.3\n",
      "Adding matplotlib 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for numpy==1.16.2\n",
      "Best match: numpy 1.16.2\n",
      "Adding numpy 1.16.2 to easy-install.pth file\n",
      "Installing f2py script to /users/hannahgz/anaconda3/bin\n",
      "Installing f2py3 script to /users/hannahgz/anaconda3/bin\n",
      "Installing f2py3.7 script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for simdna==0.4.3.1\n",
      "Best match: simdna 0.4.3.1\n",
      "Processing simdna-0.4.3.1-py3.7.egg\n",
      "simdna 0.4.3.1 is already the active version in easy-install.pth\n",
      "Installing densityMotifSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing emptyBackground.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing motifGrammarSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "Installing variableSpacingGrammarSimulation.py script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages/simdna-0.4.3.1-py3.7.egg\n",
      "Searching for python-dateutil==2.8.0\n",
      "Best match: python-dateutil 2.8.0\n",
      "Adding python-dateutil 2.8.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pyparsing==2.3.1\n",
      "Best match: pyparsing 2.3.1\n",
      "Adding pyparsing 2.3.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for kiwisolver==1.0.1\n",
      "Best match: kiwisolver 1.0.1\n",
      "Adding kiwisolver 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Searching for setuptools==41.0.1\n",
      "Best match: setuptools 41.0.1\n",
      "Adding setuptools 41.0.1 to easy-install.pth file\n",
      "Installing easy_install script to /users/hannahgz/anaconda3/bin\n",
      "Installing easy_install-3.6 script to /users/hannahgz/anaconda3/bin\n",
      "\n",
      "Using /users/hannahgz/anaconda3/lib/python3.7/site-packages\n",
      "Finished processing dependencies for revcompexp==0.1.0.0\n",
      "/users/hannahgz/revcomp_experiments\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kundajelab/simdna.git@v0.4.3.1#egg=simdna\n",
    "!git clone https://github.com/kundajelab/revcomp_experiments.git\n",
    "%cd revcomp_experiments/\n",
    "!python setup.py install\n",
    "%cd ..\n",
    "import simdna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import gzip\n",
    "import os\n",
    "import json\n",
    "from simdna import random\n",
    "\n",
    "\n",
    "DEFAULT_LETTER_TO_INDEX = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "\n",
    "\n",
    "DEFAULT_BACKGROUND_FREQ = OrderedDict(\n",
    "    [('A', 0.3), ('C', 0.2), ('G', 0.2), ('T', 0.3)])\n",
    "\n",
    "\n",
    "DEFAULT_DINUC_FREQ = OrderedDict([\n",
    " ('AA',0.095),\n",
    " ('AC',0.050),\n",
    " ('AG',0.071),\n",
    " ('AT',0.075),\n",
    " ('CA',0.073),\n",
    " ('CC',0.054),\n",
    " ('CG',0.010),\n",
    " ('CT',0.072),\n",
    " ('GA',0.060),\n",
    " ('GC',0.044),\n",
    " ('GG',0.054),\n",
    " ('GT',0.050),\n",
    " ('TA',0.064),\n",
    " ('TC',0.060),\n",
    " ('TG',0.073),\n",
    " ('TT',0.095),\n",
    "])\n",
    "\n",
    "\n",
    "def get_file_handle(filename,mode=\"r\"):\n",
    "    if (re.search('.gz$',filename) or re.search('.gzip',filename)):\n",
    "        if (mode==\"r\"):\n",
    "            mode=\"rb\";\n",
    "        elif (mode==\"w\"):\n",
    "            #I think write will actually append if the file already\n",
    "            #exists...so you want to remove it if it exists\n",
    "            if os.path.isfile(filename):\n",
    "                os.remove(filename);\n",
    "        return gzip.open(filename,mode)\n",
    "    else:\n",
    "        return open(filename,mode) \n",
    "\n",
    "\n",
    "def default_tab_seppd(s):\n",
    "    s = trim_newline(s)\n",
    "    s = split_by_delimiter(s, \"\\t\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def trim_newline(s):\n",
    "    return s.rstrip('\\r\\n')\n",
    "\n",
    "\n",
    "def split_by_delimiter(s, delimiter):\n",
    "    return s.split(delimiter)\n",
    "\n",
    "\n",
    "def perform_action_on_each_line_of_file(\n",
    "    file_handle\n",
    "    #should be a function that accepts the\n",
    "    #preprocessed/filtered line and the line number\n",
    "    , action\n",
    "    , transformation=default_tab_seppd\n",
    "    , ignore_input_title=False\n",
    "    , progress_update=None\n",
    "    , progress_update_file_name=None):\n",
    "\n",
    "    i = 0;\n",
    "    for line in file_handle:\n",
    "        i += 1;\n",
    "        line = line.decode(\"utf-8\")\n",
    "        process_line(line, i, ignore_input_title,\n",
    "                     transformation, action, progress_update)\n",
    "        print_progress(progress_update, i, progress_update_file_name)\n",
    "\n",
    "    file_handle.close();\n",
    "\n",
    "\n",
    "def process_line(line, i, ignore_input_title,\n",
    "                 transformation, action, progress_update=None):\n",
    "    if (i > 1 or (ignore_input_title==False)):\n",
    "        action(transformation(line),i)\n",
    "\n",
    "\n",
    "def print_progress(progress_update, i, file_name=None):\n",
    "    if progress_update is not None:\n",
    "        if (i%progress_update == 0):\n",
    "            print (\"Processed \"+str(i)+\" lines\"\n",
    "                   +str(\"\" if file_name is None else \" of \"+file_name))\n",
    "\n",
    "\n",
    "class VariableWrapper():\n",
    "    \"\"\" For when I want reference-type access to an immutable\"\"\"\n",
    "    def __init__(self, var):\n",
    "        self.var = var   \n",
    "\n",
    "\n",
    "def enum(**enums):\n",
    "    class Enum(object):\n",
    "        pass\n",
    "    to_return = Enum\n",
    "    for key,val in enums.items():\n",
    "        if hasattr(val, '__call__'): \n",
    "            setattr(to_return, key, staticmethod(val))\n",
    "        else:\n",
    "            setattr(to_return, key, val)\n",
    "    to_return.vals = [x for x in enums.values()]\n",
    "    to_return.the_dict = enums\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def combine_enums(*enums):\n",
    "    new_enum_dict = OrderedDict()\n",
    "    for an_enum in enums:\n",
    "        new_enum_dict.update(an_enum.the_dict)\n",
    "    return enum(**new_enum_dict)\n",
    "\n",
    "\n",
    "def sampleFromProbsArr(arrWithProbs):\n",
    "    \"\"\"Samples from a discrete distribution.\n",
    "    Arguments:\n",
    "        arrWithProbs: array of probabilities\n",
    "    Returns:\n",
    "        an index, sampled with the probability of that index in\n",
    "    array of probabilities.\n",
    "    \"\"\"\n",
    "    randNum = random.random()\n",
    "    cdfSoFar = 0\n",
    "    for (idx, prob) in enumerate(arrWithProbs):\n",
    "        cdfSoFar += prob\n",
    "        if (cdfSoFar >= randNum or idx == (len(arrWithProbs) - 1)):  # need the\n",
    "            # letterIdx==(len(row)-1) clause because of potential floating point errors\n",
    "            # that mean arrWithProbs doesn't sum to 1\n",
    "            return idx\n",
    "\n",
    "\n",
    "reverseComplementLookup = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G',\n",
    "                           'a': 't', 't': 'a', 'g': 'c', 'c': 'g', 'N': 'N', 'n': 'n'}\n",
    "\n",
    "\n",
    "def reverseComplement(sequence):\n",
    "    reversedSequence = sequence[::-1]\n",
    "    reverseComplemented = \"\".join(\n",
    "        [reverseComplementLookup[x] for x in reversedSequence])\n",
    "    return reverseComplemented\n",
    "\n",
    "\n",
    "def sampleWithoutReplacement(arr, numToSample):\n",
    "    arrayCopy = [x for x in arr]\n",
    "    for i in range(numToSample):\n",
    "        randomIndex = int(random.random() * (len(arrayCopy) - i)) + i\n",
    "        swapIndices(arrayCopy, i, randomIndex)\n",
    "    return arrayCopy[0:numToSample]\n",
    "\n",
    "\n",
    "def swapIndices(arr, idx1, idx2):\n",
    "    temp = arr[idx1]\n",
    "    arr[idx1] = arr[idx2]\n",
    "    arr[idx2] = temp\n",
    "\n",
    "\n",
    "def get_file_name_parts(file_name):\n",
    "    p = re.compile(r\"^(.*/)?([^\\./]+)(\\.[^/]*)?$\")\n",
    "    m = p.search(file_name)\n",
    "    return FileNameParts(m.group(1), m.group(2), m.group(3))\n",
    "\n",
    "\n",
    "class FileNameParts(object):\n",
    "\n",
    "    def __init__(self, directory, core_file_name, extension):\n",
    "        self.directory = directory if (directory is not None) else os.getcwd()\n",
    "        self.core_file_name = core_file_name\n",
    "        self.extension = extension\n",
    "\n",
    "    def get_full_path(self):\n",
    "        return self.directory+\"/\"+self.file_name\n",
    "\n",
    "    def get_core_file_name_and_extension(self):\n",
    "        return self.core_file_name+self.extension\n",
    "\n",
    "    def get_transformed_core_file_name(self, transformation, extension=None):\n",
    "        to_return = transformation(self.core_file_name)\n",
    "        if (extension is not None):\n",
    "            to_return = to_return + extension\n",
    "        else:\n",
    "            if (self.extension is not None):\n",
    "                to_return = to_return + self.extension\n",
    "        return to_return\n",
    "\n",
    "    def get_transformed_file_path(self, transformation, extension=None):\n",
    "        return (self.directory+\"/\"+\n",
    "                self.get_transformed_core_file_name(transformation,\n",
    "                                                    extension=extension))\n",
    "\n",
    "\n",
    "def format_as_json(jsonable_data):\n",
    "    return json.dumps(jsonable_data, indent=4, separators=(',', ': '))\n",
    "\n",
    "\n",
    "class ArgumentToAdd(object):\n",
    "    \"\"\"\n",
    "        Class to append runtime arguments to a string\n",
    "        to facilitate auto-generation of output file names.\n",
    "    \"\"\"\n",
    "    def __init__(self, val, argumentName=None, argNameAndValSep=\"-\"):\n",
    "        self.val = val;\n",
    "        self.argumentName = argumentName;\n",
    "        self.argNameAndValSep = argNameAndValSep;\n",
    "    def argNamePrefix(self):\n",
    "        return (\"\" if self.argumentName is None else self.argumentName+str(self.argNameAndValSep))\n",
    "    def transform(self):\n",
    "        string = (','.join([str(el) for el in self.val])\\\n",
    "                   if (isinstance(self.val, str)==False and\n",
    "                       hasattr(self.val,\"__len__\")) else str(self.val))\n",
    "        return self.argNamePrefix()+string;\n",
    "        # return self.argNamePrefix()+str(self.val).replace(\".\",\"p\");\n",
    "\n",
    "\n",
    "class FloatArgument(ArgumentToAdd):\n",
    "    \"\"\"\n",
    "       Replace the period with a p \n",
    "    \"\"\"\n",
    "    def __init__(self, val, argumentName=None, argNameAndValSep=\"-\"):\n",
    "        self.val = val;\n",
    "        self.argumentName = argumentName;\n",
    "        self.argNameAndValSep = argNameAndValSep;\n",
    "    def argNamePrefix(self):\n",
    "        return (\"\" if self.argumentName is None else self.argumentName+str(self.argNameAndValSep))\n",
    "    def transform(self):\n",
    "        string = str(self.val)\n",
    "        string = string.replace(\".\",\"p\")\n",
    "        return self.argNamePrefix()+string\n",
    "\n",
    "\n",
    "class BooleanArgument(ArgumentToAdd):\n",
    "\n",
    "    def transform(self):\n",
    "        assert self.val  # should be True if you're calling transformation\n",
    "        return self.argumentName\n",
    "\n",
    "\n",
    "class CoreFileNameArgument(ArgumentToAdd):\n",
    "\n",
    "    def transform(self):\n",
    "        import fileProcessing as fp\n",
    "        return self.argNamePrefix() + fp.getCoreFileName(self.val)\n",
    "\n",
    "\n",
    "class ArrArgument(ArgumentToAdd):\n",
    "\n",
    "    def __init__(self, val, argumentName, sep=\"+\", toStringFunc=str):\n",
    "        super(ArrArgument, self).__init__(val, argumentName)\n",
    "        self.sep = sep\n",
    "        self.toStringFunc = toStringFunc\n",
    "\n",
    "    def transform(self):\n",
    "        return self.argNamePrefix() + self.sep.join([self.toStringFunc(x) for x in self.val])\n",
    "\n",
    "\n",
    "class ArrOfFileNamesArgument(ArrArgument):\n",
    "\n",
    "    def __init__(self, val, argumentName, sep=\"+\"):\n",
    "        import fileProcessing as fp\n",
    "        super(ArrOfFileNamesArgument, self).__init__(val, argumentName,\n",
    "                                                     sep, toStringFunc=lambda x: fp.getCoreFileName(x))\n",
    "\n",
    "\n",
    "def addArguments(string, args, joiner=\"_\"):\n",
    "    \"\"\"\n",
    "        args is an array of ArgumentToAdd.\n",
    "    \"\"\"\n",
    "    for arg in args:\n",
    "        string = string + (\"\" if arg.val is None or arg.val is False or (hasattr(\n",
    "            arg.val, \"__len__\") and len(arg.val) == 0) else joiner + arg.transform())\n",
    "    return string\n",
    "class Embedding(object):\n",
    "    \"\"\"Represents something that has been embedded in a sequence.\n",
    "    Think of this as a combination of an embeddable + a start position.\n",
    "    Arguments:\n",
    "        what: object representing the thing that has been embedded.\\\n",
    "            Should have`` __str__`` and ``__len__`` defined.\\\n",
    "            Often is an instance of :class:`.AbstractEmbeddable`\n",
    "        startPos: int, the position relative to the start of the parent\\\n",
    "            sequence at which seq has been embedded\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, what, startPos):\n",
    "        self.what = what\n",
    "        self.startPos = startPos\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"pos-\" + str(self.startPos) + \"_\" + str(self.what)\n",
    "\n",
    "    @classmethod\n",
    "    def fromString(cls, string, whatClass=None):\n",
    "        \"\"\"Recreate an :class:`.Embedding` object from a string.\n",
    "        Arguments:\n",
    "            string: assumed to have format:\\\n",
    "                ``description[-|_]startPos[-|_]whatString``, where\n",
    "                ``whatString`` will be provided to ``whatClass``\n",
    "            whatClass: the class (usually a :class:`.AbstractEmbeddable`) that\\\n",
    "                will be used to instantiate the what from the whatString\n",
    "        Returns:\n",
    "            The Embedding class called with\n",
    "            ``what=whatClass.fromString(whatString)`` and\n",
    "            ``startPos=int(startPos)``\n",
    "        \"\"\"\n",
    "        if (whatClass is None):\n",
    "            from simdna.synthetic.embeddables import StringEmbeddable\n",
    "            whatClass = StringEmbeddable\n",
    "        # was printed out as pos-[startPos]_[what], but the\n",
    "        #[what] may contain underscores, hence the maxsplit\n",
    "        # to avoid splitting on them.\n",
    "        p = re.compile(r\"pos\\-(\\d+)_(.*)$\")\n",
    "        m = p.search(string)\n",
    "        startPos = m.group(1)\n",
    "        whatString = m.group(2) \n",
    "        return cls(what=whatClass.fromString(whatString),\n",
    "                   startPos=int(startPos))\n",
    "      \n",
    "def getEmbeddingsFromString(string):\n",
    "    \"\"\"Get a series of :class:`.Embedding` objects from a string.\n",
    "    \n",
    "    Splits the string on commas, and then passes the comma-separated vals\n",
    "        to :func:`.Embedding.fromString`\n",
    "    Arguments:\n",
    "        string: The string to turn into an array of Embedding objects\n",
    "    Returns:\n",
    "        an array of :class:`.Embedding` objects\n",
    "    \"\"\"\n",
    "    if len(string) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        embeddingStrings = string.split(\",\")\n",
    "        return [Embedding.fromString(x) for x in embeddingStrings]\n",
    "      \n",
    "def read_simdata_file(simdata_file, one_hot_encode=False, ids_to_load=None):\n",
    "    ids = []\n",
    "    sequences = []\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    if (ids_to_load is not None):\n",
    "        ids_to_load = set(ids_to_load)\n",
    "    def action(inp, line_number):\n",
    "        if (line_number > 1):\n",
    "            if (ids_to_load is None or (inp[0] in ids_to_load)):\n",
    "                ids.append(inp[0]) \n",
    "                sequences.append(inp[1])\n",
    "                embeddings.append(getEmbeddingsFromString(inp[2]))\n",
    "                labels.append([int(x) for x in inp[3:]])\n",
    "    perform_action_on_each_line_of_file(\n",
    "        file_handle=get_file_handle(simdata_file),\n",
    "        action=action,\n",
    "        transformation=default_tab_seppd)\n",
    "    return enum(\n",
    "            ids=ids,\n",
    "            sequences=sequences,\n",
    "            embeddings=embeddings,\n",
    "            labels=np.array(labels))\n",
    "  \n",
    "\n",
    "\n",
    "def perform_action_on_each_line_of_file(\n",
    "    file_handle\n",
    "    #should be a function that accepts the\n",
    "    #preprocessed/filtered line and the line number\n",
    "    , action\n",
    "    , transformation=default_tab_seppd\n",
    "    , ignore_input_title=False\n",
    "    , progress_update=None\n",
    "    , progress_update_file_name=None):\n",
    "\n",
    "    i = 0;\n",
    "    for line in file_handle:\n",
    "        i += 1;\n",
    "#         line = line.decode(\"utf-8\")\n",
    "        process_line(line, i, ignore_input_title,\n",
    "                     transformation, action, progress_update)\n",
    "        print_progress(progress_update, i, progress_update_file_name)\n",
    "\n",
    "    file_handle.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import keras_genomics\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.layers.core import Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.engine import Layer\n",
    "from keras.models import Sequential \n",
    "import keras.layers as k1\n",
    "from keras.engine.base_layer import InputSpec\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!motif_density_and_position_sim.py --seed 1234 --motifNames GATA_disc1 TAL1_known1 --max-motifs 4 --min-motifs 1 --mean-motifs 2 --zero-prob 0.5 --seqLength 1000 --posSdevInBp 100 --numSeqs 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqName\tsequence\tembeddings\n",
      "synth0\tAGCTTAATTTCGGTCGGATTCGACTGCTCGTCTATTATCTAAAGGGAGCGAGGAGTTTTTAGCACACTAATGCAATCGACCGTGTATTGCAGGTCGGTAGTTTGTAAGATCACTTACATTTTTGAACGAACGTAAATACGATTGACTAGATGAATTTTGGAGTTTTGCTTGCCTATCTTTGCTTCACTCCGAATACGATTTTGTTTACACATGGGCCCCTCATTCGCAACAGTTCACTTCAAAGAAAGATCTGAGGATGGGGATTTGCTGCGCAGTTGACAAGAGGTTTAAGTTGCGTGAATCGGAAGTCTAAAAAGTTGTGGGTATAAAAGCTACTCTGTTTATGATAATTGCAGTTTAGCCATGATTCTGTTTACCATCTGTACACTGTAACTTCTACTTAAGTCAGGATTTATTTTACTTGTGATCTCATAGAAGTGTCAATACAGGGTTATGATGGCCTAACAGATGTAATAAACGATATCTCACTAGCGAATTAGTTGAATAGTAGCAAAAACATTTAGTTACGGGTTCATCATAGCAACAGATGGCCGAATTCAAATACGGCCACTTATATAACTTCAGAAGGATTTCCCCGGATTATAGAACACTGGGAGTAGTTCCTAAACAGACCTGGGATCAGATGGTCGACTTCAGCTGTTCAACGGGATTCTAAGTAGAAATCAGGCTACACACGAAATCCTACGTCTGTTTAAAATTTCGAATATTCTCAGCGCGTGTAAGGTTTGATCGGCACTGAGATTGCCTAGCAATTTCAGGTGATTATATTTGCGATACTCGATGCATAAAGGTATACTAATTAGCTAAACAAAATATCTACGGCCCCCCGTGCATAGTTCATGTGCTTGTATTCTGCGTACTGCACTGCGATGTTCTTGGTCATGCATGACGCCCGTTTGGTGTTTGACAATAAGGCCAAAATCTTTTGCTAACCTGAGTATATGCATTGCAATCCATTGTATTCTAGACCAACCTTAGC\tpos-539_TAL1_known1-AGCAACAGATGGCCGA,pos-372_revComp-TAL1_known1-TTTACCATCTGTACAC,pos-635_TAL1_known1-GGGATCAGATGGTCGA,pos-460_TAL1_known1-CCTAACAGATGTAATA\n",
      "synth1\tCCATTTGCTTCCATAAATTGGCAGCAGGAACGATAAAATTAACTTATTGCAGGAGACTCAAACGATTACCGCCACACTTATCCAGAAATCGTAACCTTCAAAATTAGTCGAGATTAGTCGACTCCAAGGATACCGGTACGGTAGACTAATGTTTTGATGTCATTTCAAGATACTGCGCATTTAACGAATTTATAATTCGGAATGTATATATCCAGAACTCTATTATTTAATAAAATCTAATCACGCACTAGTTGAAACCGAAAGACTTAGATATACCATATAATCTTTTTATGTGGGGATATGAAGTGTCCGTAGATAAGAGAATTCCCAGTACCGCAGAAATTATGAAATCGCGTGTTGGGATATAACAAGCAGACAATCCTTGTTCGAACTCGGGTACGAGTTTTCAGACATATTATAACACGATAACGGTGAGTTAGAGGACGTACGGAGTTAAGGATAATCCCTAAGACCGCCAAGCTTTTATGGCGAACTTTATGCTACTATCATATATCCATTCTCGAAATTCTGTAAGTATACCATGAGGCATCAGGAATAATTTGTCCCCTAAATGTTAAAGGTTAAAAACAATTTAGGTCATTTTCGGCCCTCGAGGGGGCTGCCTTAAAGAGGAGTCACACGAACGCTCAGTCAGTATAAATGGGTAGAAAGATCGCTTTAGAAAACAGTTGAAAAAAACGAAGAACGTTTCCGTAAACAGTCAATCTAATATTAACAACATTTTGATTTTTATTTAAAAAAATTAATGTTAGTAGTAACGGTCCCCATAATTTTAGAGACTCCTGATAGGCAGCTAGGAATAAAAGTTCACTACTTTGGAAATCAATCTTTCGCTGCCGGATCCCGATTAGTTGCTTTTTTCTAATGTCGAGACAATTGATTTTTCCTTAACTGAATGACTTTTTTGCATTAAGTCTGTCGATGAGTTTGTAACTACTGGACCGCAATCTCTGAGAGGGCATTACCGGTAGATAACACC\t\n",
      "synth2\tTTTTGGCTATCTGTAGTGGCTAAGCCGTTTTGGAGTACATTAAGACATTTGAAACACGTGAACGTATTCTATCTGTTTATTATCTCTTTTCTTCCCATTCGACACGCTATGCTTTGGTGGATTGGCATATCATCCGTCGCAAACTATGTATGAACCTGATGAGCCATTACCAACGATAATTTTTCGATAATGCGTTTTCACTGTTCGAATGCAAGCCTTTACAGACCCTTTAATATTCAGTTAATTATTATATGCAGGGGATCTCGAAAAACCTCTGTCGTGCGCTTGTTGTTTAACAAAAGATTTTATGAACGGTTTACCGCAATAATTAAAGTTAGCACAATTCTATAGCTACGAGACAATAGTCGCGTAGGAAAAGGTCGTCATGCACAGAAACAATCGGAAGGAATTAGGAACGTACTTAGCCTGTCGTGAATGTGTACTGTGTTTATGGCGTGCGATCTCATAAACAAAATAGATACATTCATGAGTTAAGACATTGTCAATTGTTCAATAGGCAAGTGCTAGGTTTCAGTTGGAATAATATCGGCTCTTGGGGTAAATGTAAGGCAAAATGCCCATAATTTCCGCTTTAATCTTCTGAGGTACCGGCATGAGTCTGTCCACCCTCGCTAGGTGACCATTCATACTAAGGCTGCCACGGTTGGCATATAATGGATGGGCAAGACTTCACACGTGAGCCTTGTGTGTATGAATAAAAACTTTCATGGGTGAACATACGAACTCCGATTTCGGTATATTCAGAAATAATTCATAAGCTTTTTGTGACGGCCATTGATGCCGATGAGTATCGGTAATTTACAAGTAAGACCTCACTATTAATCATATAATCCACTGGAGCTTTCTTCCTTGATTCATCGTTAAGCTATCGGCATTCCCCTGCAGCTAAATGCACTCTTGTCTCAAAACCATGGTTGAGTTATGGTGTGGGTACTTATAGATGATGCAAACTAGCAGAATAACAGGACACGTGTCGCGA\t\n",
      "synth3\tTACTTCACCATATTCCACGCACCTCAAGTTAGGGGCTCATGTTACTCATGGGGATACCCAATTGTTCCTCTATGAGTGTAAACTACCGAGAGGGTAATGGTGATATGGGAGTATATCTCCTGTTCTGTTAAGCGGTGCCCAAGAATTGGGTTGAAATGCTGGATTCGGGTCGTATGGATTATGACAAGTGGGTCCCCGCCTAGGAGTGAACCATACTTCCAACGAACTGAGGCATGGGATAATGCTTTAATATAGCACCCACACTAGCCGACCAGATGTAACGATGCCGGACCTGTAAAAGATCGAAATTTGTAGGCTTTACTGTTTTCATGGGATAAAACGCGGTGTGTAATAATTGCTTTTTTCGGATGACATAAAATATAACTAATCCAGTTAGATGAGGCGAAAGCTACGGGCGGTCAAAAGATAAGGGGTACTCAGCGCTAACAAAGTTTTTTACTAGTAAGTTTAATTGCAGGTTATATCTCAATGTGCGAGCATCTGTTCCAAAATACTTCGGATTTCATGAGTTGAATAACCTGAAACCCTACCGGTATAAGAATACGGACTATATCAATATCTTAACAGATGTTCAATGAATTTAGTGTTAACCATCTGTGCCCACCCACTTAATGACTGTTGCTATCACGGCGGAAGTATGTTAACAGGCTAAGATAAAGTCAAACTCCAGTGCGTATGGGCCTCATTATGAGGAACGGGGTTCGTTCCCTCGAACGGGCTCGTTCGGATATACTGAAGCTTTCACATTGAGGCATACGGTTCACTCGCTTACGATCAGATAGCCGTATTGCGATTCTGACTTCTGAGTAAATCTGCACGTGATCTAGTGAAATATTGTAGGACTATTGTTTGCAAGGCTAGGAACCACTTTTACATAACTTAACTCTAATAGTTCTGGCCAATAAAGATAAACCCGTCTTTGGAAATGATGACGGCTTAACATGGCCGTATCCACGTCTAACAGTCGTTTTTTTGGGAG\tpos-422_GATA_disc1-AAAGATAAGG,pos-580_TAL1_known1-CTTAACAGATGTTCAA,pos-493_revComp-TAL1_known1-GCGAGCATCTGTTCCA,pos-267_TAL1_known1-CCGACCAGATGTAACG,pos-607_revComp-TAL1_known1-TTAACCATCTGTGCCC\n",
      "synth4\tTCGTTTCGCATCACTAAACATAAAATCCAATGTTGCGAGTACAATATAGTCCTCTTACAAATGGTATGTGGTGAGTATCCTTACTATGTGAAACGACGGCCTTAGTCTATTCGTGTATATTGTCGCATTGTTGTACTCTAACGGGTCACACCGTTCCGTAGTCGTTTCCTTGGATGAAGCTAGTGCCTGCAGCATCAGCCGAGCCATAGAAGGAACTGACATATTATATTAGTCTTCTGTATAACAATTGTAAAGAAAATGAAGCCCACTGCAATCCATAAACGTGATCAAGGATATGAATAAAGAAAGAAAAACGATAATGCGATATTTGAGTCAACGGTCCTGGTGTTGCAGAATATAGAGGCATTTATTAGTAACGTGCTGTGATCTGTTGCAATATAAACTAGTTTTCTCTGTTTAACATAACGCAGGATTAGAAGGATGCGTCACGCTGATATATGGGTTGTGTAACGTTGACAAAAGGTCGACTCCGTGGATACGAGCTTAAGAAGAGGCCAAAAGAAAACTCTGATGACTCGTACAAACCATCTATGTTAAAGTATAACTGACTTACCTAACGATTGTCACTGAAGGGGTGAACAAGGCCGGCATGTTTACAACAGTGAAATGCGCGAAATGTCTATTATATAAATTTCTTATGTACATATATCCGGATAGACAATATATCACCATAACCGACGACGGAGATGAAAGGGTTAAGAACGAGCATACGCTGAGGCAATTCGCCATTTATTCCTAATATCGGAGATATCGACCCTAATGTTCTCTCACTCTGGCAATAGAGTGCTATGTTCAGCACATTGAGTCAGGTCCTAAAAGAACAGTGTATCCAAAGATAGAGCAAACAGTTCGTACATATGACAGACTAGTCTTAAACATCGAACTTGAGGACCCGTGTAATTACTTATAAAAAGATCTAAACCGCTCGCTTGATAAAATTAAGTACAAATTTACGAACAAGAGCATGAATTACCCTGAC\t\n",
      "synth5\tGGTGATTCAAATTCATTTCACTTTGCACTGAAAAGGCACGAAGGACTTCTGTCTAGACTAAGGTCCGCCCCGAAAAACTCTATTGTTCAAGGCAGTTGATCGCGCATTAAACTCAGAAAATAATGTACTTAAAACATGCACTACCTCTAATCGCTTGCTGCTAATACGAAACAGACCATGTTGCGACGCTAATGTTCAAGCTAAAATCTTGGGTCTGCTTTTAGTTTTTCCTAGTACAGAATCCTCCAAATCAGTCAATGGGCGTCTGACAGTGGAAGGGGGCTGTTATCCAATCTTCCGAACTATATGGAATACGACGGCTTATTTGTCTAAACTATTACTATTCACGTTGGATAATGATCATTAAGCACCCTACACTGTGTTCGATGAGGTTGATTACTGAATAATTATCTTATGCTACACAGGGCCTGAATAATTTTATCGATATTGACTTTTAGTAATGGTAGAAACATATTTATTTACAACGTACAGCCTGGAATCTGTGGTCTGGATACGGAAGATGCTCGGAGTTGAATGTGATGATCTTCCGAAAATAATATCCTGTGTCCGATTAGATACCCTACGACATTTGTTTCTGATACGGCTGGTCAAAGCTTCTGAGCGTTCTGTCTTTGAGAACCAGGGCATGTCCGGTCAGGTATAGATGTTTCATTGGGGTAGGATCCTATGTTATCTAATTTGGGGTCATAACGCTAGCGAAGACTAAGATCGCCATCATCGGAGATGACAGGTTGGGAGATACGCGAATGATTTCAGAGAGAACGTACAGCTTTCACTAAGTTTCTTAAATAACCATGTCTCCACACCCATCTTCAGTTCCAAGACAATGATTAGAGCTTGGGTCTTGCACGCTGGTGCAACGCAAGGAAATTAATAACAGTCTAGTTGAACTTACTGACGCAGGCTGTAACAATTTAATGTAGAATTAACAAAGATTTTCACGTATATCTAATAGTTTATTGTTGAGGGTTTGCTCAGT\tpos-594_GATA_disc1-TCTGATACGG\n",
      "synth6\tTTGCTTCCCAAATTATTCCTTGATCATGTACAAAACTAACATGTCGCCGATAAATACTAAGTGAAGTAAAAAAGCGAAATTATAGGATTAGCGGAAGATGGTGCGCTCCATATTTGCAAATACACACCGGTTGAATTAACAGCTCTATCTCGTGTAAGTGGATTTTCGGGGAAGTAACATGCTAACGGATTAGCAATGCCGTATGTGGTCATCCAATGATGATAACCACTGCATGTTGGGTTCGTCTATTGGTTAATTCACGGTGGTACAGGTAAAGTCAAAATTCTTCGGGAACAGATGTTCAGGTCATATGCGGTAAATTTCGGAGGCACCTCGGGGTCCGCGATCGAACTGCTGCAGCTACTTCACGTAGCTATTGCATATTTGTATGCTAATTCGTCCAAAAACGTTAAGACAGATTTCATGGGACGCGGATTTAACAGCCTTTCTAGGCTGTCCTACAACATTAAGTAGATAGATTTGAGAGCTGCGTGTTTTGCCACCCACAATTGCCATATCCGGACATTGTGTTGGACACCTGAAAAGTACAGTTGATACTTTGAATAGCCCACTTCGCGCTATATCCACCAAACAGATGGTCGGCTGAAAAAGTTTACCCAAGAATCTAGCGATCTAAACAGCGCCGTAGTTTCGTTCTTTCTTCTCGTAAACCAAGAGTCGCAACACAAGTCAGTTTAGTTAAAACCTGCGAGTGTCGGTCAATTACCAGCTCACAATGCTTAATTACATACTATTTTAATTCAATCAAAAGTAGCTCTCTGCGAATCTAGTAGACGAGTTCATGTGCCTCGCGGCATTAAAACAGACAGTTATTGATAATTCTGGGTGTGTACTTCATCCCTTTAAGAGGTAGTATTAAGAAATTGTCACGTCGAACCCGATTAGGTCTTCTGGCGGATAGAGTAACGTTCGACCCGGTTGTACAATTGGACACCCGACCCGCATCAACGCTAATAAACAAACATTGTTTTAGTTTTTT\tpos-587_TAL1_known1-CCAAACAGATGGTCGG,pos-289_TAL1_known1-GGGAACAGATGTTCAG\n",
      "synth7\tACCGTATGCGATCTACATGATGCACTCATACCTCCTCATGTCGGCTTATTTTTATGGTATACGGTGTTCTTGACGAAATGGTCAGGGGGGGTTTGTCGGTTGTAGCTATTCCCCGCTATTGATCTAAACCCCGTACGCATGATATTCTTGGGGCTCCTTCAGAGGAAGTTTTTATGCCTTATAGCCGTTGAGAACAAAATACATTAATCCTTAATTACCCAGAATGACCCACAATGATCAACGAGACCACAATATCGCTCGATCAGCGAAGCAGTGTTTGATGTATGTCTTCGAGGTACGTTTCAAGTGGTTTGGCTTTCTCTGCAAGAGATGTCGTCATTGATCGCTCTACGCATTGTTCAATCGCGCTAGCTGCGCTATGTACTACCTGAGAAGAGATGATAACTCAAAGAATACGAAGGAATATCCAATATCTGCAGAAGGTTTAGCCTTATAATATCGCAGATAAGAACGCGACGTGATTTTGCATCCGCACCTGATAAGCGTATATCTTTGGTTGGAATAACTGACGTTATCTTATCTCTGTGAAAAATTGCTTGGATCATAATCAACCTGGGGTACGTAAGAAGTCAATATTGTATTATTTAGTCCTCCGGAGATCGGGGGGCCATCTGTTGCGGTTAATGATGATCGCTATGTTGGAATTATAGTCGTTTCCTAATTAAGTTTTTCTAATTATAGGGAATGCAGAGGGATGCGCTTTCTCAGCACCAACAACTAGAAAAAACCAACTACGAATCAAAATGAAATCGCAGCATTAGAATTTTGTCACTCAGGCAGTACGCGCGAATAATTAACGACTGACTTAACTGCCACTGTGTCAAAATTGTGATACGACTTTGTTTGAAAACGAAAGCAGATCGTCTCGCTCTTTTTTGCTCACTTTAGCAAACTACCTCATTACAGTATTTGACTAAAAAAGCTTAGGATGATAACGAGCTTTAGCTCAAACATATAAATGGGCCTTCAACATATCTTA\tpos-461_GATA_disc1-GCAGATAAGA,pos-495_GATA_disc1-CCTGATAAGC,pos-535_revComp-GATA_disc1-TCTTATCTCT,pos-624_revComp-TAL1_known1-GGGGCCATCTGTTGCG\n",
      "synth8\tAAGTTTGGTCAAATTATACTAGATTAATCAAAGACGACTTTTACAATGCCTATCATGCAATTACAGTTTGTATCTATTGATTTTTAAGTTATGGAGCGAATCTGAAACAAACACTGAGGAATGACATAAAACAAATGGGTTCGCTCGAGATTTCGATCTGAATGGTAATCGGTCTCCTGCGAGCGAAAACCAAAGCTGTTATGCCAACTAAACATTTGCATAGTAGCTTGTCAATGGCATCGGGACAAATTATGCTGTTTGACTGAGTTGTTTAAATTTAATAGACGGTAATCCACTCATAGGAATTAGTTATTGTGATTCTTATACGTTTTCGCATTTTACAGATTAGAGATATACTCTTATACAGAGGTAGATCATTGATACATATAGACGTCCCACTCAGGGTTATATTTTCAAAAAACCCGGAAAGTATTTCTTTGTGTGAATAAAGGAAGCGAGATAATTGAGCCACCGCATGATTACGAAGTAAGTAGATGGAGCAACGTGTAGGTTATCTAAATAATGAGGGTGATACTTTAAATACTCAGATGATATTTCTGCCCCTCTATGACGCTAATATCACACACTTTCGTTTCATGGTGACCCGTGGTTAATGTTGAAGATTCTTTTCCTGATAATGATAAAGAAGTCCAATTACCGTTCAGACAACTGTAGTTTTGTTATCAAATTTTAGTCACGTTCCCATACGAATAGTTAAACGAGCATGATGTTATGCCTTCATTAGGTTACTGACATCCTTACATAAGAAGGAACACCCTTGGTACATATACCTTGAGAGAAAGACGGGCTGGGTTGATGAGTCTGGATCTACTTGGAGTGGAAGTTGCAATTATGCTCCGGTAATTACAAATTTTATCATAACCCGCCACTCTATAATTCACTGAGTCGAAGTTTCTTAAAAGAGCCACGTATAGGTTGTCAGTGTCTCGTGGACCTACGAATCTTTCTAGCAACTACTAAGAGGGACACTGTAGGGTTA\tpos-340_GATA_disc1-ACAGATTAGA,pos-474_GATA_disc1-CATGATTACG\n"
     ]
    }
   ],
   "source": [
    "!head DensityEmbedding_motifs-GATA_disc1+TAL1_known1_min-1_max-4_mean-2_zeroProb-0p5_seqLength-1000_posSdevInBp-100_numSeqs-20000.simdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = read_simdata_file(\"DensityEmbedding_motifs-GATA_disc1+TAL1_known1_min-1_max-4_mean-2_zeroProb-0p5_seqLength-1000_posSdevInBp-100_numSeqs-10000.simdata\").sequences\n",
    "embeddings = read_simdata_file(\"DensityEmbedding_motifs-GATA_disc1+TAL1_known1_min-1_max-4_mean-2_zeroProb-0p5_seqLength-1000_posSdevInBp-100_numSeqs-10000.simdata\").embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(embeddings): \n",
    "    if len(embeddings) > 0:\n",
    "        all_chars = \"\"\n",
    "        for x in embeddings: \n",
    "            all_chars += str(x.what)\n",
    "        if 'TAL' in all_chars and 'GATA' in all_chars: \n",
    "            return [1, 1]\n",
    "        if 'TAL' in all_chars and 'GATA' not in all_chars:\n",
    "            return [1, 0]\n",
    "        if 'TAL' not in all_chars and 'GATA' in all_chars:\n",
    "            return [0, 1]\n",
    "    return [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.zeros((0,2))\n",
    "for x in embeddings: \n",
    "    thing = check(x)\n",
    "    y = np.append(y, [thing], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def mutate(s, num, target):\n",
    "#     change_locs = set(sample(range(len(s)), num))\n",
    "#     changed = (target if i in change_locs else c for i,c in enumerate(s))\n",
    "#     return ''.join(changed)\n",
    "\n",
    "def mutate(y, mutation_prob):\n",
    "    np.random.seed(1234)\n",
    "    mutated_y = []\n",
    "    for row in y:\n",
    "        new_labels_for_row = []\n",
    "        for label in row:\n",
    "            if np.random.uniform() < mutation_prob:\n",
    "                new_labels_for_row.append(1-label)\n",
    "            else:\n",
    "                new_labels_for_row.append(label)\n",
    "        mutated_y.append(new_labels_for_row)\n",
    "    return np.array(mutated_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrdict = {'a':[1,0,0,0],\n",
    "           'c':[0,1,0,0],\n",
    "           'g':[0,0,1,0],\n",
    "           't':[0,0,0,1],\n",
    "           'n':[0,0,0,0],\n",
    "           'A':[1,0,0,0],\n",
    "           'C':[0,1,0,0],\n",
    "           'G':[0,0,1,0],\n",
    "           'T':[0,0,0,1],\n",
    "           'N':[0,0,0,0]}\n",
    "\n",
    "def onehot_encode(sequence):\n",
    "    return np.array([ltrdict[x] for x in sequence])\n",
    "\n",
    "x = np.array([onehot_encode(x) for x in sequences]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_y_train = mutate(y_train, mutation_prob=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompSumPool(Layer): \n",
    "    def __init__(self, **kwargs): \n",
    "        super(RevCompSumPool, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_input_chan = input_shape[2]\n",
    "        super(RevCompSumPool, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #divide by sqrt 2 for variance preservation\n",
    "        inputs = (inputs[:,:,:int(self.num_input_chan/2)] + inputs[:,:,int(self.num_input_chan/2):][:,::-1,::-1])/(1.41421356237)\n",
    "        return inputs\n",
    "      \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], int(input_shape[2]/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 15\n",
    "filters= 30\n",
    "input_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 21000\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "\n",
    "seed(seed_num)\n",
    "set_random_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('Seed %s.txt' % seed_num, str(seed_num))[0]\n",
    "f = open(filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def evaluate(model, x, y): \n",
    "    y_pred = model.predict(x)\n",
    "    auroc = roc_auc_score(y, model.predict(x)) \n",
    "    auprc = average_precision_score(y, model.predict(x))\n",
    "    print(\"auroc: \" + str(auroc))\n",
    "    print(\"auprc: \"+ str(auprc))\n",
    "    f.write(\"auroc: \" + str(auroc) + \"\\n\")\n",
    "    f.write(\"auprc: \" + str(auprc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Initializer\n",
    "def _compute_fans(shape, data_format='channels_last'):\n",
    "    \"\"\"Computes the number of input and output units for a weight shape.\n",
    "    # Arguments\n",
    "        shape: Integer shape tuple.\n",
    "        data_format: Image data format to use for convolution kernels.\n",
    "            Note that all kernels in Keras are standardized on the\n",
    "            `channels_last` ordering (even when inputs are set\n",
    "            to `channels_first`).\n",
    "    # Returns\n",
    "        A tuple of scalars, `(fan_in, fan_out)`.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid `data_format` argument.\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "        fan_out = shape[1]\n",
    "    elif len(shape) in {3, 4, 5}:\n",
    "        # Assuming convolution kernels (1D, 2D or 3D).\n",
    "        # TH kernel shape: (depth, input_depth, ...)\n",
    "        # TF kernel shape: (..., input_depth, depth)\n",
    "        if data_format == 'channels_first':\n",
    "            receptive_field_size = np.prod(shape[2:])\n",
    "            fan_in = shape[1] * receptive_field_size\n",
    "            fan_out = shape[0] * receptive_field_size\n",
    "        elif data_format == 'channels_last':\n",
    "            receptive_field_size = np.prod(shape[:-2])\n",
    "            fan_in = shape[-2] * receptive_field_size\n",
    "            fan_out = shape[-1] * receptive_field_size\n",
    "        else:\n",
    "            raise ValueError('Invalid data_format: ' + data_format)\n",
    "    else:\n",
    "        # No specific assumptions.\n",
    "        fan_in = np.sqrt(np.prod(shape))\n",
    "        fan_out = np.sqrt(np.prod(shape))\n",
    "    return fan_in, fan_out\n",
    "\n",
    "class RevcompVarianceScaling(Initializer):\n",
    "    def __init__(self, scale=1.0,\n",
    "                 mode='fan_in',\n",
    "                 distribution='normal',\n",
    "                 seed=None):\n",
    "        if scale <= 0.:\n",
    "            raise ValueError('`scale` must be a positive float. Got:', scale)\n",
    "        mode = mode.lower()\n",
    "        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n",
    "            raise ValueError('Invalid `mode` argument: '\n",
    "                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n",
    "                             'but got', mode)\n",
    "        distribution = distribution.lower()\n",
    "        if distribution not in {'normal', 'uniform'}:\n",
    "            raise ValueError('Invalid `distribution` argument: '\n",
    "                             'expected one of {\"normal\", \"uniform\"} '\n",
    "                             'but got', distribution)\n",
    "        self.scale = scale\n",
    "        self.mode = mode\n",
    "        self.distribution = distribution\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        fan_in, fan_out = _compute_fans(shape)\n",
    "        fan_out = fan_out*2 #revcomp kernel underestimates fan_out\n",
    "        print(\"fanin:\",fan_in, \"fanout:\",fan_out, self.scale, self.mode)\n",
    "        scale = self.scale\n",
    "        if self.mode == 'fan_in':\n",
    "            scale /= max(1., fan_in)\n",
    "        elif self.mode == 'fan_out':\n",
    "            scale /= max(1., fan_out)\n",
    "        else:\n",
    "            scale /= max(1., float(fan_in + fan_out) / 2)\n",
    "        if self.distribution == 'normal':\n",
    "            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n",
    "            stddev = np.sqrt(scale) / .87962566103423978\n",
    "            return K.truncated_normal(shape, 0., stddev,\n",
    "                                      dtype=dtype, seed=self.seed)\n",
    "        else:\n",
    "            limit = np.sqrt(3. * scale)\n",
    "            return K.random_uniform(shape, -limit, limit,\n",
    "                                    dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'scale': self.scale,\n",
    "            'mode': self.mode,\n",
    "            'distribution': self.distribution,\n",
    "            'seed': self.seed\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanin: 60 fanout: 900 1.0 fan_avg\n",
      "fanin: 900 fanout: 900 1.0 fan_avg\n",
      "fanin: 900 fanout: 900 1.0 fan_avg\n",
      "fanin: 750 fanout: 200 1.0 fan_avg\n"
     ]
    }
   ],
   "source": [
    "scale = 1.0\n",
    "rc_model = keras.models.Sequential()\n",
    "rc_model.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, \n",
    "            input_shape=x_train.shape[1:], padding=\"same\", \n",
    "            kernel_initializer = RevcompVarianceScaling(\n",
    "                                 scale= scale,\n",
    "                                 mode='fan_avg',\n",
    "                                 distribution='uniform',\n",
    "                                 seed=None)))\n",
    "# rc_model.add(keras_genomics.layers.normalization.RevCompConv1DBatchNorm())\n",
    "rc_model.add(k1.core.Activation(\"relu\"))\n",
    "rc_model.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size, padding=\"same\", \n",
    "            kernel_initializer = RevcompVarianceScaling(\n",
    "                                 scale= scale,\n",
    "                                 mode='fan_avg',\n",
    "                                 distribution='uniform',\n",
    "                                 seed=None)))\n",
    "# rc_model.add(keras_genomics.layers.normalization.RevCompConv1DBatchNorm())\n",
    "rc_model.add(k1.core.Activation(\"relu\"))\n",
    "rc_model.add(keras_genomics.layers.RevCompConv1D(\n",
    "            filters=filters, kernel_size=kernel_size,padding=\"same\", \n",
    "            kernel_initializer = RevcompVarianceScaling(\n",
    "                                 scale= scale,\n",
    "                                 mode='fan_avg',\n",
    "                                 distribution='uniform',\n",
    "                                 seed=None)))\n",
    "# rc_model.add(keras_genomics.layers.normalization.RevCompConv1DBatchNorm())\n",
    "rc_model.add(k1.core.Activation(\"relu\"))\n",
    "rc_model.add(RevCompSumPool())\n",
    "rc_model.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\", strides=40))\n",
    "rc_model.add(Flatten())\n",
    "rc_model.add(keras_genomics.layers.core.Dense(units = 100, activation = \"relu\", \n",
    "                                             kernel_initializer = RevcompVarianceScaling(\n",
    "                                                 scale= scale,\n",
    "                                                 mode='fan_avg',\n",
    "                                                 distribution='uniform',\n",
    "                                                 seed=None)))\n",
    "rc_model.add(keras_genomics.layers.core.Dense(units = 2))\n",
    "rc_model.add(k1.core.Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.7545 - acc: 0.5047 - val_loss: 0.6934 - val_acc: 0.4937\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 2s 379us/step - loss: 0.6927 - acc: 0.5077 - val_loss: 0.6941 - val_acc: 0.5113\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 2s 357us/step - loss: 0.6927 - acc: 0.5102 - val_loss: 0.6935 - val_acc: 0.4937\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 2s 352us/step - loss: 0.6927 - acc: 0.5153 - val_loss: 0.6920 - val_acc: 0.5553\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.6725 - acc: 0.5777 - val_loss: 0.6437 - val_acc: 0.6180\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.6345 - acc: 0.6218 - val_loss: 0.6279 - val_acc: 0.6380\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.6240 - acc: 0.6384 - val_loss: 0.6258 - val_acc: 0.6323\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 2s 359us/step - loss: 0.6153 - acc: 0.6399 - val_loss: 0.6226 - val_acc: 0.6347\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 2s 376us/step - loss: 0.6086 - acc: 0.6514 - val_loss: 0.6229 - val_acc: 0.6303\n",
      "Epoch 10/100\n",
      "6000/6000 [==============================] - 2s 356us/step - loss: 0.6092 - acc: 0.6498 - val_loss: 0.6258 - val_acc: 0.6367\n",
      "Epoch 11/100\n",
      "6000/6000 [==============================] - 2s 351us/step - loss: 0.6042 - acc: 0.6515 - val_loss: 0.6238 - val_acc: 0.6377\n",
      "Epoch 12/100\n",
      "6000/6000 [==============================] - 2s 353us/step - loss: 0.5961 - acc: 0.6616 - val_loss: 0.6261 - val_acc: 0.6303\n",
      "Epoch 13/100\n",
      "6000/6000 [==============================] - 2s 351us/step - loss: 0.5903 - acc: 0.6632 - val_loss: 0.6287 - val_acc: 0.6250\n",
      "Epoch 14/100\n",
      "6000/6000 [==============================] - 2s 349us/step - loss: 0.5825 - acc: 0.6729 - val_loss: 0.6369 - val_acc: 0.6313\n",
      "Epoch 15/100\n",
      "6000/6000 [==============================] - 2s 352us/step - loss: 0.5750 - acc: 0.6808 - val_loss: 0.6436 - val_acc: 0.6273\n",
      "Epoch 16/100\n",
      "6000/6000 [==============================] - 2s 348us/step - loss: 0.5575 - acc: 0.6926 - val_loss: 0.6536 - val_acc: 0.6177\n",
      "Epoch 17/100\n",
      "6000/6000 [==============================] - 2s 347us/step - loss: 0.5443 - acc: 0.6995 - val_loss: 0.6663 - val_acc: 0.6080\n",
      "Epoch 18/100\n",
      "6000/6000 [==============================] - 2s 351us/step - loss: 0.5208 - acc: 0.7141 - val_loss: 0.6832 - val_acc: 0.6193\n",
      "Epoch 19/100\n",
      "6000/6000 [==============================] - 2s 375us/step - loss: 0.5079 - acc: 0.7273 - val_loss: 0.7272 - val_acc: 0.6013\n",
      "Epoch 20/100\n",
      "6000/6000 [==============================] - 2s 357us/step - loss: 0.4805 - acc: 0.7359 - val_loss: 0.7936 - val_acc: 0.6097\n",
      "Epoch 21/100\n",
      "6000/6000 [==============================] - 2s 355us/step - loss: 0.4570 - acc: 0.7516 - val_loss: 0.8157 - val_acc: 0.5993\n",
      "Epoch 22/100\n",
      "6000/6000 [==============================] - 2s 357us/step - loss: 0.4305 - acc: 0.7752 - val_loss: 0.8318 - val_acc: 0.6037\n",
      "Epoch 23/100\n",
      "6000/6000 [==============================] - 2s 353us/step - loss: 0.4109 - acc: 0.7867 - val_loss: 0.8846 - val_acc: 0.5937\n",
      "Epoch 24/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.3840 - acc: 0.8086 - val_loss: 0.9715 - val_acc: 0.5987\n",
      "Epoch 25/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.3563 - acc: 0.8325 - val_loss: 1.0318 - val_acc: 0.5990\n",
      "Epoch 26/100\n",
      "6000/6000 [==============================] - 2s 352us/step - loss: 0.3241 - acc: 0.8481 - val_loss: 1.0726 - val_acc: 0.5850\n",
      "Epoch 27/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.2853 - acc: 0.8709 - val_loss: 1.2198 - val_acc: 0.6020\n",
      "Epoch 28/100\n",
      "6000/6000 [==============================] - 2s 356us/step - loss: 0.2458 - acc: 0.8967 - val_loss: 1.3333 - val_acc: 0.5937\n",
      "Epoch 29/100\n",
      "6000/6000 [==============================] - 2s 355us/step - loss: 0.1985 - acc: 0.9218 - val_loss: 1.4440 - val_acc: 0.5960\n",
      "Epoch 30/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.1503 - acc: 0.9452 - val_loss: 1.6086 - val_acc: 0.5990\n",
      "Epoch 31/100\n",
      "6000/6000 [==============================] - 2s 351us/step - loss: 0.1062 - acc: 0.9664 - val_loss: 1.7543 - val_acc: 0.5853\n",
      "Epoch 32/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.0726 - acc: 0.9795 - val_loss: 1.9083 - val_acc: 0.5943\n",
      "Epoch 33/100\n",
      "6000/6000 [==============================] - 2s 369us/step - loss: 0.0462 - acc: 0.9900 - val_loss: 2.0818 - val_acc: 0.6020\n",
      "Epoch 34/100\n",
      "6000/6000 [==============================] - 2s 367us/step - loss: 0.0281 - acc: 0.9959 - val_loss: 2.1724 - val_acc: 0.5857\n",
      "Epoch 35/100\n",
      "6000/6000 [==============================] - 2s 357us/step - loss: 0.0140 - acc: 0.9995 - val_loss: 2.3330 - val_acc: 0.5933\n",
      "Epoch 36/100\n",
      "6000/6000 [==============================] - 2s 356us/step - loss: 0.0067 - acc: 0.9998 - val_loss: 2.4027 - val_acc: 0.5923\n",
      "Epoch 37/100\n",
      "6000/6000 [==============================] - 2s 356us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.5136 - val_acc: 0.5877\n",
      "Epoch 38/100\n",
      "6000/6000 [==============================] - 2s 352us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.5672 - val_acc: 0.5877\n",
      "Epoch 39/100\n",
      "6000/6000 [==============================] - 2s 351us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.6273 - val_acc: 0.5860\n",
      "Epoch 40/100\n",
      "6000/6000 [==============================] - 2s 353us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6632 - val_acc: 0.5833\n",
      "Epoch 41/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.7022 - val_acc: 0.5840\n",
      "Epoch 42/100\n",
      "6000/6000 [==============================] - 2s 357us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7346 - val_acc: 0.5860\n",
      "Epoch 43/100\n",
      "6000/6000 [==============================] - 2s 353us/step - loss: 9.5241e-04 - acc: 1.0000 - val_loss: 2.7634 - val_acc: 0.5863\n",
      "Epoch 44/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 8.4872e-04 - acc: 1.0000 - val_loss: 2.7926 - val_acc: 0.5843\n",
      "Epoch 45/100\n",
      "6000/6000 [==============================] - 2s 353us/step - loss: 7.6351e-04 - acc: 1.0000 - val_loss: 2.8157 - val_acc: 0.5850\n",
      "Epoch 46/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 6.8747e-04 - acc: 1.0000 - val_loss: 2.8364 - val_acc: 0.5870\n",
      "Epoch 47/100\n",
      "6000/6000 [==============================] - 2s 354us/step - loss: 6.2535e-04 - acc: 1.0000 - val_loss: 2.8633 - val_acc: 0.5870\n",
      "Epoch 48/100\n",
      "6000/6000 [==============================] - 2s 352us/step - loss: 5.7005e-04 - acc: 1.0000 - val_loss: 2.8849 - val_acc: 0.5860\n"
     ]
    }
   ],
   "source": [
    "rc_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 40,\n",
    "                              restore_best_weights=True)\n",
    "history_rc = rc_model.fit(x_train, noisy_y_train, validation_split=0.2,  \n",
    "                    callbacks= [early_stopping_callback], batch_size=100,  epochs=100)\n",
    "rc_model.set_weights(early_stopping_callback.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanin: 60 fanout: 900 1.0 fan_avg\n",
      "fanin: 900 fanout: 900 1.0 fan_avg\n",
      "fanin: 900 fanout: 900 1.0 fan_avg\n",
      "fanin: 750 fanout: 200 1.0 fan_avg\n"
     ]
    }
   ],
   "source": [
    "rc_filename = ('rc_model_noise_var_%s.h5' % seed_num, str(seed_num))[0]\n",
    "rc_model.save(rc_filename)\n",
    "custom_objects = {'RevCompConv1D':keras_genomics.layers.RevCompConv1D, \n",
    "                  'RevCompConv1DBatchNorm':keras_genomics.layers.RevCompConv1DBatchNorm,\n",
    "                  'RevCompSumPool':RevCompSumPool,\n",
    "                 'RevcompVarianceScaling':RevcompVarianceScaling}\n",
    "rc_model_final = load_model(rc_filename, custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = keras.models.Sequential()\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        input_shape=(input_length,4), padding=\"same\"))\n",
    "# reg_model.add(k1.BatchNormalization())\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "# reg_model.add(k1.BatchNormalization())\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "reg_model.add(k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                        padding=\"same\"))\n",
    "# reg_model.add(k1.BatchNormalization())\n",
    "reg_model.add(k1.core.Activation(\"relu\"))\n",
    "reg_model.add(k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\",\n",
    "                                               strides=40))\n",
    "reg_model.add(Flatten())\n",
    "reg_model.add(k1.Dense(units = 100, activation = \"relu\"))\n",
    "reg_model.add(k1.Dense(units = 2))\n",
    "reg_model.add(k1.core.Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.6960 - acc: 0.5010 - val_loss: 0.6931 - val_acc: 0.5017\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 1s 206us/step - loss: 0.6929 - acc: 0.5064 - val_loss: 0.6932 - val_acc: 0.5010\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.6927 - acc: 0.5132 - val_loss: 0.6931 - val_acc: 0.5120\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.6924 - acc: 0.5188 - val_loss: 0.6938 - val_acc: 0.4990\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.6832 - acc: 0.5530 - val_loss: 0.6757 - val_acc: 0.5620\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.6418 - acc: 0.6221 - val_loss: 0.6501 - val_acc: 0.6120\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 1s 195us/step - loss: 0.6254 - acc: 0.6417 - val_loss: 0.6318 - val_acc: 0.6337\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 1s 180us/step - loss: 0.6141 - acc: 0.6588 - val_loss: 0.6297 - val_acc: 0.6293\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 1s 185us/step - loss: 0.6041 - acc: 0.6737 - val_loss: 0.6324 - val_acc: 0.6380\n",
      "Epoch 10/100\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.5918 - acc: 0.6816 - val_loss: 0.6379 - val_acc: 0.6337\n",
      "Epoch 11/100\n",
      "6000/6000 [==============================] - 1s 186us/step - loss: 0.5744 - acc: 0.7020 - val_loss: 0.6359 - val_acc: 0.6530\n",
      "Epoch 12/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.5485 - acc: 0.7241 - val_loss: 0.6399 - val_acc: 0.6570\n",
      "Epoch 13/100\n",
      "6000/6000 [==============================] - 1s 193us/step - loss: 0.5217 - acc: 0.7426 - val_loss: 0.6587 - val_acc: 0.6553\n",
      "Epoch 14/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.4926 - acc: 0.7637 - val_loss: 0.6606 - val_acc: 0.6550\n",
      "Epoch 15/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.4528 - acc: 0.7872 - val_loss: 0.6862 - val_acc: 0.6497\n",
      "Epoch 16/100\n",
      "6000/6000 [==============================] - 1s 189us/step - loss: 0.4139 - acc: 0.8102 - val_loss: 0.7252 - val_acc: 0.6430\n",
      "Epoch 17/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.3720 - acc: 0.8358 - val_loss: 0.7204 - val_acc: 0.6273\n",
      "Epoch 18/100\n",
      "6000/6000 [==============================] - 1s 179us/step - loss: 0.3250 - acc: 0.8633 - val_loss: 0.8429 - val_acc: 0.6277\n",
      "Epoch 19/100\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.2627 - acc: 0.8957 - val_loss: 0.8972 - val_acc: 0.6363\n",
      "Epoch 20/100\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.2150 - acc: 0.9188 - val_loss: 0.9848 - val_acc: 0.6190\n",
      "Epoch 21/100\n",
      "6000/6000 [==============================] - 1s 186us/step - loss: 0.1574 - acc: 0.9455 - val_loss: 1.1166 - val_acc: 0.6270\n",
      "Epoch 22/100\n",
      "6000/6000 [==============================] - 1s 195us/step - loss: 0.1089 - acc: 0.9690 - val_loss: 1.2799 - val_acc: 0.6363\n",
      "Epoch 23/100\n",
      "6000/6000 [==============================] - 1s 198us/step - loss: 0.0720 - acc: 0.9830 - val_loss: 1.3903 - val_acc: 0.6233\n",
      "Epoch 24/100\n",
      "6000/6000 [==============================] - 1s 193us/step - loss: 0.0487 - acc: 0.9912 - val_loss: 1.5565 - val_acc: 0.6237\n",
      "Epoch 25/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.0274 - acc: 0.9984 - val_loss: 1.7101 - val_acc: 0.6240\n",
      "Epoch 26/100\n",
      "6000/6000 [==============================] - 1s 195us/step - loss: 0.0149 - acc: 0.9999 - val_loss: 1.8839 - val_acc: 0.6270\n",
      "Epoch 27/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.9990 - val_acc: 0.6273\n",
      "Epoch 28/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.0989 - val_acc: 0.6250\n",
      "Epoch 29/100\n",
      "6000/6000 [==============================] - 1s 187us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.1780 - val_acc: 0.6257\n",
      "Epoch 30/100\n",
      "6000/6000 [==============================] - 1s 193us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.2349 - val_acc: 0.6253\n",
      "Epoch 31/100\n",
      "6000/6000 [==============================] - 1s 194us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.2875 - val_acc: 0.6257\n",
      "Epoch 32/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.3323 - val_acc: 0.6257\n",
      "Epoch 33/100\n",
      "6000/6000 [==============================] - 1s 188us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.3720 - val_acc: 0.6250\n",
      "Epoch 34/100\n",
      "6000/6000 [==============================] - 1s 184us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.4250 - val_acc: 0.6233\n",
      "Epoch 35/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.4525 - val_acc: 0.6220\n",
      "Epoch 36/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.4833 - val_acc: 0.6240\n",
      "Epoch 37/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.5165 - val_acc: 0.6243\n",
      "Epoch 38/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.5451 - val_acc: 0.6243\n",
      "Epoch 39/100\n",
      "6000/6000 [==============================] - 1s 193us/step - loss: 9.0481e-04 - acc: 1.0000 - val_loss: 2.5668 - val_acc: 0.6247\n",
      "Epoch 40/100\n",
      "6000/6000 [==============================] - 1s 195us/step - loss: 8.1962e-04 - acc: 1.0000 - val_loss: 2.5982 - val_acc: 0.6233\n",
      "Epoch 41/100\n",
      "6000/6000 [==============================] - 1s 186us/step - loss: 7.4091e-04 - acc: 1.0000 - val_loss: 2.6321 - val_acc: 0.6247\n",
      "Epoch 42/100\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 6.7671e-04 - acc: 1.0000 - val_loss: 2.6555 - val_acc: 0.6240\n",
      "Epoch 43/100\n",
      "6000/6000 [==============================] - 1s 194us/step - loss: 6.1649e-04 - acc: 1.0000 - val_loss: 2.6786 - val_acc: 0.6243\n",
      "Epoch 44/100\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 5.6640e-04 - acc: 1.0000 - val_loss: 2.7051 - val_acc: 0.6243\n",
      "Epoch 45/100\n",
      "6000/6000 [==============================] - 1s 185us/step - loss: 5.1990e-04 - acc: 1.0000 - val_loss: 2.7223 - val_acc: 0.6217\n",
      "Epoch 46/100\n",
      "6000/6000 [==============================] - 1s 180us/step - loss: 4.7734e-04 - acc: 1.0000 - val_loss: 2.7509 - val_acc: 0.6230\n",
      "Epoch 47/100\n",
      "6000/6000 [==============================] - 1s 185us/step - loss: 4.4208e-04 - acc: 1.0000 - val_loss: 2.7667 - val_acc: 0.6247\n",
      "Epoch 48/100\n",
      "6000/6000 [==============================] - 1s 188us/step - loss: 4.0907e-04 - acc: 1.0000 - val_loss: 2.7890 - val_acc: 0.6227\n"
     ]
    }
   ],
   "source": [
    "reg_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 40,\n",
    "                              restore_best_weights=True)\n",
    "history_reg = reg_model.fit(x_train, noisy_y_train, validation_split = 0.2, \n",
    "                           callbacks=[early_stopping_callback], batch_size = 100, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.set_weights(early_stopping_callback.best_weights)\n",
    "reg_filename = ('reg_model_noise_%s.h5' % seed_num, str(seed_num))[0]\n",
    "reg_model.save(reg_filename)\n",
    "reg_model_final = load_model(reg_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = Sequential([\n",
    "    k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "            input_shape=(input_length,4), padding=\"same\"), \n",
    "#     k1.BatchNormalization(), \n",
    "    k1.core.Activation(\"relu\"),\n",
    "    k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "              padding=\"same\"), \n",
    "#     k1.BatchNormalization(), \n",
    "    k1.core.Activation(\"relu\"),\n",
    "    k1.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "              padding=\"same\"), \n",
    "#     k1.BatchNormalization(), \n",
    "    k1.core.Activation(\"relu\"),\n",
    "    k1.pooling.MaxPooling1D(pool_size=40,padding=\"same\",\n",
    "                                               strides=40), \n",
    "    Flatten(), \n",
    "    k1.Dense(units = 100, activation = \"relu\"),\n",
    "    k1.Dense(units = 2)\n",
    "], name = \"shared_layers\")\n",
    "\n",
    "main_input = Input(shape=(input_length, 4, ))\n",
    "rev_input = Input(shape=(input_length, 4, ))\n",
    "\n",
    "main_output = s_model(main_input)\n",
    "rev_output = s_model(rev_input)\n",
    "\n",
    "avg = k1.Average()([main_output, rev_output])\n",
    "final_out = k1.core.Activation(\"sigmoid\")(avg)\n",
    "siamese_model = Model(inputs = [main_input, rev_input], outputs = final_out)\n",
    "\n",
    "merged = keras.layers.concatenate([main_output, rev_output])\n",
    "\n",
    "predictions = k1.core.Activation(\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 0.6942 - acc: 0.5069 - val_loss: 0.6932 - val_acc: 0.5017\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 2s 306us/step - loss: 0.6929 - acc: 0.5106 - val_loss: 0.6929 - val_acc: 0.5127\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 2s 304us/step - loss: 0.6925 - acc: 0.5140 - val_loss: 0.6935 - val_acc: 0.4990\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 2s 303us/step - loss: 0.6800 - acc: 0.5596 - val_loss: 0.6570 - val_acc: 0.6017\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 2s 311us/step - loss: 0.6418 - acc: 0.6163 - val_loss: 0.6347 - val_acc: 0.6287\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 2s 335us/step - loss: 0.6274 - acc: 0.6412 - val_loss: 0.6288 - val_acc: 0.6210\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 2s 321us/step - loss: 0.6168 - acc: 0.6492 - val_loss: 0.6234 - val_acc: 0.6350\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 2s 300us/step - loss: 0.6015 - acc: 0.6788 - val_loss: 0.6370 - val_acc: 0.6543\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 2s 308us/step - loss: 0.5775 - acc: 0.7158 - val_loss: 0.5915 - val_acc: 0.7080\n",
      "Epoch 10/100\n",
      "6000/6000 [==============================] - 2s 293us/step - loss: 0.5499 - acc: 0.7397 - val_loss: 0.6051 - val_acc: 0.7027\n",
      "Epoch 11/100\n",
      "6000/6000 [==============================] - 2s 298us/step - loss: 0.5355 - acc: 0.7452 - val_loss: 0.5877 - val_acc: 0.7173\n",
      "Epoch 12/100\n",
      "6000/6000 [==============================] - 2s 303us/step - loss: 0.5176 - acc: 0.7601 - val_loss: 0.6014 - val_acc: 0.7150\n",
      "Epoch 13/100\n",
      "6000/6000 [==============================] - 2s 306us/step - loss: 0.4855 - acc: 0.7778 - val_loss: 0.6162 - val_acc: 0.7003\n",
      "Epoch 14/100\n",
      "6000/6000 [==============================] - 2s 302us/step - loss: 0.4487 - acc: 0.8003 - val_loss: 0.6309 - val_acc: 0.7127\n",
      "Epoch 15/100\n",
      "6000/6000 [==============================] - 2s 297us/step - loss: 0.4041 - acc: 0.8209 - val_loss: 0.6572 - val_acc: 0.6893\n",
      "Epoch 16/100\n",
      "6000/6000 [==============================] - 2s 300us/step - loss: 0.3491 - acc: 0.8504 - val_loss: 0.7025 - val_acc: 0.6773\n",
      "Epoch 17/100\n",
      "6000/6000 [==============================] - 2s 297us/step - loss: 0.2958 - acc: 0.8800 - val_loss: 0.7850 - val_acc: 0.6553\n",
      "Epoch 18/100\n",
      "6000/6000 [==============================] - 2s 299us/step - loss: 0.2375 - acc: 0.9120 - val_loss: 0.8593 - val_acc: 0.6640\n",
      "Epoch 19/100\n",
      "6000/6000 [==============================] - 2s 296us/step - loss: 0.1836 - acc: 0.9337 - val_loss: 0.9431 - val_acc: 0.6530\n",
      "Epoch 20/100\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 0.1324 - acc: 0.9590 - val_loss: 1.0911 - val_acc: 0.6523\n",
      "Epoch 21/100\n",
      "6000/6000 [==============================] - 2s 304us/step - loss: 0.1011 - acc: 0.9727 - val_loss: 1.1777 - val_acc: 0.6423\n",
      "Epoch 22/100\n",
      "6000/6000 [==============================] - 2s 317us/step - loss: 0.0606 - acc: 0.9899 - val_loss: 1.3351 - val_acc: 0.6493\n",
      "Epoch 23/100\n",
      "6000/6000 [==============================] - 2s 316us/step - loss: 0.0370 - acc: 0.9964 - val_loss: 1.4570 - val_acc: 0.6530\n",
      "Epoch 24/100\n",
      "6000/6000 [==============================] - 2s 317us/step - loss: 0.0217 - acc: 0.9998 - val_loss: 1.5906 - val_acc: 0.6457\n",
      "Epoch 25/100\n",
      "6000/6000 [==============================] - 2s 346us/step - loss: 0.0144 - acc: 0.9998 - val_loss: 1.6846 - val_acc: 0.6443\n",
      "Epoch 26/100\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.7893 - val_acc: 0.6437\n",
      "Epoch 27/100\n",
      "6000/6000 [==============================] - 2s 317us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.8770 - val_acc: 0.6443\n",
      "Epoch 28/100\n",
      "6000/6000 [==============================] - 2s 306us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.9415 - val_acc: 0.6410\n",
      "Epoch 29/100\n",
      "6000/6000 [==============================] - 2s 308us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.9873 - val_acc: 0.6393\n",
      "Epoch 30/100\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.0325 - val_acc: 0.6437\n",
      "Epoch 31/100\n",
      "6000/6000 [==============================] - 2s 316us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.0778 - val_acc: 0.6407\n",
      "Epoch 32/100\n",
      "6000/6000 [==============================] - 2s 319us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.1237 - val_acc: 0.6430\n",
      "Epoch 33/100\n",
      "6000/6000 [==============================] - 2s 312us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.1601 - val_acc: 0.6403\n",
      "Epoch 34/100\n",
      "6000/6000 [==============================] - 2s 308us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.1903 - val_acc: 0.6427\n",
      "Epoch 35/100\n",
      "6000/6000 [==============================] - 2s 308us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.2264 - val_acc: 0.6410\n",
      "Epoch 36/100\n",
      "6000/6000 [==============================] - 2s 318us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.2511 - val_acc: 0.6413\n",
      "Epoch 37/100\n",
      "6000/6000 [==============================] - 2s 305us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2841 - val_acc: 0.6407\n",
      "Epoch 38/100\n",
      "6000/6000 [==============================] - 2s 302us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.3121 - val_acc: 0.6403\n",
      "Epoch 39/100\n",
      "6000/6000 [==============================] - 2s 300us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.3420 - val_acc: 0.6403\n",
      "Epoch 40/100\n",
      "6000/6000 [==============================] - 2s 294us/step - loss: 9.9767e-04 - acc: 1.0000 - val_loss: 2.3620 - val_acc: 0.6400\n",
      "Epoch 41/100\n",
      "6000/6000 [==============================] - 2s 301us/step - loss: 9.1441e-04 - acc: 1.0000 - val_loss: 2.3901 - val_acc: 0.6413\n",
      "Epoch 42/100\n",
      "6000/6000 [==============================] - 2s 303us/step - loss: 8.3236e-04 - acc: 1.0000 - val_loss: 2.4117 - val_acc: 0.6390\n",
      "Epoch 43/100\n",
      "6000/6000 [==============================] - 2s 305us/step - loss: 7.6956e-04 - acc: 1.0000 - val_loss: 2.4305 - val_acc: 0.6407\n",
      "Epoch 44/100\n",
      "6000/6000 [==============================] - 2s 295us/step - loss: 7.1965e-04 - acc: 1.0000 - val_loss: 2.4473 - val_acc: 0.6437\n",
      "Epoch 45/100\n",
      "6000/6000 [==============================] - 2s 296us/step - loss: 6.5183e-04 - acc: 1.0000 - val_loss: 2.4713 - val_acc: 0.6400\n",
      "Epoch 46/100\n",
      "6000/6000 [==============================] - 2s 298us/step - loss: 5.9597e-04 - acc: 1.0000 - val_loss: 2.4923 - val_acc: 0.6410\n",
      "Epoch 47/100\n",
      "6000/6000 [==============================] - 2s 295us/step - loss: 5.5673e-04 - acc: 1.0000 - val_loss: 2.5040 - val_acc: 0.6380\n",
      "Epoch 48/100\n",
      "6000/6000 [==============================] - 2s 309us/step - loss: 5.1148e-04 - acc: 1.0000 - val_loss: 2.5256 - val_acc: 0.6393\n",
      "Epoch 49/100\n",
      "6000/6000 [==============================] - 2s 310us/step - loss: 4.7496e-04 - acc: 1.0000 - val_loss: 2.5429 - val_acc: 0.6380\n",
      "Epoch 50/100\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 4.4220e-04 - acc: 1.0000 - val_loss: 2.5685 - val_acc: 0.6397\n",
      "Epoch 51/100\n",
      "6000/6000 [==============================] - 2s 308us/step - loss: 4.1809e-04 - acc: 1.0000 - val_loss: 2.5813 - val_acc: 0.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43cc3dbbe0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                              monitor='val_loss',\n",
    "                              patience= 40,\n",
    "                              restore_best_weights=True)\n",
    "siamese_model.fit([x_train, x_train[:,::-1,::-1]], noisy_y_train, validation_split=0.2,  \n",
    "                    callbacks=[early_stopping_callback],\n",
    "                    batch_size=100,  epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.set_weights(early_stopping_callback.best_weights)\n",
    "siamese_filename = ('siamese_model_noise_%s.h5' % seed_num, str(seed_num))[0]\n",
    "siamese_model.save(siamese_filename)\n",
    "siamese_model_final = load_model(siamese_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse Complement Model\n",
      "auroc: 0.7473625840916727\n",
      "auprc: 0.7563629332330897\n"
     ]
    }
   ],
   "source": [
    "print(\"Reverse Complement Model\")\n",
    "f.write(\"Reverse Complement Model\\n\")\n",
    "evaluate(rc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Model\n",
      "auroc: 0.7566077268950202\n",
      "auprc: 0.7651813672685217\n"
     ]
    }
   ],
   "source": [
    "print(\"Regular Model\")\n",
    "f.write(\"Regular Model\\n\")\n",
    "evaluate(reg_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese Architecture\n",
      "auroc: 0.937246598867005\n",
      "auprc: 0.948257274539625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Siamese Architecture\")\n",
    "y_pred = siamese_model.predict([x_test, x_test[:,::-1,::-1]])\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "auprc = average_precision_score(y_test, y_pred)\n",
    "print(\"auroc: \" + str(auroc))\n",
    "print(\"auprc: \"+ str(auprc))\n",
    "f.write(\"Siamese Architecture\\n\")\n",
    "f.write(\"auroc: \" + str(auroc) + \"\\n\")\n",
    "f.write(\"auprc: \"+ str(auprc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
